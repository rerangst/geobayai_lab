<!DOCTYPE html>
<html lang="vi-VN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Chương 5: Pre-trained Weights và Sensor Support trong TorchGeo | Deep Learning trong Viễn thám</title>
    <meta name="description" content="Nghiên cứu ứng dụng CNN và Deep Learning trong phân tích ảnh viễn thám">
    <meta name="generator" content="VitePress v1.6.4">
    <link rel="preload stylesheet" href="/sen_doc/assets/style.W3JISx3E.css" as="style">
    <link rel="preload stylesheet" href="/sen_doc/vp-icons.css" as="style">
    
    <script type="module" src="/sen_doc/assets/app.CWSbRAFv.js"></script>
    <link rel="preload" href="/sen_doc/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/framework.nRfFlDZQ.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/theme.Ch0spFQA.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/katex.Cu_Erd72.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/dagre-6UL2VRFP.BQ5r6kFc.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/cose-bilkent-S5V4N54A.Cg2D0hX4.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/c4Diagram-YG6GDRKO.Ch1Z5DYy.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/flowDiagram-NV44I4VS.B-M56PNY.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/erDiagram-Q2GNP2WA.ChNEjQqf.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/gitGraphDiagram-NY62KEGX.CYjbWr1H.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/ganttDiagram-JELNMOA3.BuFF-7gm.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/infoDiagram-WHAUD3N6.DXhWiX-4.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/pieDiagram-ADFJNKIX.CEooP7iW.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/quadrantDiagram-AYHSOK5B.BxpFNOre.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/xychartDiagram-PRI3JC2R.D7l7DTkm.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/requirementDiagram-UZGBJVZJ.CnZWdBnS.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/sequenceDiagram-WL72ISMW.Dq5DiI5R.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/classDiagram-2ON5EDUG.C-uTH9t6.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/classDiagram-v2-WZHVMYZB.C-uTH9t6.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/stateDiagram-FKZM4ZOC.DA69JNoS.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/stateDiagram-v2-4FDKWEC3.CvG5pOcG.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/journeyDiagram-XKPGCS4Q.B6_zk-Uc.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/timeline-definition-IT6M3QCI.Bq-srREc.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/mindmap-definition-VGOIOE7T.C1lO0ZZX.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/kanban-definition-3W4ZIXB7.D1R1ZtJ4.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/sankeyDiagram-TZEHDZUN.3FvNQ0V-.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/diagram-S2PKOQOG.CN4gAtio.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/diagram-QEK2KX5R.BgEYpliI.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/blockDiagram-VD42YOAC.CblIZ9TF.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/architectureDiagram-VXUJARFQ.D58rp7Xd.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/diagram-PSM6KHXK.55LfW1Pd.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/virtual_mermaid-config.CQTEIV6y.js">
    <link rel="modulepreload" href="/sen_doc/assets/chuong-05-torchgeo_muc-05-pretrained-weights_01-pretrained-weights.md.BuNGhnCB.lean.js">
    <meta name="theme-color" content="#3eaf7c">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5d98c3a5><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0b0ada53></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0b0ada53>Skip to content</a><!--]--><!----><header class="VPNav" data-v-5d98c3a5 data-v-ae24b3ad><div class="VPNavBar" data-v-ae24b3ad data-v-6aa21345><div class="wrapper" data-v-6aa21345><div class="container" data-v-6aa21345><div class="title" data-v-6aa21345><div class="VPNavBarTitle has-sidebar" data-v-6aa21345 data-v-1168a8e4><a class="title" href="/sen_doc/" data-v-1168a8e4><!--[--><!--]--><!----><span data-v-1168a8e4>Deep Learning trong Viễn thám</span><!--[--><!--]--></a></div></div><div class="content" data-v-6aa21345><div class="content-body" data-v-6aa21345><!--[--><!--]--><div class="VPNavBarSearch search" data-v-6aa21345><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-6aa21345 data-v-dc692963><span id="main-nav-aria-label" class="visually-hidden" data-v-dc692963> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/sen_doc/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Trang chủ</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/sen_doc/chuong-01-gioi-thieu/muc-01-tong-quan/01-gioi-thieu-cnn-deep-learning.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Giới thiệu</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/sen_doc/chuong-05-torchgeo/muc-01-tong-quan/01-tong-quan.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>TorchGeo</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/01-dataset.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>xView</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-6aa21345 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-6aa21345 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/tchatb/sen_doc" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-6aa21345 data-v-bb2aa2f0 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-cf11d7a2><span class="vpi-more-horizontal icon" data-v-cf11d7a2></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><!----><!--[--><!--[--><!----><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>Giao diện</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/tchatb/sen_doc" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-6aa21345 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-6aa21345><div class="divider-line" data-v-6aa21345></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-5d98c3a5 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-8a42e2b4><button data-v-8a42e2b4>Về đầu trang</button><!----></div></div></div><aside class="VPSidebar" data-v-5d98c3a5 data-v-319d5ca6><div class="curtain" data-v-319d5ca6></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-319d5ca6><span class="visually-hidden" id="sidebar-aria-label" data-v-319d5ca6> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 1: Giới thiệu</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-01-gioi-thieu/muc-01-tong-quan/01-gioi-thieu-cnn-deep-learning.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>1.1. Tổng quan CNN & Deep Learning</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 2: Cơ sở lý thuyết</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-01-kien-truc-cnn/01-kien-truc-co-ban.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.1.1. Kiến trúc CNN cơ bản</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-01-kien-truc-cnn/02-backbone-networks.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.1.2. Backbone Networks</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/01-phan-loai-anh.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.2.1. Phân loại ảnh</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/02-phat-hien-doi-tuong.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.2.2. Phát hiện đối tượng</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/03-phan-doan-ngu-nghia.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.2.3. Phân đoạn ngữ nghĩa</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/04-instance-segmentation.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.2.4. Instance Segmentation</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible collapsed" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 3: Phát hiện tàu biển</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-03-phat-hien-tau-bien/muc-01-dac-diem-bai-toan/01-dac-diem.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>3.1. Đặc điểm bài toán</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-03-phat-hien-tau-bien/muc-02-mo-hinh/01-cac-mo-hinh.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>3.2. Các mô hình</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-03-phat-hien-tau-bien/muc-03-quy-trinh/01-pipeline.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>3.3. Quy trình pipeline</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-03-phat-hien-tau-bien/muc-04-bo-du-lieu/01-datasets.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>3.4. Bộ dữ liệu</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible collapsed" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 4: Phát hiện dầu loang</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-phat-hien-dau-loang/muc-01-dac-diem-bai-toan/01-dac-diem.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>4.1. Đặc điểm bài toán</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-phat-hien-dau-loang/muc-02-mo-hinh/01-cac-mo-hinh.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>4.2. Các mô hình</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-phat-hien-dau-loang/muc-03-quy-trinh/01-pipeline.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>4.3. Quy trình pipeline</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-phat-hien-dau-loang/muc-04-bo-du-lieu/01-datasets.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>4.4. Bộ dữ liệu</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible collapsed has-active" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 5: TorchGeo</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-torchgeo/muc-01-tong-quan/01-tong-quan.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.1. Tổng quan</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-torchgeo/muc-02-classification/01-classification-models.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.2. Classification Models</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-torchgeo/muc-03-segmentation/01-segmentation-models.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.3. Segmentation Models</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-torchgeo/muc-04-change-detection/01-change-detection-models.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.4. Change Detection</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-torchgeo/muc-05-pretrained-weights/01-pretrained-weights.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.5. Pre-trained Weights</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 6: xView Challenges</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><section class="VPSidebarItem level-1 collapsible collapsed" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h3 class="text" data-v-b3fd67f8>6.1. xView1 - Object Detection</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/01-dataset.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/02-giai-nhat.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhất</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/03-giai-nhi.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhì</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/04-giai-ba.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải ba</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/05-giai-tu.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải tư</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/06-giai-nam.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải năm</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible collapsed" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h3 class="text" data-v-b3fd67f8>6.2. xView2 - Building Damage</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-02-xview2-building-damage/01-dataset.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Dataset (xBD)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-02-xview2-building-damage/02-giai-nhat.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhất</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-02-xview2-building-damage/03-giai-nhi.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhì</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-02-xview2-building-damage/04-giai-ba.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải ba</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-02-xview2-building-damage/05-giai-tu.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải tư</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-02-xview2-building-damage/06-giai-nam.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải năm</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible collapsed" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h3 class="text" data-v-b3fd67f8>6.3. xView3 - Maritime (SAR)</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-03-xview3-maritime/01-dataset.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-03-xview3-maritime/02-giai-nhat.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhất</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-03-xview3-maritime/03-giai-nhi.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhì</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-03-xview3-maritime/04-giai-ba.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải ba</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-03-xview3-maritime/05-giai-tu.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải tư</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-03-xview3-maritime/06-giai-nam.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải năm</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 7: Kết luận</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-07-ket-luan/muc-01-tong-ket/01-ket-luan.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>7.1. Tổng kết</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5d98c3a5 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-a5bbad30><div class="content" data-v-a5bbad30><div class="outline-marker" data-v-a5bbad30></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a5bbad30>Mục lục trang</div><ul class="VPDocOutlineItem root" data-v-a5bbad30 data-v-b933a997><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _sen_doc_chuong-05-torchgeo_muc-05-pretrained-weights_01-pretrained-weights" data-v-39a288b8><div><h1 id="chuong-5-pre-trained-weights-va-sensor-support-trong-torchgeo" tabindex="-1">Chương 5: Pre-trained Weights và Sensor Support trong TorchGeo <a class="header-anchor" href="#chuong-5-pre-trained-weights-va-sensor-support-trong-torchgeo" aria-label="Permalink to &quot;Chương 5: Pre-trained Weights và Sensor Support trong TorchGeo&quot;">​</a></h1><h2 id="_6-40-tong-quan-pre-trained-weights" tabindex="-1">6.40. Tổng quan Pre-trained Weights <a class="header-anchor" href="#_6-40-tong-quan-pre-trained-weights" aria-label="Permalink to &quot;6.40. Tổng quan Pre-trained Weights&quot;">​</a></h2><p>Pre-trained weights là một trong những đóng góp quan trọng nhất của TorchGeo cho remote sensing community. Thay vì training models từ scratch hoặc sử dụng ImageNet pretrained weights không phù hợp với satellite imagery, TorchGeo cung cấp weights được train đặc biệt trên dữ liệu vệ tinh, cho performance tốt hơn đáng kể trên downstream tasks.</p><p>Trong phần này, chúng ta sẽ phân tích chi tiết các pre-trained weights có sẵn, sensor support, và cách sử dụng hiệu quả cho các ứng dụng khác nhau.</p><h2 id="_6-41-ssl4eo-pre-trained-weights" tabindex="-1">6.41. SSL4EO Pre-trained Weights <a class="header-anchor" href="#_6-41-ssl4eo-pre-trained-weights" aria-label="Permalink to &quot;6.41. SSL4EO Pre-trained Weights&quot;">​</a></h2><h3 id="_6-41-1-tong-quan-ssl4eo" tabindex="-1">6.41.1. Tổng quan SSL4EO <a class="header-anchor" href="#_6-41-1-tong-quan-ssl4eo" aria-label="Permalink to &quot;6.41.1. Tổng quan SSL4EO&quot;">​</a></h3><p>SSL4EO (Self-Supervised Learning for Earth Observation) là initiative để tạo pre-trained models cho Earth Observation data sử dụng self-supervised learning.</p><p><strong>SSL4EO-S12:</strong> Dataset và weights cho Sentinel-1 và Sentinel-2:</p><ul><li>200,000+ image triplets</li><li>European coverage</li><li>Seasonal variations captured</li><li>Multiple pre-training methods</li></ul><p><strong>Tại sao Self-supervised:</strong></p><ul><li>Không cần labeled data (expensive và limited cho remote sensing)</li><li>Learns general representations</li><li>Transfers well to various tasks</li><li>Scales với available data</li></ul><h3 id="_6-41-2-moco-pre-training" tabindex="-1">6.41.2. MoCo Pre-training <a class="header-anchor" href="#_6-41-2-moco-pre-training" aria-label="Permalink to &quot;6.41.2. MoCo Pre-training&quot;">​</a></h3><p>Momentum Contrast (MoCo) cho remote sensing:</p><p><strong>Method:</strong></p><ul><li>Contrastive learning framework</li><li>Query và key encoders</li><li>Momentum update cho key encoder</li><li>Large negative sample queue</li></ul><p><strong>SSL4EO MoCo Weights:</strong></p><table tabindex="0"><thead><tr><th>Model</th><th>Input</th><th>Weight Name</th></tr></thead><tbody><tr><td>ResNet-18</td><td>Sentinel-2 All Bands</td><td>SENTINEL2_ALL_MOCO</td></tr><tr><td>ResNet-50</td><td>Sentinel-2 All Bands</td><td>SENTINEL2_ALL_MOCO</td></tr><tr><td>ResNet-50</td><td>Sentinel-2 RGB Only</td><td>SENTINEL2_RGB_MOCO</td></tr><tr><td>ResNet-50</td><td>Sentinel-1 All Bands</td><td>SENTINEL1_ALL_MOCO</td></tr></tbody></table><p><strong>Usage:</strong></p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torchgeo.models </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ResNet50_Weights, resnet50</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Load với Sentinel-2 MoCo weights</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ResNet50_Weights.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SENTINEL2_ALL_MOCO</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> resnet50(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">weights</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Access transforms</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">transform </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> weights.transforms()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h3 id="_6-41-3-mae-pre-training" tabindex="-1">6.41.3. MAE Pre-training <a class="header-anchor" href="#_6-41-3-mae-pre-training" aria-label="Permalink to &quot;6.41.3. MAE Pre-training&quot;">​</a></h3><p>Masked Autoencoder pre-training cho Vision Transformers:</p><p><strong>Method:</strong></p><ul><li>Mask random patches of image</li><li>Reconstruct masked patches</li><li>Learns strong representations</li></ul><p><strong>SSL4EO MAE Weights:</strong></p><table tabindex="0"><thead><tr><th>Model</th><th>Input</th><th>Weight Name</th></tr></thead><tbody><tr><td>ViT-Small</td><td>Sentinel-2</td><td>SENTINEL2_ALL_MAE</td></tr><tr><td>ViT-Base</td><td>Sentinel-2</td><td>SENTINEL2_ALL_MAE</td></tr></tbody></table><p><strong>Advantages:</strong></p><ul><li>Excellent cho ViT architectures</li><li>Data-efficient training</li><li>Strong transfer performance</li></ul><h3 id="_6-41-4-dino-pre-training" tabindex="-1">6.41.4. DINO Pre-training <a class="header-anchor" href="#_6-41-4-dino-pre-training" aria-label="Permalink to &quot;6.41.4. DINO Pre-training&quot;">​</a></h3><p>Self-Distillation với No Labels:</p><p><strong>Method:</strong></p><ul><li>Student-teacher framework</li><li>Teacher is momentum-updated student</li><li>Knowledge distillation without labels</li></ul><p><strong>SSL4EO DINO Weights:</strong></p><table tabindex="0"><thead><tr><th>Model</th><th>Input</th><th>Weight Name</th></tr></thead><tbody><tr><td>ViT-Small</td><td>Sentinel-2</td><td>SENTINEL2_ALL_DINO</td></tr><tr><td>ViT-Base</td><td>Sentinel-2</td><td>SENTINEL2_ALL_DINO</td></tr></tbody></table><p><strong>Characteristics:</strong></p><ul><li>Good for ViT models</li><li>Learns semantic features</li><li>Works well on diverse tasks</li></ul><h2 id="_6-42-satmae-weights" tabindex="-1">6.42. SatMAE Weights <a class="header-anchor" href="#_6-42-satmae-weights" aria-label="Permalink to &quot;6.42. SatMAE Weights&quot;">​</a></h2><h3 id="_6-42-1-overview" tabindex="-1">6.42.1. Overview <a class="header-anchor" href="#_6-42-1-overview" aria-label="Permalink to &quot;6.42.1. Overview&quot;">​</a></h3><p>SatMAE (Satellite Masked Autoencoder) specifically designed cho satellite imagery:</p><p><strong>Key Features:</strong></p><ul><li>Temporal encoding cho time series</li><li>Multi-spectral positional embeddings</li><li>Global-scale pre-training</li><li>Designed cho fMoW dataset</li></ul><h3 id="_6-42-2-available-weights" tabindex="-1">6.42.2. Available Weights <a class="header-anchor" href="#_6-42-2-available-weights" aria-label="Permalink to &quot;6.42.2. Available Weights&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Model</th><th>Dataset</th><th>Resolution</th></tr></thead><tbody><tr><td>ViT-Large</td><td>fMoW RGB</td><td>Various</td></tr><tr><td>ViT-Large</td><td>fMoW Temporal</td><td>Multi-date</td></tr></tbody></table><h3 id="_6-42-3-temporal-capabilities" tabindex="-1">6.42.3. Temporal Capabilities <a class="header-anchor" href="#_6-42-3-temporal-capabilities" aria-label="Permalink to &quot;6.42.3. Temporal Capabilities&quot;">​</a></h3><p>SatMAE handles temporal dimension:</p><ul><li>Multiple dates as input</li><li>Temporal position encoding</li><li>Good for change detection và time series</li></ul><h2 id="_6-43-sensor-specific-weights" tabindex="-1">6.43. Sensor-specific Weights <a class="header-anchor" href="#_6-43-sensor-specific-weights" aria-label="Permalink to &quot;6.43. Sensor-specific Weights&quot;">​</a></h2><h3 id="_6-43-1-sentinel-2-weights" tabindex="-1">6.43.1. Sentinel-2 Weights <a class="header-anchor" href="#_6-43-1-sentinel-2-weights" aria-label="Permalink to &quot;6.43.1. Sentinel-2 Weights&quot;">​</a></h3><p><strong>Available Pre-training:</strong></p><ul><li>SSL4EO MoCo (ResNet)</li><li>SSL4EO MAE (ViT)</li><li>SSL4EO DINO (ViT)</li><li>SatMAE (ViT)</li><li>BigEarthNet supervised</li></ul><p><strong>Band Support:</strong></p><ul><li>All 13 bands: Complete spectral information</li><li>RGB only: B4, B3, B2 (10m resolution)</li><li>RGB + NIR: B4, B3, B2, B8</li></ul><p><strong>Usage với All Bands:</strong></p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># ResNet-50 với 13-band Sentinel-2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ResNet50_Weights.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SENTINEL2_ALL_MOCO</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> resnet50(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">weights</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_chans</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">13</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h3 id="_6-43-2-sentinel-1-weights" tabindex="-1">6.43.2. Sentinel-1 Weights <a class="header-anchor" href="#_6-43-2-sentinel-1-weights" aria-label="Permalink to &quot;6.43.2. Sentinel-1 Weights&quot;">​</a></h3><p><strong>Available Pre-training:</strong></p><ul><li>SSL4EO MoCo</li></ul><p><strong>Polarization Support:</strong></p><ul><li>VV + VH: Dual polarization</li><li>Single polarization options</li></ul><p><strong>SAR-specific Considerations:</strong></p><ul><li>Log-scale normalization</li><li>Speckle handling</li><li>Different value distributions than optical</li></ul><p><strong>Usage:</strong></p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># ResNet-50 cho Sentinel-1</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ResNet50_Weights.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SENTINEL1_ALL_MOCO</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> resnet50(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">weights</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_chans</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># VV, VH</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h3 id="_6-43-3-landsat-weights" tabindex="-1">6.43.3. Landsat Weights <a class="header-anchor" href="#_6-43-3-landsat-weights" aria-label="Permalink to &quot;6.43.3. Landsat Weights&quot;">​</a></h3><p><strong>Current Status:</strong></p><ul><li>Fewer dedicated weights than Sentinel</li><li>Can use Sentinel weights với adaptation</li><li>Some benchmark-specific weights</li></ul><p><strong>Approach:</strong></p><ul><li>Use Sentinel-2 weights (similar bands)</li><li>Adapt first layer for Landsat bands</li><li>Fine-tune on Landsat data</li></ul><h3 id="_6-43-4-high-resolution-imagery" tabindex="-1">6.43.4. High-resolution Imagery <a class="header-anchor" href="#_6-43-4-high-resolution-imagery" aria-label="Permalink to &quot;6.43.4. High-resolution Imagery&quot;">​</a></h3><p>For aerial và very-high-resolution satellite:</p><p><strong>Options:</strong></p><ul><li>NAIP-specific training</li><li>ImageNet weights (often sufficient for RGB)</li><li>Million-AID pre-training</li></ul><p><strong>Considerations:</strong></p><ul><li>Usually RGB or RGBIR</li><li>Higher spatial resolution</li><li>Different object scales</li></ul><h2 id="_6-44-weight-comparison-va-selection" tabindex="-1">6.44. Weight Comparison và Selection <a class="header-anchor" href="#_6-44-weight-comparison-va-selection" aria-label="Permalink to &quot;6.44. Weight Comparison và Selection&quot;">​</a></h2><h3 id="_6-44-1-performance-comparison" tabindex="-1">6.44.1. Performance Comparison <a class="header-anchor" href="#_6-44-1-performance-comparison" aria-label="Permalink to &quot;6.44.1. Performance Comparison&quot;">​</a></h3><p><strong>EuroSAT (Sentinel-2 Classification):</strong></p><table tabindex="0"><thead><tr><th>Weights</th><th>ResNet-50 Accuracy</th></tr></thead><tbody><tr><td>Random Init</td><td>89.2%</td></tr><tr><td>ImageNet</td><td>95.5%</td></tr><tr><td>SSL4EO MoCo</td><td>97.2%</td></tr><tr><td>SSL4EO MAE (ViT)</td><td>97.8%</td></tr></tbody></table><p><strong>Key Insight:</strong> Domain-specific pre-training outperforms ImageNet by 1.5-2%.</p><h3 id="_6-44-2-selection-guidelines" tabindex="-1">6.44.2. Selection Guidelines <a class="header-anchor" href="#_6-44-2-selection-guidelines" aria-label="Permalink to &quot;6.44.2. Selection Guidelines&quot;">​</a></h3><p><strong>Sentinel-2 Tasks:</strong></p><ul><li>First choice: SSL4EO MoCo/MAE weights</li><li>Alternative: BigEarthNet pre-trained</li></ul><p><strong>Sentinel-1 Tasks:</strong></p><ul><li>Use: SSL4EO Sentinel-1 weights</li><li>Critical: Match polarization channels</li></ul><p><strong>High-resolution RGB:</strong></p><ul><li>ImageNet weights often sufficient</li><li>Million-AID for aerial specific</li><li>Fine-tuning usually needed</li></ul><p><strong>Multi-sensor:</strong></p><ul><li>Separate encoders với sensor-specific weights</li><li>Fusion at feature level</li></ul><h3 id="_6-44-3-when-to-use-what" tabindex="-1">6.44.3. When to Use What <a class="header-anchor" href="#_6-44-3-when-to-use-what" aria-label="Permalink to &quot;6.44.3. When to Use What&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Scenario</th><th>Recommended Weights</th></tr></thead><tbody><tr><td>Sentinel-2 classification</td><td>SSL4EO MoCo/MAE</td></tr><tr><td>Sentinel-2 segmentation</td><td>SSL4EO MoCo encoder</td></tr><tr><td>Sentinel-1 classification</td><td>SSL4EO S1 MoCo</td></tr><tr><td>SAR ship detection</td><td>SSL4EO S1 or ImageNet</td></tr><tr><td>High-res buildings</td><td>ImageNet or Million-AID</td></tr><tr><td>Temporal analysis</td><td>SatMAE</td></tr></tbody></table><h2 id="_6-45-adapting-weights-cho-different-inputs" tabindex="-1">6.45. Adapting Weights cho Different Inputs <a class="header-anchor" href="#_6-45-adapting-weights-cho-different-inputs" aria-label="Permalink to &quot;6.45. Adapting Weights cho Different Inputs&quot;">​</a></h2><h3 id="_6-45-1-channel-mismatch" tabindex="-1">6.45.1. Channel Mismatch <a class="header-anchor" href="#_6-45-1-channel-mismatch" aria-label="Permalink to &quot;6.45.1. Channel Mismatch&quot;">​</a></h3><p>When input channels differ từ pre-trained weights:</p><p><strong>Fewer Channels:</strong></p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Pre-trained on 13 bands, using 4 (RGBIR)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Option 1: Select matching weights</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> resnet50(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">weights</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Manually select first conv weights for bands</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Option 2: Average redundant channels</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Pre-trained weights: 13 channels</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># New input: 4 channels</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Average groups of weights</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p><strong>More Channels:</strong></p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Pre-trained on 3 (RGB), using 13</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Duplicate và tile RGB weights</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Or initialize extra channels randomly</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p><strong>TorchGeo Approach:</strong> TorchGeo models often handle this automatically với in_chans parameter.</p><h3 id="_6-45-2-resolution-mismatch" tabindex="-1">6.45.2. Resolution Mismatch <a class="header-anchor" href="#_6-45-2-resolution-mismatch" aria-label="Permalink to &quot;6.45.2. Resolution Mismatch&quot;">​</a></h3><p>When spatial resolution differs:</p><p><strong>Interpolation:</strong></p><ul><li>Bilinear resize input to expected resolution</li><li>Or modify patch/window sizes</li></ul><p><strong>Considerations:</strong></p><ul><li>Very different resolutions may need different architectures</li><li>Feature scales may not transfer well</li></ul><h3 id="_6-45-3-value-range-adaptation" tabindex="-1">6.45.3. Value Range Adaptation <a class="header-anchor" href="#_6-45-3-value-range-adaptation" aria-label="Permalink to &quot;6.45.3. Value Range Adaptation&quot;">​</a></h3><p>Different sensors have different value ranges:</p><p><strong>Normalization:</strong></p><ul><li>Use sensor-specific statistics</li><li>Match distribution của pre-training data</li><li>TorchGeo provides normalization stats</li></ul><h2 id="_6-46-fine-tuning-strategies" tabindex="-1">6.46. Fine-tuning Strategies <a class="header-anchor" href="#_6-46-fine-tuning-strategies" aria-label="Permalink to &quot;6.46. Fine-tuning Strategies&quot;">​</a></h2><h3 id="_6-46-1-full-fine-tuning" tabindex="-1">6.46.1. Full Fine-tuning <a class="header-anchor" href="#_6-46-1-full-fine-tuning" aria-label="Permalink to &quot;6.46.1. Full Fine-tuning&quot;">​</a></h3><p>Update all parameters:</p><ul><li>Best when sufficient data available</li><li>Highest performance potential</li><li>Risk of overfitting on small datasets</li></ul><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> resnet50(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">weights</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ssl4eo_weights)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">optimizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Adam(model.parameters(), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">lr</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h3 id="_6-46-2-linear-probing" tabindex="-1">6.46.2. Linear Probing <a class="header-anchor" href="#_6-46-2-linear-probing" aria-label="Permalink to &quot;6.46.2. Linear Probing&quot;">​</a></h3><p>Freeze pre-trained layers, only train classifier:</p><ul><li>Quick baseline</li><li>Tests feature quality</li><li>Works với minimal data</li></ul><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> resnet50(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">weights</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ssl4eo_weights)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Freeze backbone</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> param </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.parameters():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    param.requires_grad </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> False</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Unfreeze classifier</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> param </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.fc.parameters():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    param.requires_grad </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h3 id="_6-46-3-progressive-unfreezing" tabindex="-1">6.46.3. Progressive Unfreezing <a class="header-anchor" href="#_6-46-3-progressive-unfreezing" aria-label="Permalink to &quot;6.46.3. Progressive Unfreezing&quot;">​</a></h3><p>Gradually unfreeze layers:</p><ol><li>Train classifier only</li><li>Unfreeze last block</li><li>Unfreeze more blocks</li><li>Fine-tune entire model</li></ol><p><strong>Benefits:</strong></p><ul><li>Stable training</li><li>Preserves pre-trained features</li><li>Good for limited data</li></ul><h3 id="_6-46-4-layer-wise-learning-rates" tabindex="-1">6.46.4. Layer-wise Learning Rates <a class="header-anchor" href="#_6-46-4-layer-wise-learning-rates" aria-label="Permalink to &quot;6.46.4. Layer-wise Learning Rates&quot;">​</a></h3><p>Different learning rates for different depths:</p><ul><li>Lower LR for early (pre-trained) layers</li><li>Higher LR for later layers và new heads</li></ul><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">optimizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Adam([</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;params&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: model.layer1.parameters(), </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;lr&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;params&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: model.layer2.parameters(), </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;lr&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;params&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: model.layer3.parameters(), </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;lr&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;params&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: model.layer4.parameters(), </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;lr&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;params&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: model.fc.parameters(), </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;lr&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h2 id="_6-47-practical-considerations" tabindex="-1">6.47. Practical Considerations <a class="header-anchor" href="#_6-47-practical-considerations" aria-label="Permalink to &quot;6.47. Practical Considerations&quot;">​</a></h2><h3 id="_6-47-1-memory-va-compute" tabindex="-1">6.47.1. Memory và Compute <a class="header-anchor" href="#_6-47-1-memory-va-compute" aria-label="Permalink to &quot;6.47.1. Memory và Compute&quot;">​</a></h3><p><strong>Model Sizes:</strong></p><table tabindex="0"><thead><tr><th>Model</th><th>Parameters</th><th>Memory (inference)</th></tr></thead><tbody><tr><td>ResNet-18</td><td>11M</td><td>~200MB</td></tr><tr><td>ResNet-50</td><td>25M</td><td>~400MB</td></tr><tr><td>ViT-Base</td><td>86M</td><td>~700MB</td></tr><tr><td>ViT-Large</td><td>307M</td><td>~2.5GB</td></tr></tbody></table><p><strong>Considerations:</strong></p><ul><li>Edge deployment: ResNet-18, MobileNet</li><li>Server deployment: ResNet-50, ViT-Base</li><li>Research: ViT-Large</li></ul><h3 id="_6-47-2-inference-speed" tabindex="-1">6.47.2. Inference Speed <a class="header-anchor" href="#_6-47-2-inference-speed" aria-label="Permalink to &quot;6.47.2. Inference Speed&quot;">​</a></h3><p><strong>Typical FPS (GPU):</strong></p><table tabindex="0"><thead><tr><th>Model</th><th>Input Size</th><th>FPS</th></tr></thead><tbody><tr><td>ResNet-18</td><td>224×224</td><td>~500</td></tr><tr><td>ResNet-50</td><td>224×224</td><td>~200</td></tr><tr><td>ViT-Base</td><td>224×224</td><td>~100</td></tr></tbody></table><p><strong>Considerations:</strong></p><ul><li>Real-time applications: ResNet-18, MobileNet</li><li>Batch processing: ResNet-50, ViT-Base acceptable</li></ul><h3 id="_6-47-3-data-requirements" tabindex="-1">6.47.3. Data Requirements <a class="header-anchor" href="#_6-47-3-data-requirements" aria-label="Permalink to &quot;6.47.3. Data Requirements&quot;">​</a></h3><p><strong>Guidelines:</strong></p><table tabindex="0"><thead><tr><th>Data Amount</th><th>Strategy</th></tr></thead><tbody><tr><td>&lt;100 samples</td><td>Linear probing only</td></tr><tr><td>100-1000</td><td>Progressive unfreezing</td></tr><tr><td>1000-10000</td><td>Full fine-tuning với care</td></tr><tr><td>&gt;10000</td><td>Full fine-tuning</td></tr></tbody></table><p>Pre-trained weights reduce data requirements by 10x or more.</p><h2 id="_6-48-accessing-weights" tabindex="-1">6.48. Accessing Weights <a class="header-anchor" href="#_6-48-accessing-weights" aria-label="Permalink to &quot;6.48. Accessing Weights&quot;">​</a></h2><h3 id="_6-48-1-torchgeo-weight-enum" tabindex="-1">6.48.1. TorchGeo Weight Enum <a class="header-anchor" href="#_6-48-1-torchgeo-weight-enum" aria-label="Permalink to &quot;6.48.1. TorchGeo Weight Enum&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torchgeo.models </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ResNet18_Weights,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ResNet50_Weights,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ViTSmall16_Weights,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># List available weights</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(ResNet50_Weights.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__members__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h3 id="_6-48-2-loading-weights" tabindex="-1">6.48.2. Loading Weights <a class="header-anchor" href="#_6-48-2-loading-weights" aria-label="Permalink to &quot;6.48.2. Loading Weights&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Method 1: Through model factory</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> resnet50(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">weights</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ResNet50_Weights.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SENTINEL2_ALL_MOCO</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Method 2: Load và apply manually</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ResNet50_Weights.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SENTINEL2_ALL_MOCO</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> resnet50()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model.load_state_dict(weights.get_state_dict(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">progress</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Method 3: Custom loading</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">state_dict </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.load(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;path/to/weights.pth&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model.load_state_dict(state_dict)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><h3 id="_6-48-3-weight-metadata" tabindex="-1">6.48.3. Weight Metadata <a class="header-anchor" href="#_6-48-3-weight-metadata" aria-label="Permalink to &quot;6.48.3. Weight Metadata&quot;">​</a></h3><p>Weights include metadata:</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ResNet50_Weights.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SENTINEL2_ALL_MOCO</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Access metadata</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(weights.meta)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># {&#39;bands&#39;: [&#39;B01&#39;, &#39;B02&#39;, ...], &#39;mean&#39;: [...], &#39;std&#39;: [...]}</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Get transforms</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">transform </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> weights.transforms()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h2 id="_6-49-future-directions" tabindex="-1">6.49. Future Directions <a class="header-anchor" href="#_6-49-future-directions" aria-label="Permalink to &quot;6.49. Future Directions&quot;">​</a></h2><h3 id="_6-49-1-more-sensors" tabindex="-1">6.49.1. More Sensors <a class="header-anchor" href="#_6-49-1-more-sensors" aria-label="Permalink to &quot;6.49.1. More Sensors&quot;">​</a></h3><p>Expanding support cho:</p><ul><li>MODIS</li><li>VIIRS</li><li>Pléiades, WorldView</li><li>Commercial SAR (ICEYE, Capella)</li><li>Hyperspectral</li></ul><h3 id="_6-49-2-foundation-models" tabindex="-1">6.49.2. Foundation Models <a class="header-anchor" href="#_6-49-2-foundation-models" aria-label="Permalink to &quot;6.49.2. Foundation Models&quot;">​</a></h3><p>Trend toward large foundation models:</p><ul><li>IBM/NASA Prithvi</li><li>Google/DeepMind Earth models</li><li>Generalist remote sensing models</li></ul><h3 id="_6-49-3-multi-modal-pre-training" tabindex="-1">6.49.3. Multi-modal Pre-training <a class="header-anchor" href="#_6-49-3-multi-modal-pre-training" aria-label="Permalink to &quot;6.49.3. Multi-modal Pre-training&quot;">​</a></h3><p>Joint pre-training on:</p><ul><li>Optical + SAR</li><li>Satellite + text</li><li>Image + location</li></ul><h3 id="_6-49-4-efficient-pre-training" tabindex="-1">6.49.4. Efficient Pre-training <a class="header-anchor" href="#_6-49-4-efficient-pre-training" aria-label="Permalink to &quot;6.49.4. Efficient Pre-training&quot;">​</a></h3><p>Reducing compute requirements:</p><ul><li>Knowledge distillation</li><li>Efficient architectures</li><li>Progressive training</li></ul><h2 id="_6-50-summary-va-recommendations" tabindex="-1">6.50. Summary và Recommendations <a class="header-anchor" href="#_6-50-summary-va-recommendations" aria-label="Permalink to &quot;6.50. Summary và Recommendations&quot;">​</a></h2><h3 id="_6-50-1-quick-start-recommendations" tabindex="-1">6.50.1. Quick Start Recommendations <a class="header-anchor" href="#_6-50-1-quick-start-recommendations" aria-label="Permalink to &quot;6.50.1. Quick Start Recommendations&quot;">​</a></h3><p><strong>Sentinel-2 RGB:</strong></p><ul><li>ResNet-50 + SSL4EO MoCo</li><li>Good balance of performance và efficiency</li></ul><p><strong>Sentinel-2 All Bands:</strong></p><ul><li>ResNet-50 + SSL4EO MoCo (all bands)</li><li>Use all spectral information</li></ul><p><strong>Sentinel-1 SAR:</strong></p><ul><li>ResNet-50 + SSL4EO S1 MoCo</li><li>Essential cho SAR applications</li></ul><p><strong>Vision Transformer:</strong></p><ul><li>ViT-Base + SSL4EO MAE</li><li>Best overall performance</li></ul><h3 id="_6-50-2-best-practices" tabindex="-1">6.50.2. Best Practices <a class="header-anchor" href="#_6-50-2-best-practices" aria-label="Permalink to &quot;6.50.2. Best Practices&quot;">​</a></h3><ol><li><strong>Always use domain-specific weights</strong> when available</li><li><strong>Match input channels</strong> to pre-training</li><li><strong>Use appropriate normalization</strong> statistics</li><li><strong>Start với linear probing</strong> to test</li><li><strong>Progressive unfreezing</strong> for limited data</li><li><strong>Monitor validation metrics</strong> for overfitting</li></ol><h3 id="_6-50-3-common-mistakes" tabindex="-1">6.50.3. Common Mistakes <a class="header-anchor" href="#_6-50-3-common-mistakes" aria-label="Permalink to &quot;6.50.3. Common Mistakes&quot;">​</a></h3><ul><li>Using ImageNet weights without adaptation for multi-spectral</li><li>Ignoring normalization differences</li><li>Full fine-tuning với insufficient data</li><li>Wrong input channel configuration</li><li>Mismatched transforms</li></ul><p>TorchGeo pre-trained weights represent significant advancement cho remote sensing deep learning, enabling practitioners to achieve strong performance với reduced data và compute requirements.</p></div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-e257564d><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><a class="VPLink link pager-link prev" href="/sen_doc/chuong-05-torchgeo/muc-04-change-detection/01-change-detection-models.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Trang trước</span><span class="title" data-v-e257564d>5.4. Change Detection</span><!--]--></a></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/01-dataset.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Trang sau</span><span class="title" data-v-e257564d>Dataset</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5d98c3a5 data-v-e315a0ad><div class="container" data-v-e315a0ad><p class="message" data-v-e315a0ad>Nghiên cứu Ứng dụng Deep Learning trong Viễn thám</p><p class="copyright" data-v-e315a0ad>2024</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"assets_images_xview1_image-sources.md\":\"ckCsuNuZ\",\"assets_images_xview1_readme.md\":\"Dh-ZirnL\",\"assets_images_xview2_download-guide.md\":\"CoBf_73u\",\"assets_images_xview2_image-reference-catalog.md\":\"BygTyrM0\",\"assets_images_xview2_image-sources.md\":\"DuMc8EPf\",\"assets_images_xview2_readme.md\":\"BxXava9o\",\"assets_images_xview3_image-sources.md\":\"BniOX9bd\",\"chuong-01-gioi-thieu_muc-01-tong-quan_01-gioi-thieu-cnn-deep-learning.md\":\"Bd-Fbg20\",\"chuong-02-co-so-ly-thuyet_muc-01-kien-truc-cnn_01-kien-truc-co-ban.md\":\"JTkuWTE-\",\"chuong-02-co-so-ly-thuyet_muc-01-kien-truc-cnn_02-backbone-networks.md\":\"BlX0yEKA\",\"chuong-02-co-so-ly-thuyet_muc-02-phuong-phap-xu-ly-anh_01-phan-loai-anh.md\":\"DETt3o-M\",\"chuong-02-co-so-ly-thuyet_muc-02-phuong-phap-xu-ly-anh_02-phat-hien-doi-tuong.md\":\"GmKUOhbb\",\"chuong-02-co-so-ly-thuyet_muc-02-phuong-phap-xu-ly-anh_03-phan-doan-ngu-nghia.md\":\"CcH_kyR9\",\"chuong-02-co-so-ly-thuyet_muc-02-phuong-phap-xu-ly-anh_04-instance-segmentation.md\":\"TtJykzVA\",\"chuong-03-phat-hien-tau-bien_muc-01-dac-diem-bai-toan_01-dac-diem.md\":\"C0Yxv2n_\",\"chuong-03-phat-hien-tau-bien_muc-02-mo-hinh_01-cac-mo-hinh.md\":\"DGRPnXI5\",\"chuong-03-phat-hien-tau-bien_muc-03-quy-trinh_01-pipeline.md\":\"CyQavZag\",\"chuong-03-phat-hien-tau-bien_muc-04-bo-du-lieu_01-datasets.md\":\"B-r7bzJa\",\"chuong-04-phat-hien-dau-loang_muc-01-dac-diem-bai-toan_01-dac-diem.md\":\"DoL0XU6F\",\"chuong-04-phat-hien-dau-loang_muc-02-mo-hinh_01-cac-mo-hinh.md\":\"BDt_W34a\",\"chuong-04-phat-hien-dau-loang_muc-03-quy-trinh_01-pipeline.md\":\"CFhAxDR2\",\"chuong-04-phat-hien-dau-loang_muc-04-bo-du-lieu_01-datasets.md\":\"B0YdiGB0\",\"chuong-05-torchgeo_muc-01-tong-quan_01-tong-quan.md\":\"BoDJs4WI\",\"chuong-05-torchgeo_muc-02-classification_01-classification-models.md\":\"CzG4Fvsd\",\"chuong-05-torchgeo_muc-03-segmentation_01-segmentation-models.md\":\"BI9c1b3a\",\"chuong-05-torchgeo_muc-04-change-detection_01-change-detection-models.md\":\"AY_JAMod\",\"chuong-05-torchgeo_muc-05-pretrained-weights_01-pretrained-weights.md\":\"BuNGhnCB\",\"chuong-06-xview-challenges_muc-01-xview1-object-detection_01-dataset.md\":\"Dm7BptPM\",\"chuong-06-xview-challenges_muc-01-xview1-object-detection_02-giai-nhat.md\":\"2wV3PEsV\",\"chuong-06-xview-challenges_muc-01-xview1-object-detection_03-giai-nhi.md\":\"BufeTIgD\",\"chuong-06-xview-challenges_muc-01-xview1-object-detection_04-giai-ba.md\":\"BB8ENdVV\",\"chuong-06-xview-challenges_muc-01-xview1-object-detection_05-giai-tu.md\":\"BeVPeWzd\",\"chuong-06-xview-challenges_muc-01-xview1-object-detection_06-giai-nam.md\":\"BODlexDn\",\"chuong-06-xview-challenges_muc-02-xview2-building-damage_01-dataset.md\":\"D4Zdh38-\",\"chuong-06-xview-challenges_muc-02-xview2-building-damage_02-giai-nhat.md\":\"DmTBWgjK\",\"chuong-06-xview-challenges_muc-02-xview2-building-damage_03-giai-nhi.md\":\"BW-aVCBj\",\"chuong-06-xview-challenges_muc-02-xview2-building-damage_04-giai-ba.md\":\"C82xwoJR\",\"chuong-06-xview-challenges_muc-02-xview2-building-damage_05-giai-tu.md\":\"_cJqRaka\",\"chuong-06-xview-challenges_muc-02-xview2-building-damage_06-giai-nam.md\":\"B4Yzptuh\",\"chuong-06-xview-challenges_muc-03-xview3-maritime_01-dataset.md\":\"DteeNegR\",\"chuong-06-xview-challenges_muc-03-xview3-maritime_02-giai-nhat.md\":\"DNNZ5ArH\",\"chuong-06-xview-challenges_muc-03-xview3-maritime_03-giai-nhi.md\":\"DXfAO9PE\",\"chuong-06-xview-challenges_muc-03-xview3-maritime_04-giai-ba.md\":\"B_Gh3WW0\",\"chuong-06-xview-challenges_muc-03-xview3-maritime_05-giai-tu.md\":\"CSu3Wob_\",\"chuong-06-xview-challenges_muc-03-xview3-maritime_06-giai-nam.md\":\"YgGqePJH\",\"chuong-07-ket-luan_muc-01-tong-ket_01-ket-luan.md\":\"CnvNs1AJ\",\"index.md\":\"I4CP-rxb\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"vi-VN\",\"dir\":\"ltr\",\"title\":\"Deep Learning trong Viễn thám\",\"description\":\"Nghiên cứu ứng dụng CNN và Deep Learning trong phân tích ảnh viễn thám\",\"base\":\"/sen_doc/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"Trang chủ\",\"link\":\"/\"},{\"text\":\"Giới thiệu\",\"link\":\"/chuong-01-gioi-thieu/muc-01-tong-quan/01-gioi-thieu-cnn-deep-learning\"},{\"text\":\"TorchGeo\",\"link\":\"/chuong-05-torchgeo/muc-01-tong-quan/01-tong-quan\"},{\"text\":\"xView\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/01-dataset\"}],\"sidebar\":[{\"text\":\"Chương 1: Giới thiệu\",\"collapsed\":false,\"items\":[{\"text\":\"1.1. Tổng quan CNN & Deep Learning\",\"link\":\"/chuong-01-gioi-thieu/muc-01-tong-quan/01-gioi-thieu-cnn-deep-learning\"}]},{\"text\":\"Chương 2: Cơ sở lý thuyết\",\"collapsed\":false,\"items\":[{\"text\":\"2.1.1. Kiến trúc CNN cơ bản\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-01-kien-truc-cnn/01-kien-truc-co-ban\"},{\"text\":\"2.1.2. Backbone Networks\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-01-kien-truc-cnn/02-backbone-networks\"},{\"text\":\"2.2.1. Phân loại ảnh\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/01-phan-loai-anh\"},{\"text\":\"2.2.2. Phát hiện đối tượng\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/02-phat-hien-doi-tuong\"},{\"text\":\"2.2.3. Phân đoạn ngữ nghĩa\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/03-phan-doan-ngu-nghia\"},{\"text\":\"2.2.4. Instance Segmentation\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/04-instance-segmentation\"}]},{\"text\":\"Chương 3: Phát hiện tàu biển\",\"collapsed\":true,\"items\":[{\"text\":\"3.1. Đặc điểm bài toán\",\"link\":\"/chuong-03-phat-hien-tau-bien/muc-01-dac-diem-bai-toan/01-dac-diem\"},{\"text\":\"3.2. Các mô hình\",\"link\":\"/chuong-03-phat-hien-tau-bien/muc-02-mo-hinh/01-cac-mo-hinh\"},{\"text\":\"3.3. Quy trình pipeline\",\"link\":\"/chuong-03-phat-hien-tau-bien/muc-03-quy-trinh/01-pipeline\"},{\"text\":\"3.4. Bộ dữ liệu\",\"link\":\"/chuong-03-phat-hien-tau-bien/muc-04-bo-du-lieu/01-datasets\"}]},{\"text\":\"Chương 4: Phát hiện dầu loang\",\"collapsed\":true,\"items\":[{\"text\":\"4.1. Đặc điểm bài toán\",\"link\":\"/chuong-04-phat-hien-dau-loang/muc-01-dac-diem-bai-toan/01-dac-diem\"},{\"text\":\"4.2. Các mô hình\",\"link\":\"/chuong-04-phat-hien-dau-loang/muc-02-mo-hinh/01-cac-mo-hinh\"},{\"text\":\"4.3. Quy trình pipeline\",\"link\":\"/chuong-04-phat-hien-dau-loang/muc-03-quy-trinh/01-pipeline\"},{\"text\":\"4.4. Bộ dữ liệu\",\"link\":\"/chuong-04-phat-hien-dau-loang/muc-04-bo-du-lieu/01-datasets\"}]},{\"text\":\"Chương 5: TorchGeo\",\"collapsed\":true,\"items\":[{\"text\":\"5.1. Tổng quan\",\"link\":\"/chuong-05-torchgeo/muc-01-tong-quan/01-tong-quan\"},{\"text\":\"5.2. Classification Models\",\"link\":\"/chuong-05-torchgeo/muc-02-classification/01-classification-models\"},{\"text\":\"5.3. Segmentation Models\",\"link\":\"/chuong-05-torchgeo/muc-03-segmentation/01-segmentation-models\"},{\"text\":\"5.4. Change Detection\",\"link\":\"/chuong-05-torchgeo/muc-04-change-detection/01-change-detection-models\"},{\"text\":\"5.5. Pre-trained Weights\",\"link\":\"/chuong-05-torchgeo/muc-05-pretrained-weights/01-pretrained-weights\"}]},{\"text\":\"Chương 6: xView Challenges\",\"collapsed\":false,\"items\":[{\"text\":\"6.1. xView1 - Object Detection\",\"collapsed\":true,\"items\":[{\"text\":\"Dataset\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/01-dataset\"},{\"text\":\"Giải nhất\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/02-giai-nhat\"},{\"text\":\"Giải nhì\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/03-giai-nhi\"},{\"text\":\"Giải ba\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/04-giai-ba\"},{\"text\":\"Giải tư\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/05-giai-tu\"},{\"text\":\"Giải năm\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/06-giai-nam\"}]},{\"text\":\"6.2. xView2 - Building Damage\",\"collapsed\":true,\"items\":[{\"text\":\"Dataset (xBD)\",\"link\":\"/chuong-06-xview-challenges/muc-02-xview2-building-damage/01-dataset\"},{\"text\":\"Giải nhất\",\"link\":\"/chuong-06-xview-challenges/muc-02-xview2-building-damage/02-giai-nhat\"},{\"text\":\"Giải nhì\",\"link\":\"/chuong-06-xview-challenges/muc-02-xview2-building-damage/03-giai-nhi\"},{\"text\":\"Giải ba\",\"link\":\"/chuong-06-xview-challenges/muc-02-xview2-building-damage/04-giai-ba\"},{\"text\":\"Giải tư\",\"link\":\"/chuong-06-xview-challenges/muc-02-xview2-building-damage/05-giai-tu\"},{\"text\":\"Giải năm\",\"link\":\"/chuong-06-xview-challenges/muc-02-xview2-building-damage/06-giai-nam\"}]},{\"text\":\"6.3. xView3 - Maritime (SAR)\",\"collapsed\":true,\"items\":[{\"text\":\"Dataset\",\"link\":\"/chuong-06-xview-challenges/muc-03-xview3-maritime/01-dataset\"},{\"text\":\"Giải nhất\",\"link\":\"/chuong-06-xview-challenges/muc-03-xview3-maritime/02-giai-nhat\"},{\"text\":\"Giải nhì\",\"link\":\"/chuong-06-xview-challenges/muc-03-xview3-maritime/03-giai-nhi\"},{\"text\":\"Giải ba\",\"link\":\"/chuong-06-xview-challenges/muc-03-xview3-maritime/04-giai-ba\"},{\"text\":\"Giải tư\",\"link\":\"/chuong-06-xview-challenges/muc-03-xview3-maritime/05-giai-tu\"},{\"text\":\"Giải năm\",\"link\":\"/chuong-06-xview-challenges/muc-03-xview3-maritime/06-giai-nam\"}]}]},{\"text\":\"Chương 7: Kết luận\",\"collapsed\":false,\"items\":[{\"text\":\"7.1. Tổng kết\",\"link\":\"/chuong-07-ket-luan/muc-01-tong-ket/01-ket-luan\"}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/tchatb/sen_doc\"}],\"search\":{\"provider\":\"local\"},\"outline\":{\"level\":[2,3],\"label\":\"Mục lục trang\"},\"footer\":{\"message\":\"Nghiên cứu Ứng dụng Deep Learning trong Viễn thám\",\"copyright\":\"2024\"},\"docFooter\":{\"prev\":\"Trang trước\",\"next\":\"Trang sau\"},\"lastUpdated\":{\"text\":\"Cập nhật lần cuối\"},\"returnToTopLabel\":\"Về đầu trang\",\"sidebarMenuLabel\":\"Menu\",\"darkModeSwitchLabel\":\"Giao diện\"},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>