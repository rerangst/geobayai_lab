<!DOCTYPE html>
<html lang="vi-VN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Chương 1: Giới thiệu về Convolutional Neural Network và Deep Learning trong Viễn thám | Deep Learning trong Viễn thám</title>
    <meta name="description" content="Nghiên cứu ứng dụng CNN và Deep Learning trong phân tích ảnh viễn thám">
    <meta name="generator" content="VitePress v1.6.4">
    <link rel="preload stylesheet" href="/sen_doc/assets/style.W3JISx3E.css" as="style">
    <link rel="preload stylesheet" href="/sen_doc/vp-icons.css" as="style">
    
    <script type="module" src="/sen_doc/assets/app.CWSbRAFv.js"></script>
    <link rel="preload" href="/sen_doc/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/framework.nRfFlDZQ.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/theme.Ch0spFQA.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/katex.Cu_Erd72.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/dagre-6UL2VRFP.BQ5r6kFc.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/cose-bilkent-S5V4N54A.Cg2D0hX4.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/c4Diagram-YG6GDRKO.Ch1Z5DYy.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/flowDiagram-NV44I4VS.B-M56PNY.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/erDiagram-Q2GNP2WA.ChNEjQqf.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/gitGraphDiagram-NY62KEGX.CYjbWr1H.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/ganttDiagram-JELNMOA3.BuFF-7gm.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/infoDiagram-WHAUD3N6.DXhWiX-4.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/pieDiagram-ADFJNKIX.CEooP7iW.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/quadrantDiagram-AYHSOK5B.BxpFNOre.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/xychartDiagram-PRI3JC2R.D7l7DTkm.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/requirementDiagram-UZGBJVZJ.CnZWdBnS.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/sequenceDiagram-WL72ISMW.Dq5DiI5R.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/classDiagram-2ON5EDUG.C-uTH9t6.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/classDiagram-v2-WZHVMYZB.C-uTH9t6.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/stateDiagram-FKZM4ZOC.DA69JNoS.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/stateDiagram-v2-4FDKWEC3.CvG5pOcG.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/journeyDiagram-XKPGCS4Q.B6_zk-Uc.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/timeline-definition-IT6M3QCI.Bq-srREc.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/mindmap-definition-VGOIOE7T.C1lO0ZZX.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/kanban-definition-3W4ZIXB7.D1R1ZtJ4.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/sankeyDiagram-TZEHDZUN.3FvNQ0V-.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/diagram-S2PKOQOG.CN4gAtio.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/diagram-QEK2KX5R.BgEYpliI.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/blockDiagram-VD42YOAC.CblIZ9TF.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/architectureDiagram-VXUJARFQ.D58rp7Xd.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/diagram-PSM6KHXK.55LfW1Pd.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/virtual_mermaid-config.CQTEIV6y.js">
    <link rel="modulepreload" href="/sen_doc/assets/chuong-01-gioi-thieu_muc-01-tong-quan_01-gioi-thieu-cnn-deep-learning.md.Bd-Fbg20.lean.js">
    <meta name="theme-color" content="#3eaf7c">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5d98c3a5><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0b0ada53></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0b0ada53>Skip to content</a><!--]--><!----><header class="VPNav" data-v-5d98c3a5 data-v-ae24b3ad><div class="VPNavBar" data-v-ae24b3ad data-v-6aa21345><div class="wrapper" data-v-6aa21345><div class="container" data-v-6aa21345><div class="title" data-v-6aa21345><div class="VPNavBarTitle has-sidebar" data-v-6aa21345 data-v-1168a8e4><a class="title" href="/sen_doc/" data-v-1168a8e4><!--[--><!--]--><!----><span data-v-1168a8e4>Deep Learning trong Viễn thám</span><!--[--><!--]--></a></div></div><div class="content" data-v-6aa21345><div class="content-body" data-v-6aa21345><!--[--><!--]--><div class="VPNavBarSearch search" data-v-6aa21345><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-6aa21345 data-v-dc692963><span id="main-nav-aria-label" class="visually-hidden" data-v-dc692963> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/sen_doc/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Trang chủ</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink active" href="/sen_doc/chuong-01-gioi-thieu/muc-01-tong-quan/01-gioi-thieu-cnn-deep-learning.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Giới thiệu</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/sen_doc/chuong-05-torchgeo/muc-01-tong-quan/01-tong-quan.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>TorchGeo</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/01-dataset.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>xView</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-6aa21345 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-6aa21345 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/tchatb/sen_doc" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-6aa21345 data-v-bb2aa2f0 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-cf11d7a2><span class="vpi-more-horizontal icon" data-v-cf11d7a2></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><!----><!--[--><!--[--><!----><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>Giao diện</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/tchatb/sen_doc" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-6aa21345 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-6aa21345><div class="divider-line" data-v-6aa21345></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-5d98c3a5 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-8a42e2b4><button data-v-8a42e2b4>Về đầu trang</button><!----></div></div></div><aside class="VPSidebar" data-v-5d98c3a5 data-v-319d5ca6><div class="curtain" data-v-319d5ca6></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-319d5ca6><span class="visually-hidden" id="sidebar-aria-label" data-v-319d5ca6> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible has-active" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 1: Giới thiệu</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-01-gioi-thieu/muc-01-tong-quan/01-gioi-thieu-cnn-deep-learning.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>1.1. Tổng quan CNN & Deep Learning</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 2: Cơ sở lý thuyết</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-01-kien-truc-cnn/01-kien-truc-co-ban.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.1.1. Kiến trúc CNN cơ bản</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-01-kien-truc-cnn/02-backbone-networks.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.1.2. Backbone Networks</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/01-phan-loai-anh.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.2.1. Phân loại ảnh</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/02-phat-hien-doi-tuong.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.2.2. Phát hiện đối tượng</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/03-phan-doan-ngu-nghia.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.2.3. Phân đoạn ngữ nghĩa</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/04-instance-segmentation.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.2.4. Instance Segmentation</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible collapsed" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 3: Phát hiện tàu biển</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-03-phat-hien-tau-bien/muc-01-dac-diem-bai-toan/01-dac-diem.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>3.1. Đặc điểm bài toán</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-03-phat-hien-tau-bien/muc-02-mo-hinh/01-cac-mo-hinh.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>3.2. Các mô hình</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-03-phat-hien-tau-bien/muc-03-quy-trinh/01-pipeline.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>3.3. Quy trình pipeline</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-03-phat-hien-tau-bien/muc-04-bo-du-lieu/01-datasets.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>3.4. Bộ dữ liệu</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible collapsed" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 4: Phát hiện dầu loang</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-phat-hien-dau-loang/muc-01-dac-diem-bai-toan/01-dac-diem.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>4.1. Đặc điểm bài toán</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-phat-hien-dau-loang/muc-02-mo-hinh/01-cac-mo-hinh.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>4.2. Các mô hình</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-phat-hien-dau-loang/muc-03-quy-trinh/01-pipeline.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>4.3. Quy trình pipeline</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-phat-hien-dau-loang/muc-04-bo-du-lieu/01-datasets.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>4.4. Bộ dữ liệu</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible collapsed" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 5: TorchGeo</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-torchgeo/muc-01-tong-quan/01-tong-quan.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.1. Tổng quan</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-torchgeo/muc-02-classification/01-classification-models.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.2. Classification Models</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-torchgeo/muc-03-segmentation/01-segmentation-models.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.3. Segmentation Models</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-torchgeo/muc-04-change-detection/01-change-detection-models.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.4. Change Detection</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-torchgeo/muc-05-pretrained-weights/01-pretrained-weights.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.5. Pre-trained Weights</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 6: xView Challenges</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><section class="VPSidebarItem level-1 collapsible collapsed" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h3 class="text" data-v-b3fd67f8>6.1. xView1 - Object Detection</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/01-dataset.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/02-giai-nhat.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhất</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/03-giai-nhi.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhì</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/04-giai-ba.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải ba</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/05-giai-tu.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải tư</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/06-giai-nam.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải năm</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible collapsed" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h3 class="text" data-v-b3fd67f8>6.2. xView2 - Building Damage</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-02-xview2-building-damage/01-dataset.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Dataset (xBD)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-02-xview2-building-damage/02-giai-nhat.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhất</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-02-xview2-building-damage/03-giai-nhi.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhì</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-02-xview2-building-damage/04-giai-ba.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải ba</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-02-xview2-building-damage/05-giai-tu.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải tư</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-02-xview2-building-damage/06-giai-nam.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải năm</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible collapsed" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h3 class="text" data-v-b3fd67f8>6.3. xView3 - Maritime (SAR)</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-03-xview3-maritime/01-dataset.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-03-xview3-maritime/02-giai-nhat.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhất</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-03-xview3-maritime/03-giai-nhi.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhì</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-03-xview3-maritime/04-giai-ba.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải ba</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-03-xview3-maritime/05-giai-tu.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải tư</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-03-xview3-maritime/06-giai-nam.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải năm</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 7: Kết luận</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-07-ket-luan/muc-01-tong-ket/01-ket-luan.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>7.1. Tổng kết</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5d98c3a5 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-a5bbad30><div class="content" data-v-a5bbad30><div class="outline-marker" data-v-a5bbad30></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a5bbad30>Mục lục trang</div><ul class="VPDocOutlineItem root" data-v-a5bbad30 data-v-b933a997><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _sen_doc_chuong-01-gioi-thieu_muc-01-tong-quan_01-gioi-thieu-cnn-deep-learning" data-v-39a288b8><div><h1 id="chuong-1-gioi-thieu-ve-convolutional-neural-network-va-deep-learning-trong-vien-tham" tabindex="-1">Chương 1: Giới thiệu về Convolutional Neural Network và Deep Learning trong Viễn thám <a class="header-anchor" href="#chuong-1-gioi-thieu-ve-convolutional-neural-network-va-deep-learning-trong-vien-tham" aria-label="Permalink to &quot;Chương 1: Giới thiệu về Convolutional Neural Network và Deep Learning trong Viễn thám&quot;">​</a></h1><h2 id="_1-1-boi-canh-va-tam-quan-trong" tabindex="-1">1.1. Bối cảnh và Tầm quan trọng <a class="header-anchor" href="#_1-1-boi-canh-va-tam-quan-trong" aria-label="Permalink to &quot;1.1. Bối cảnh và Tầm quan trọng&quot;">​</a></h2><p>Trong những thập kỷ gần đây, sự phát triển vượt bậc của công nghệ vệ tinh quan sát Trái Đất đã mở ra một kỷ nguyên mới trong lĩnh vực viễn thám. Các vệ tinh quan sát như Sentinel-1, Sentinel-2 của Cơ quan Vũ trụ Châu Âu (ESA), WorldView-3 của Maxar Technologies, hay Planet Labs với hệ thống vệ tinh nhỏ quy mô lớn, liên tục thu thập hàng petabyte dữ liệu ảnh mỗi ngày. Khối lượng dữ liệu khổng lồ này đặt ra thách thức lớn trong việc phân tích và trích xuất thông tin hữu ích một cách tự động và hiệu quả.</p><p>Trước đây, các phương pháp xử lý ảnh viễn thám truyền thống chủ yếu dựa vào việc trích xuất đặc trưng thủ công (handcrafted features) kết hợp với các bộ phân loại cổ điển như Support Vector Machine (SVM), Random Forest, hay các thuật toán threshold đơn giản. Tuy nhiên, những phương pháp này bộc lộ nhiều hạn chế khi đối mặt với sự đa dạng và phức tạp của dữ liệu ảnh vệ tinh thực tế. Các đặc trưng được thiết kế thủ công thường khó có thể tổng quát hóa tốt trên nhiều loại cảnh quan, điều kiện thời tiết, hay góc chụp khác nhau.</p><p>Sự ra đời và phát triển mạnh mẽ của Deep Learning, đặc biệt là mạng Convolutional Neural Network (CNN), đã tạo ra bước đột phá quan trọng trong việc giải quyết các bài toán xử lý ảnh viễn thám. Khác với các phương pháp truyền thống, CNN có khả năng tự động học và trích xuất các đặc trưng phân cấp từ dữ liệu thô, từ các đặc trưng cấp thấp như cạnh (edge), góc (corner), đến các đặc trưng cấp cao như hình dạng đối tượng, mối quan hệ không gian. Khả năng học biểu diễn end-to-end này cho phép CNN đạt được hiệu suất vượt trội so với các phương pháp truyền thống trong hầu hết các bài toán xử lý ảnh viễn thám.</p><p>Trong bối cảnh an ninh hàng hải và bảo vệ môi trường biển, hai bài toán quan trọng được đặc biệt quan tâm là phát hiện tàu biển (Ship Detection) và nhận dạng vết dầu loang (Oil Spill Detection). Phát hiện tàu biển đóng vai trò then chốt trong việc giám sát hoạt động hàng hải, phát hiện tàu đánh cá bất hợp pháp (Illegal, Unreported, and Unregulated fishing - IUU), và đảm bảo an ninh vùng biển. Trong khi đó, nhận dạng vết dầu loang là nhiệm vụ thiết yếu để phát hiện sớm các sự cố tràn dầu, hỗ trợ ứng phó kịp thời và giảm thiểu tác động đến môi trường sinh thái biển.</p><h2 id="_1-2-convolutional-neural-network-la-gi" tabindex="-1">1.2. Convolutional Neural Network là gì? <a class="header-anchor" href="#_1-2-convolutional-neural-network-la-gi" aria-label="Permalink to &quot;1.2. Convolutional Neural Network là gì?&quot;">​</a></h2><p>Convolutional Neural Network, thường được viết tắt là CNN hoặc ConvNet, là một lớp kiến trúc mạng nơ-ron sâu (Deep Neural Network) được thiết kế đặc biệt để xử lý dữ liệu có cấu trúc lưới (grid-like topology), điển hình nhất là dữ liệu ảnh hai chiều. Tên gọi &quot;Convolutional&quot; xuất phát từ phép toán tích chập (convolution) được sử dụng làm thao tác xử lý chính trong mạng, thay thế cho phép nhân ma trận thông thường trong ít nhất một lớp của mạng.</p><p>Ý tưởng cốt lõi của CNN được lấy cảm hứng từ cơ chế hoạt động của vỏ não thị giác (visual cortex) trong não động vật có vú. Các nghiên cứu sinh học thần kinh của Hubel và Wiesel vào những năm 1960 đã chỉ ra rằng các tế bào thần kinh trong vỏ não thị giác phản ứng với các kích thích trong vùng thị giác giới hạn, gọi là receptive field. Các receptive field của các tế bào khác nhau chồng chéo lên nhau một phần để bao phủ toàn bộ trường thị giác. CNN mô phỏng cơ chế này bằng cách sử dụng các bộ lọc (filter hay kernel) có kích thước nhỏ quét qua toàn bộ ảnh đầu vào.</p><p>Điểm khác biệt quan trọng giữa CNN và mạng nơ-ron truyền thống fully connected là ba tính chất kiến trúc đặc trưng: kết nối cục bộ (local connectivity), chia sẻ trọng số (weight sharing), và pooling. Trong mạng fully connected, mỗi nơ-ron ở lớp sau được kết nối với tất cả các nơ-ron ở lớp trước, dẫn đến số lượng tham số rất lớn và dễ bị overfitting. Ngược lại, trong CNN, mỗi nơ-ron chỉ kết nối với một vùng nhỏ của lớp trước (receptive field cục bộ), và các trọng số kết nối được chia sẻ trên toàn bộ ảnh. Điều này không chỉ giảm đáng kể số lượng tham số mà còn cho phép mạng học được các đặc trưng bất biến với vị trí (translation invariant).</p><h2 id="_1-3-lich-su-phat-trien-cua-cnn" tabindex="-1">1.3. Lịch sử Phát triển của CNN <a class="header-anchor" href="#_1-3-lich-su-phat-trien-cua-cnn" aria-label="Permalink to &quot;1.3. Lịch sử Phát triển của CNN&quot;">​</a></h2><h3 id="_1-3-1-giai-đoan-khoi-đau-lenet-1989-1998" tabindex="-1">1.3.1. Giai đoạn Khởi đầu: LeNet (1989-1998) <a class="header-anchor" href="#_1-3-1-giai-đoan-khoi-đau-lenet-1989-1998" aria-label="Permalink to &quot;1.3.1. Giai đoạn Khởi đầu: LeNet (1989-1998)&quot;">​</a></h3><p>Lịch sử của CNN bắt đầu từ những năm cuối thập niên 1980 với công trình tiên phong của Yann LeCun và cộng sự tại AT&amp;T Bell Labs. Năm 1989, LeCun lần đầu tiên áp dụng thành công thuật toán backpropagation để huấn luyện mạng nơ-ron tích chập nhận dạng chữ số viết tay. Đến năm 1998, kiến trúc LeNet-5 được công bố, trở thành một trong những CNN hoàn chỉnh đầu tiên được triển khai trong thực tế để đọc mã ZIP trên thư tín tại Hoa Kỳ.</p><p>LeNet-5 có kiến trúc gồm 7 lớp (không kể đầu vào): 3 lớp convolution, 2 lớp subsampling (tương tự pooling), và 2 lớp fully connected. Mặc dù quy mô nhỏ theo tiêu chuẩn hiện đại, LeNet-5 đã thiết lập nền tảng kiến trúc cơ bản cho các CNN sau này: xen kẽ giữa các lớp convolution và pooling, sau đó kết nối với các lớp fully connected để thực hiện phân loại cuối cùng.</p><h3 id="_1-3-2-thoi-ky-tram-lang-1998-2012" tabindex="-1">1.3.2. Thời kỳ Trầm lắng (1998-2012) <a class="header-anchor" href="#_1-3-2-thoi-ky-tram-lang-1998-2012" aria-label="Permalink to &quot;1.3.2. Thời kỳ Trầm lắng (1998-2012)&quot;">​</a></h3><p>Sau thành công ban đầu của LeNet, nghiên cứu về mạng nơ-ron nói chung và CNN nói riêng trải qua giai đoạn trầm lắng kéo dài gần 15 năm. Nguyên nhân chính bao gồm: hạn chế về năng lực tính toán của phần cứng thời bấy giờ, thiếu các tập dữ liệu quy mô lớn để huấn luyện, và sự thống trị của các phương pháp học máy khác như SVM và boosting vốn cho kết quả tốt với chi phí tính toán thấp hơn.</p><p>Trong giai đoạn này, các phương pháp dựa trên đặc trưng thủ công như SIFT (Scale-Invariant Feature Transform), HOG (Histogram of Oriented Gradients), và các biến thể của chúng chiếm ưu thế trong các bài toán thị giác máy tính. Đối với xử lý ảnh viễn thám, các kỹ thuật truyền thống như phân loại dựa trên chỉ số phổ, phân tích kết cấu (texture analysis), và phân đoạn dựa trên ngưỡng vẫn là những phương pháp chính được sử dụng.</p><h3 id="_1-3-3-buoc-ngoat-alexnet-2012" tabindex="-1">1.3.3. Bước Ngoặt AlexNet (2012) <a class="header-anchor" href="#_1-3-3-buoc-ngoat-alexnet-2012" aria-label="Permalink to &quot;1.3.3. Bước Ngoặt AlexNet (2012)&quot;">​</a></h3><p>Năm 2012 đánh dấu bước ngoặt lịch sử của Deep Learning khi Alex Krizhevsky, Ilya Sutskever và Geoffrey Hinton giành chiến thắng áp đảo trong cuộc thi ImageNet Large Scale Visual Recognition Challenge (ILSVRC). Mạng AlexNet của họ đạt top-5 error rate 15.3%, vượt xa đáng kể so với phương pháp xếp thứ hai với 26.2%. Khoảng cách vượt trội này đã gây chấn động cộng đồng nghiên cứu và khởi đầu kỷ nguyên Deep Learning hiện đại.</p><p>AlexNet có kiến trúc sâu hơn đáng kể so với LeNet với 8 lớp học được (5 lớp convolution và 3 lớp fully connected), sử dụng hàm kích hoạt ReLU thay cho sigmoid/tanh, áp dụng kỹ thuật Dropout để chống overfitting, và được huấn luyện trên GPU - một bước tiến quan trọng về mặt kỹ thuật. Thành công của AlexNet chứng minh rằng với đủ dữ liệu và năng lực tính toán, các mạng nơ-ron sâu có thể học được các biểu diễn đặc trưng mạnh mẽ hơn nhiều so với các đặc trưng thiết kế thủ công.</p><h3 id="_1-3-4-ky-nguyen-mang-rat-sau-vggnet-va-resnet-2014-2015" tabindex="-1">1.3.4. Kỷ nguyên Mạng Rất Sâu: VGGNet và ResNet (2014-2015) <a class="header-anchor" href="#_1-3-4-ky-nguyen-mang-rat-sau-vggnet-va-resnet-2014-2015" aria-label="Permalink to &quot;1.3.4. Kỷ nguyên Mạng Rất Sâu: VGGNet và ResNet (2014-2015)&quot;">​</a></h3><p>Sau AlexNet, xu hướng chính trong nghiên cứu CNN là tăng độ sâu của mạng. Năm 2014, nhóm Visual Geometry Group tại Đại học Oxford giới thiệu VGGNet với kiến trúc sử dụng các bộ lọc convolution nhỏ 3×3 xếp chồng lên nhau. VGG-16 và VGG-19 với 16 và 19 lớp học được đạt kết quả ấn tượng trên ImageNet, đồng thời chứng minh rằng độ sâu của mạng là yếu tố quan trọng quyết định hiệu suất.</p><p>Tuy nhiên, việc tăng độ sâu mạng gặp phải vấn đề nghiêm trọng: gradient vanishing và gradient exploding trong quá trình backpropagation, khiến việc huấn luyện các mạng rất sâu trở nên khó khăn hoặc không thể. Năm 2015, Kaiming He và cộng sự tại Microsoft Research đề xuất kiến trúc Residual Network (ResNet) với ý tưởng đột phá: thêm các kết nối tắt (skip connection hay shortcut connection) cho phép gradient chảy trực tiếp qua nhiều lớp. Với kỹ thuật này, ResNet có thể huấn luyện thành công các mạng với hàng trăm thậm chí hàng nghìn lớp. ResNet-152 đạt top-5 error rate 3.57% trên ImageNet, lần đầu tiên vượt qua ngưỡng nhận dạng của con người (khoảng 5%).</p><h3 id="_1-3-5-tu-efficientnet-đen-vision-transformer-2019-hien-tai" tabindex="-1">1.3.5. Từ EfficientNet đến Vision Transformer (2019-Hiện tại) <a class="header-anchor" href="#_1-3-5-tu-efficientnet-đen-vision-transformer-2019-hien-tai" aria-label="Permalink to &quot;1.3.5. Từ EfficientNet đến Vision Transformer (2019-Hiện tại)&quot;">​</a></h3><p>Năm 2019, Mingxing Tan và Quoc V. Le từ Google Research giới thiệu EfficientNet với phương pháp compound scaling - cân bằng đồng thời ba chiều: độ sâu, độ rộng, và độ phân giải của mạng. EfficientNet đạt được độ chính xác state-of-the-art với số lượng tham số và chi phí tính toán ít hơn đáng kể so với các kiến trúc trước đó.</p><p>Bước ngoặt mới nhất trong lĩnh vực thị giác máy tính là sự xuất hiện của Vision Transformer (ViT) vào năm 2020. Lấy cảm hứng từ kiến trúc Transformer vốn thành công vượt trội trong xử lý ngôn ngữ tự nhiên, ViT chia ảnh thành các patch và xử lý như một chuỗi token. Khi được huấn luyện trên tập dữ liệu đủ lớn, ViT đạt được hoặc vượt qua hiệu suất của các CNN tốt nhất trên nhiều benchmark. Các biến thể như Swin Transformer còn kết hợp ưu điểm của cả CNN (xử lý phân cấp) và Transformer (attention toàn cục).</p><h2 id="_1-4-tai-sao-cnn-phu-hop-voi-anh-ve-tinh" tabindex="-1">1.4. Tại sao CNN phù hợp với ảnh vệ tinh? <a class="header-anchor" href="#_1-4-tai-sao-cnn-phu-hop-voi-anh-ve-tinh" aria-label="Permalink to &quot;1.4. Tại sao CNN phù hợp với ảnh vệ tinh?&quot;">​</a></h2><p>Ảnh vệ tinh có nhiều đặc điểm khác biệt so với ảnh tự nhiên thông thường, và CNN tỏ ra đặc biệt phù hợp để xử lý những đặc thù này.</p><p>Thứ nhất, ảnh vệ tinh thường có kích thước rất lớn, từ hàng nghìn đến hàng chục nghìn pixel mỗi chiều. Một scene Sentinel-1 điển hình có kích thước khoảng 250×250 km với độ phân giải 10m, tương đương ảnh 25,000×25,000 pixel. Kiến trúc CNN với các lớp convolution và pooling cho phép xử lý ảnh lớn một cách hiệu quả thông qua việc chia nhỏ thành các tile và trượt cửa sổ.</p><p>Thứ hai, các đối tượng trong ảnh vệ tinh xuất hiện ở nhiều tỷ lệ khác nhau. Một tàu container có thể chiếm hàng trăm pixel trong ảnh WorldView-3 (0.3m GSD) nhưng chỉ vài pixel trong ảnh Sentinel-1 (10m GSD). Các kiến trúc CNN hiện đại như Feature Pyramid Network (FPN) được thiết kế đặc biệt để xử lý vấn đề đa tỷ lệ này bằng cách kết hợp các đặc trưng từ nhiều mức độ phân giải khác nhau.</p><p>Thứ ba, ảnh vệ tinh thường có nhiều kênh phổ hơn ảnh RGB thông thường. Ảnh Sentinel-2 có 13 kênh phổ từ khả kiến đến hồng ngoại nhiệt, trong khi ảnh Sentinel-1 SAR có 2 kênh phân cực VV và VH. CNN có thể dễ dàng mở rộng để xử lý đầu vào đa kênh bằng cách điều chỉnh số kênh ở lớp convolution đầu tiên.</p><p>Thứ tư, các đối tượng trong ảnh vệ tinh có thể xuất hiện theo nhiều hướng khác nhau, không như ảnh tự nhiên thường có hướng &quot;lên-xuống&quot; cố định. Tính chất translation invariant của CNN, kết hợp với data augmentation xoay ảnh trong quá trình huấn luyện, giúp mạng có khả năng nhận dạng đối tượng bất kể hướng.</p><h2 id="_1-5-cac-bai-toan-chinh-trong-xu-ly-anh-vien-tham" tabindex="-1">1.5. Các bài toán chính trong xử lý ảnh viễn thám <a class="header-anchor" href="#_1-5-cac-bai-toan-chinh-trong-xu-ly-anh-vien-tham" aria-label="Permalink to &quot;1.5. Các bài toán chính trong xử lý ảnh viễn thám&quot;">​</a></h2><h3 id="_1-5-1-phan-loai-anh-image-classification" tabindex="-1">1.5.1. Phân loại ảnh (Image Classification) <a class="header-anchor" href="#_1-5-1-phan-loai-anh-image-classification" aria-label="Permalink to &quot;1.5.1. Phân loại ảnh (Image Classification)&quot;">​</a></h3><p>Phân loại ảnh là bài toán gán một hoặc nhiều nhãn lớp cho toàn bộ ảnh hoặc một vùng ảnh (patch). Trong viễn thám, bài toán này thường được áp dụng cho phân loại lớp phủ mặt đất (land cover classification), phân loại cảnh quan (scene classification), hay phân loại loại tàu (vessel type classification). Output của bài toán phân loại là một vector xác suất cho các lớp, và mạng CNN điển hình cho bài toán này bao gồm các lớp convolution để trích xuất đặc trưng, theo sau bởi các lớp fully connected để thực hiện phân loại cuối cùng.</p><h3 id="_1-5-2-phat-hien-đoi-tuong-object-detection" tabindex="-1">1.5.2. Phát hiện đối tượng (Object Detection) <a class="header-anchor" href="#_1-5-2-phat-hien-đoi-tuong-object-detection" aria-label="Permalink to &quot;1.5.2. Phát hiện đối tượng (Object Detection)&quot;">​</a></h3><p>Phát hiện đối tượng yêu cầu mạng không chỉ phân loại mà còn định vị vị trí của các đối tượng trong ảnh thông qua bounding box. Đây là bài toán quan trọng trong phát hiện tàu biển, phương tiện, máy bay, và các đối tượng nhân tạo khác từ ảnh vệ tinh. Các kiến trúc phổ biến bao gồm họ YOLO (You Only Look Once) cho phát hiện thời gian thực, và Faster R-CNN cho độ chính xác cao. Đối với ảnh vệ tinh, các biến thể như Rotated Faster R-CNN còn hỗ trợ oriented bounding box để xử lý các đối tượng có hướng nghiêng như tàu biển.</p><h3 id="_1-5-3-phan-đoan-ngu-nghia-semantic-segmentation" tabindex="-1">1.5.3. Phân đoạn ngữ nghĩa (Semantic Segmentation) <a class="header-anchor" href="#_1-5-3-phan-đoan-ngu-nghia-semantic-segmentation" aria-label="Permalink to &quot;1.5.3. Phân đoạn ngữ nghĩa (Semantic Segmentation)&quot;">​</a></h3><p>Phân đoạn ngữ nghĩa yêu cầu gán nhãn lớp cho từng pixel trong ảnh, tạo ra mask phân vùng chi tiết. Bài toán này đặc biệt quan trọng trong nhận dạng vết dầu loang, lập bản đồ ngập lụt, hay trích xuất vùng đô thị. Các kiến trúc encoder-decoder như U-Net và DeepLabV3+ là những lựa chọn phổ biến, với encoder trích xuất đặc trưng và decoder khôi phục độ phân giải không gian. Các kết nối skip connection giữa encoder và decoder giúp bảo toàn thông tin chi tiết biên đối tượng.</p><h3 id="_1-5-4-instance-segmentation" tabindex="-1">1.5.4. Instance Segmentation <a class="header-anchor" href="#_1-5-4-instance-segmentation" aria-label="Permalink to &quot;1.5.4. Instance Segmentation&quot;">​</a></h3><p>Instance Segmentation kết hợp phát hiện đối tượng và phân đoạn ngữ nghĩa, không chỉ phân vùng theo lớp mà còn phân biệt từng instance riêng lẻ. Ví dụ, trong một cảng biển có nhiều tàu, instance segmentation sẽ tạo mask riêng biệt cho từng tàu, cho phép đếm chính xác số lượng và phân tích đặc điểm từng tàu. Mask R-CNN là kiến trúc tiêu biểu cho bài toán này.</p><h2 id="_1-6-muc-tieu-va-pham-vi-bao-cao" tabindex="-1">1.6. Mục tiêu và Phạm vi Báo cáo <a class="header-anchor" href="#_1-6-muc-tieu-va-pham-vi-bao-cao" aria-label="Permalink to &quot;1.6. Mục tiêu và Phạm vi Báo cáo&quot;">​</a></h2><p>Báo cáo này tập trung vào hai bài toán ứng dụng cụ thể trong lĩnh vực giám sát biển: <strong>phát hiện tàu biển (Ship Detection)</strong> và <strong>nhận dạng vết dầu loang (Oil Spill Detection)</strong>. Đây là hai bài toán có tầm quan trọng chiến lược trong bối cảnh Việt Nam là quốc gia biển với đường bờ biển dài hơn 3,260 km và vùng đặc quyền kinh tế rộng lớn.</p><p>Phát hiện tàu biển từ ảnh vệ tinh là công cụ quan trọng để giám sát hoạt động đánh bắt cá bất hợp pháp, đảm bảo an ninh hàng hải, và quản lý giao thông đường biển. Với việc sử dụng ảnh SAR (Synthetic Aperture Radar) từ vệ tinh Sentinel-1, hệ thống có thể hoạt động liên tục 24/7, bất kể điều kiện thời tiết hay thời gian trong ngày - một ưu điểm vượt trội so với ảnh quang học.</p><p>Nhận dạng vết dầu loang đóng vai trò quan trọng trong bảo vệ môi trường biển. Việc phát hiện sớm các sự cố tràn dầu, dù từ tai nạn hay xả thải bất hợp pháp, cho phép các cơ quan chức năng ứng phó kịp thời, giảm thiểu tác động đến hệ sinh thái biển và ngành thủy sản. Ảnh SAR cũng là lựa chọn hàng đầu cho bài toán này do khả năng phát hiện vết dầu dựa trên sự thay đổi độ nhám bề mặt biển.</p><p>Báo cáo sẽ trình bày chi tiết về kiến trúc CNN cơ bản, các phương pháp áp dụng CNN cho ảnh vệ tinh, quy trình xử lý hoàn chỉnh cho từng bài toán, các model state-of-the-art, và các bộ dữ liệu chuẩn được sử dụng trong nghiên cứu và đánh giá. Đặc biệt, báo cáo sẽ tập trung phân tích các model có sẵn trong thư viện TorchGeo - một thư viện Python được thiết kế đặc biệt cho các bài toán Deep Learning trong viễn thám, với các pre-trained weights cho nhiều loại cảm biến vệ tinh khác nhau.</p><p>Thông qua việc tổng hợp và phân tích các nghiên cứu, phương pháp, và công cụ hiện đại, báo cáo nhằm cung cấp một cái nhìn toàn diện về ứng dụng Deep Learning trong viễn thám biển, đồng thời đề xuất các hướng tiếp cận phù hợp cho việc triển khai thực tế tại Việt Nam.</p></div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-e257564d><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><!----></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-01-kien-truc-cnn/01-kien-truc-co-ban.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Trang sau</span><span class="title" data-v-e257564d>2.1.1. Kiến trúc CNN cơ bản</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5d98c3a5 data-v-e315a0ad><div class="container" data-v-e315a0ad><p class="message" data-v-e315a0ad>Nghiên cứu Ứng dụng Deep Learning trong Viễn thám</p><p class="copyright" data-v-e315a0ad>2024</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"assets_images_xview1_image-sources.md\":\"ckCsuNuZ\",\"assets_images_xview1_readme.md\":\"Dh-ZirnL\",\"assets_images_xview2_download-guide.md\":\"CoBf_73u\",\"assets_images_xview2_image-reference-catalog.md\":\"BygTyrM0\",\"assets_images_xview2_image-sources.md\":\"DuMc8EPf\",\"assets_images_xview2_readme.md\":\"BxXava9o\",\"assets_images_xview3_image-sources.md\":\"BniOX9bd\",\"chuong-01-gioi-thieu_muc-01-tong-quan_01-gioi-thieu-cnn-deep-learning.md\":\"Bd-Fbg20\",\"chuong-02-co-so-ly-thuyet_muc-01-kien-truc-cnn_01-kien-truc-co-ban.md\":\"JTkuWTE-\",\"chuong-02-co-so-ly-thuyet_muc-01-kien-truc-cnn_02-backbone-networks.md\":\"BlX0yEKA\",\"chuong-02-co-so-ly-thuyet_muc-02-phuong-phap-xu-ly-anh_01-phan-loai-anh.md\":\"DETt3o-M\",\"chuong-02-co-so-ly-thuyet_muc-02-phuong-phap-xu-ly-anh_02-phat-hien-doi-tuong.md\":\"GmKUOhbb\",\"chuong-02-co-so-ly-thuyet_muc-02-phuong-phap-xu-ly-anh_03-phan-doan-ngu-nghia.md\":\"CcH_kyR9\",\"chuong-02-co-so-ly-thuyet_muc-02-phuong-phap-xu-ly-anh_04-instance-segmentation.md\":\"TtJykzVA\",\"chuong-03-phat-hien-tau-bien_muc-01-dac-diem-bai-toan_01-dac-diem.md\":\"C0Yxv2n_\",\"chuong-03-phat-hien-tau-bien_muc-02-mo-hinh_01-cac-mo-hinh.md\":\"DGRPnXI5\",\"chuong-03-phat-hien-tau-bien_muc-03-quy-trinh_01-pipeline.md\":\"CyQavZag\",\"chuong-03-phat-hien-tau-bien_muc-04-bo-du-lieu_01-datasets.md\":\"B-r7bzJa\",\"chuong-04-phat-hien-dau-loang_muc-01-dac-diem-bai-toan_01-dac-diem.md\":\"DoL0XU6F\",\"chuong-04-phat-hien-dau-loang_muc-02-mo-hinh_01-cac-mo-hinh.md\":\"BDt_W34a\",\"chuong-04-phat-hien-dau-loang_muc-03-quy-trinh_01-pipeline.md\":\"CFhAxDR2\",\"chuong-04-phat-hien-dau-loang_muc-04-bo-du-lieu_01-datasets.md\":\"B0YdiGB0\",\"chuong-05-torchgeo_muc-01-tong-quan_01-tong-quan.md\":\"BoDJs4WI\",\"chuong-05-torchgeo_muc-02-classification_01-classification-models.md\":\"CzG4Fvsd\",\"chuong-05-torchgeo_muc-03-segmentation_01-segmentation-models.md\":\"BI9c1b3a\",\"chuong-05-torchgeo_muc-04-change-detection_01-change-detection-models.md\":\"AY_JAMod\",\"chuong-05-torchgeo_muc-05-pretrained-weights_01-pretrained-weights.md\":\"BuNGhnCB\",\"chuong-06-xview-challenges_muc-01-xview1-object-detection_01-dataset.md\":\"Dm7BptPM\",\"chuong-06-xview-challenges_muc-01-xview1-object-detection_02-giai-nhat.md\":\"2wV3PEsV\",\"chuong-06-xview-challenges_muc-01-xview1-object-detection_03-giai-nhi.md\":\"BufeTIgD\",\"chuong-06-xview-challenges_muc-01-xview1-object-detection_04-giai-ba.md\":\"BB8ENdVV\",\"chuong-06-xview-challenges_muc-01-xview1-object-detection_05-giai-tu.md\":\"BeVPeWzd\",\"chuong-06-xview-challenges_muc-01-xview1-object-detection_06-giai-nam.md\":\"BODlexDn\",\"chuong-06-xview-challenges_muc-02-xview2-building-damage_01-dataset.md\":\"D4Zdh38-\",\"chuong-06-xview-challenges_muc-02-xview2-building-damage_02-giai-nhat.md\":\"DmTBWgjK\",\"chuong-06-xview-challenges_muc-02-xview2-building-damage_03-giai-nhi.md\":\"BW-aVCBj\",\"chuong-06-xview-challenges_muc-02-xview2-building-damage_04-giai-ba.md\":\"C82xwoJR\",\"chuong-06-xview-challenges_muc-02-xview2-building-damage_05-giai-tu.md\":\"_cJqRaka\",\"chuong-06-xview-challenges_muc-02-xview2-building-damage_06-giai-nam.md\":\"B4Yzptuh\",\"chuong-06-xview-challenges_muc-03-xview3-maritime_01-dataset.md\":\"DteeNegR\",\"chuong-06-xview-challenges_muc-03-xview3-maritime_02-giai-nhat.md\":\"DNNZ5ArH\",\"chuong-06-xview-challenges_muc-03-xview3-maritime_03-giai-nhi.md\":\"DXfAO9PE\",\"chuong-06-xview-challenges_muc-03-xview3-maritime_04-giai-ba.md\":\"B_Gh3WW0\",\"chuong-06-xview-challenges_muc-03-xview3-maritime_05-giai-tu.md\":\"CSu3Wob_\",\"chuong-06-xview-challenges_muc-03-xview3-maritime_06-giai-nam.md\":\"YgGqePJH\",\"chuong-07-ket-luan_muc-01-tong-ket_01-ket-luan.md\":\"CnvNs1AJ\",\"index.md\":\"I4CP-rxb\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"vi-VN\",\"dir\":\"ltr\",\"title\":\"Deep Learning trong Viễn thám\",\"description\":\"Nghiên cứu ứng dụng CNN và Deep Learning trong phân tích ảnh viễn thám\",\"base\":\"/sen_doc/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"Trang chủ\",\"link\":\"/\"},{\"text\":\"Giới thiệu\",\"link\":\"/chuong-01-gioi-thieu/muc-01-tong-quan/01-gioi-thieu-cnn-deep-learning\"},{\"text\":\"TorchGeo\",\"link\":\"/chuong-05-torchgeo/muc-01-tong-quan/01-tong-quan\"},{\"text\":\"xView\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/01-dataset\"}],\"sidebar\":[{\"text\":\"Chương 1: Giới thiệu\",\"collapsed\":false,\"items\":[{\"text\":\"1.1. Tổng quan CNN & Deep Learning\",\"link\":\"/chuong-01-gioi-thieu/muc-01-tong-quan/01-gioi-thieu-cnn-deep-learning\"}]},{\"text\":\"Chương 2: Cơ sở lý thuyết\",\"collapsed\":false,\"items\":[{\"text\":\"2.1.1. Kiến trúc CNN cơ bản\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-01-kien-truc-cnn/01-kien-truc-co-ban\"},{\"text\":\"2.1.2. Backbone Networks\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-01-kien-truc-cnn/02-backbone-networks\"},{\"text\":\"2.2.1. Phân loại ảnh\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/01-phan-loai-anh\"},{\"text\":\"2.2.2. Phát hiện đối tượng\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/02-phat-hien-doi-tuong\"},{\"text\":\"2.2.3. Phân đoạn ngữ nghĩa\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/03-phan-doan-ngu-nghia\"},{\"text\":\"2.2.4. Instance Segmentation\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/04-instance-segmentation\"}]},{\"text\":\"Chương 3: Phát hiện tàu biển\",\"collapsed\":true,\"items\":[{\"text\":\"3.1. Đặc điểm bài toán\",\"link\":\"/chuong-03-phat-hien-tau-bien/muc-01-dac-diem-bai-toan/01-dac-diem\"},{\"text\":\"3.2. Các mô hình\",\"link\":\"/chuong-03-phat-hien-tau-bien/muc-02-mo-hinh/01-cac-mo-hinh\"},{\"text\":\"3.3. Quy trình pipeline\",\"link\":\"/chuong-03-phat-hien-tau-bien/muc-03-quy-trinh/01-pipeline\"},{\"text\":\"3.4. Bộ dữ liệu\",\"link\":\"/chuong-03-phat-hien-tau-bien/muc-04-bo-du-lieu/01-datasets\"}]},{\"text\":\"Chương 4: Phát hiện dầu loang\",\"collapsed\":true,\"items\":[{\"text\":\"4.1. Đặc điểm bài toán\",\"link\":\"/chuong-04-phat-hien-dau-loang/muc-01-dac-diem-bai-toan/01-dac-diem\"},{\"text\":\"4.2. Các mô hình\",\"link\":\"/chuong-04-phat-hien-dau-loang/muc-02-mo-hinh/01-cac-mo-hinh\"},{\"text\":\"4.3. Quy trình pipeline\",\"link\":\"/chuong-04-phat-hien-dau-loang/muc-03-quy-trinh/01-pipeline\"},{\"text\":\"4.4. Bộ dữ liệu\",\"link\":\"/chuong-04-phat-hien-dau-loang/muc-04-bo-du-lieu/01-datasets\"}]},{\"text\":\"Chương 5: TorchGeo\",\"collapsed\":true,\"items\":[{\"text\":\"5.1. Tổng quan\",\"link\":\"/chuong-05-torchgeo/muc-01-tong-quan/01-tong-quan\"},{\"text\":\"5.2. Classification Models\",\"link\":\"/chuong-05-torchgeo/muc-02-classification/01-classification-models\"},{\"text\":\"5.3. Segmentation Models\",\"link\":\"/chuong-05-torchgeo/muc-03-segmentation/01-segmentation-models\"},{\"text\":\"5.4. Change Detection\",\"link\":\"/chuong-05-torchgeo/muc-04-change-detection/01-change-detection-models\"},{\"text\":\"5.5. Pre-trained Weights\",\"link\":\"/chuong-05-torchgeo/muc-05-pretrained-weights/01-pretrained-weights\"}]},{\"text\":\"Chương 6: xView Challenges\",\"collapsed\":false,\"items\":[{\"text\":\"6.1. xView1 - Object Detection\",\"collapsed\":true,\"items\":[{\"text\":\"Dataset\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/01-dataset\"},{\"text\":\"Giải nhất\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/02-giai-nhat\"},{\"text\":\"Giải nhì\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/03-giai-nhi\"},{\"text\":\"Giải ba\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/04-giai-ba\"},{\"text\":\"Giải tư\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/05-giai-tu\"},{\"text\":\"Giải năm\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/06-giai-nam\"}]},{\"text\":\"6.2. xView2 - Building Damage\",\"collapsed\":true,\"items\":[{\"text\":\"Dataset (xBD)\",\"link\":\"/chuong-06-xview-challenges/muc-02-xview2-building-damage/01-dataset\"},{\"text\":\"Giải nhất\",\"link\":\"/chuong-06-xview-challenges/muc-02-xview2-building-damage/02-giai-nhat\"},{\"text\":\"Giải nhì\",\"link\":\"/chuong-06-xview-challenges/muc-02-xview2-building-damage/03-giai-nhi\"},{\"text\":\"Giải ba\",\"link\":\"/chuong-06-xview-challenges/muc-02-xview2-building-damage/04-giai-ba\"},{\"text\":\"Giải tư\",\"link\":\"/chuong-06-xview-challenges/muc-02-xview2-building-damage/05-giai-tu\"},{\"text\":\"Giải năm\",\"link\":\"/chuong-06-xview-challenges/muc-02-xview2-building-damage/06-giai-nam\"}]},{\"text\":\"6.3. xView3 - Maritime (SAR)\",\"collapsed\":true,\"items\":[{\"text\":\"Dataset\",\"link\":\"/chuong-06-xview-challenges/muc-03-xview3-maritime/01-dataset\"},{\"text\":\"Giải nhất\",\"link\":\"/chuong-06-xview-challenges/muc-03-xview3-maritime/02-giai-nhat\"},{\"text\":\"Giải nhì\",\"link\":\"/chuong-06-xview-challenges/muc-03-xview3-maritime/03-giai-nhi\"},{\"text\":\"Giải ba\",\"link\":\"/chuong-06-xview-challenges/muc-03-xview3-maritime/04-giai-ba\"},{\"text\":\"Giải tư\",\"link\":\"/chuong-06-xview-challenges/muc-03-xview3-maritime/05-giai-tu\"},{\"text\":\"Giải năm\",\"link\":\"/chuong-06-xview-challenges/muc-03-xview3-maritime/06-giai-nam\"}]}]},{\"text\":\"Chương 7: Kết luận\",\"collapsed\":false,\"items\":[{\"text\":\"7.1. Tổng kết\",\"link\":\"/chuong-07-ket-luan/muc-01-tong-ket/01-ket-luan\"}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/tchatb/sen_doc\"}],\"search\":{\"provider\":\"local\"},\"outline\":{\"level\":[2,3],\"label\":\"Mục lục trang\"},\"footer\":{\"message\":\"Nghiên cứu Ứng dụng Deep Learning trong Viễn thám\",\"copyright\":\"2024\"},\"docFooter\":{\"prev\":\"Trang trước\",\"next\":\"Trang sau\"},\"lastUpdated\":{\"text\":\"Cập nhật lần cuối\"},\"returnToTopLabel\":\"Về đầu trang\",\"sidebarMenuLabel\":\"Menu\",\"darkModeSwitchLabel\":\"Giao diện\"},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>