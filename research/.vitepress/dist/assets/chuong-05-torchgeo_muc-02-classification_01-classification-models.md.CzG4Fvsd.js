import{_ as e,c as a,o as i,a2 as s}from"./chunks/framework.nRfFlDZQ.js";const u=JSON.parse('{"title":"Chương 5: Classification Models trong TorchGeo","description":"","frontmatter":{},"headers":[],"relativePath":"chuong-05-torchgeo/muc-02-classification/01-classification-models.md","filePath":"chuong-05-torchgeo/muc-02-classification/01-classification-models.md","lastUpdated":null}'),r={name:"chuong-05-torchgeo/muc-02-classification/01-classification-models.md"};function n(l,t,o,d,c,h){return i(),a("div",null,[...t[0]||(t[0]=[s(`<h1 id="chuong-5-classification-models-trong-torchgeo" tabindex="-1">Chương 5: Classification Models trong TorchGeo <a class="header-anchor" href="#chuong-5-classification-models-trong-torchgeo" aria-label="Permalink to &quot;Chương 5: Classification Models trong TorchGeo&quot;">​</a></h1><h2 id="_6-11-tong-quan-classification-trong-torchgeo" tabindex="-1">6.11. Tổng quan Classification trong TorchGeo <a class="header-anchor" href="#_6-11-tong-quan-classification-trong-torchgeo" aria-label="Permalink to &quot;6.11. Tổng quan Classification trong TorchGeo&quot;">​</a></h2><p>Classification là một trong những tasks phổ biến nhất trong remote sensing, từ land use/land cover classification đến scene classification và crop type mapping. TorchGeo cung cấp comprehensive support cho classification tasks thông qua pre-trained models, benchmark datasets, và training utilities.</p><p>Trong phần này, chúng ta sẽ phân tích chi tiết các classification models có sẵn trong TorchGeo, cách sử dụng pre-trained weights, và best practices cho training classification models trên satellite imagery.</p><h2 id="_6-12-available-architectures" tabindex="-1">6.12. Available Architectures <a class="header-anchor" href="#_6-12-available-architectures" aria-label="Permalink to &quot;6.12. Available Architectures&quot;">​</a></h2><h3 id="_6-12-1-resnet-family" tabindex="-1">6.12.1. ResNet Family <a class="header-anchor" href="#_6-12-1-resnet-family" aria-label="Permalink to &quot;6.12.1. ResNet Family&quot;">​</a></h3><p>ResNet (Residual Networks) là backbone phổ biến nhất cho remote sensing classification trong TorchGeo.</p><p><strong>Variants có sẵn:</strong></p><ul><li>ResNet-18: 11M parameters, lightweight</li><li>ResNet-34: 21M parameters</li><li>ResNet-50: 25M parameters, best balance</li><li>ResNet-101: 44M parameters</li><li>ResNet-152: 60M parameters, highest capacity</li></ul><p><strong>Modifications cho Remote Sensing:</strong> TorchGeo ResNet được modified để handle multi-spectral input:</p><ul><li>First convolutional layer adapted cho variable input channels</li><li>Supports 1 to any number of bands</li><li>Maintains compatibility với pre-trained weights</li></ul><p><strong>Usage:</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>from torchgeo.models import resnet50, ResNet50_Weights</span></span>
<span class="line"><span></span></span>
<span class="line"><span># Load với pre-trained weights</span></span>
<span class="line"><span>weights = ResNet50_Weights.SENTINEL2_ALL_MOCO</span></span>
<span class="line"><span>model = resnet50(weights=weights)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># Or for custom input channels</span></span>
<span class="line"><span>model = resnet50(in_chans=13)  # 13-band Sentinel-2</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h3 id="_6-12-2-vision-transformer-vit" tabindex="-1">6.12.2. Vision Transformer (ViT) <a class="header-anchor" href="#_6-12-2-vision-transformer-vit" aria-label="Permalink to &quot;6.12.2. Vision Transformer (ViT)&quot;">​</a></h3><p>Vision Transformers đã được adapted cho remote sensing trong TorchGeo.</p><p><strong>Variants:</strong></p><ul><li>ViT-Small: 22M parameters</li><li>ViT-Base: 86M parameters</li><li>ViT-Large: 307M parameters</li></ul><p><strong>Pre-training:</strong> ViT models trong TorchGeo có weights từ:</p><ul><li>SSL4EO self-supervised learning</li><li>SatMAE masked autoencoder</li><li>DINO distillation</li></ul><p><strong>Patch Processing:</strong> ViT processes images as sequences of patches:</p><ul><li>Default patch size: 16×16 pixels</li><li>Position embeddings cho spatial awareness</li><li>Self-attention captures global context</li></ul><p><strong>Advantages cho Remote Sensing:</strong></p><ul><li>Better global context than CNNs</li><li>Handles variable object scales</li><li>Strong transfer learning performance</li></ul><h3 id="_6-12-3-swin-transformer" tabindex="-1">6.12.3. Swin Transformer <a class="header-anchor" href="#_6-12-3-swin-transformer" aria-label="Permalink to &quot;6.12.3. Swin Transformer&quot;">​</a></h3><p>Swin Transformer với hierarchical feature maps được support.</p><p><strong>Key Features:</strong></p><ul><li>Shifted window attention</li><li>Multi-scale representations</li><li>Efficient computation</li></ul><p><strong>Variants:</strong></p><ul><li>Swin-Tiny: 28M parameters</li><li>Swin-Small: 50M parameters</li><li>Swin-Base: 88M parameters</li></ul><p><strong>Remote Sensing Benefits:</strong></p><ul><li>Hierarchical features suit multi-scale objects</li><li>Local+global attention</li><li>Strong performance on benchmarks</li></ul><h3 id="_6-12-4-efficientnet" tabindex="-1">6.12.4. EfficientNet <a class="header-anchor" href="#_6-12-4-efficientnet" aria-label="Permalink to &quot;6.12.4. EfficientNet&quot;">​</a></h3><p>EfficientNet với compound scaling trong TorchGeo.</p><p><strong>Variants:</strong></p><ul><li>EfficientNet-B0 đến B7</li><li>Increasing size và accuracy</li></ul><p><strong>Advantages:</strong></p><ul><li>Excellent accuracy/efficiency trade-off</li><li>Mobile-friendly options (B0-B2)</li><li>Scalable cho different compute budgets</li></ul><h3 id="_6-12-5-other-architectures" tabindex="-1">6.12.5. Other Architectures <a class="header-anchor" href="#_6-12-5-other-architectures" aria-label="Permalink to &quot;6.12.5. Other Architectures&quot;">​</a></h3><p>TorchGeo cũng supports:</p><ul><li>VGG (11, 13, 16, 19)</li><li>DenseNet</li><li>MobileNet variants</li><li>RegNet</li></ul><h2 id="_6-13-pre-trained-weights" tabindex="-1">6.13. Pre-trained Weights <a class="header-anchor" href="#_6-13-pre-trained-weights" aria-label="Permalink to &quot;6.13. Pre-trained Weights&quot;">​</a></h2><h3 id="_6-13-1-ssl4eo-weights" tabindex="-1">6.13.1. SSL4EO Weights <a class="header-anchor" href="#_6-13-1-ssl4eo-weights" aria-label="Permalink to &quot;6.13.1. SSL4EO Weights&quot;">​</a></h3><p>SSL4EO (Self-Supervised Learning for Earth Observation) cung cấp weights trained trên European satellite data.</p><p><strong>SSL4EO-S12:</strong></p><ul><li>Dataset: Sentinel-1 và Sentinel-2 imagery</li><li>Coverage: Europe, seasonal variations</li><li>Size: 200k+ image triplets</li></ul><p><strong>Pre-training Methods:</strong></p><p><strong>MoCo v2 (Momentum Contrast):</strong></p><ul><li>Contrastive learning approach</li><li>Instance discrimination task</li><li>Strong feature learning</li></ul><p><strong>DINO (Distillation with No Labels):</strong></p><ul><li>Self-distillation from Vision Transformers</li><li>Teacher-student framework</li><li>Good for ViT models</li></ul><p><strong>MAE (Masked Autoencoder):</strong></p><ul><li>Reconstruction-based pre-training</li><li>Masks patches và reconstructs</li><li>Data-efficient</li></ul><p><strong>Available Weights:</strong></p><table tabindex="0"><thead><tr><th>Model</th><th>Method</th><th>Input Bands</th><th>Weight Name</th></tr></thead><tbody><tr><td>ResNet-18</td><td>MoCo</td><td>Sentinel-2 All</td><td>SENTINEL2_ALL_MOCO</td></tr><tr><td>ResNet-50</td><td>MoCo</td><td>Sentinel-2 All</td><td>SENTINEL2_ALL_MOCO</td></tr><tr><td>ResNet-50</td><td>MoCo</td><td>Sentinel-2 RGB</td><td>SENTINEL2_RGB_MOCO</td></tr><tr><td>ResNet-50</td><td>MoCo</td><td>Sentinel-1</td><td>SENTINEL1_ALL_MOCO</td></tr><tr><td>ViT-S</td><td>DINO</td><td>Sentinel-2</td><td>SENTINEL2_ALL_DINO</td></tr><tr><td>ViT-B</td><td>MAE</td><td>Sentinel-2</td><td>SENTINEL2_ALL_MAE</td></tr></tbody></table><h3 id="_6-13-2-satmae-weights" tabindex="-1">6.13.2. SatMAE Weights <a class="header-anchor" href="#_6-13-2-satmae-weights" aria-label="Permalink to &quot;6.13.2. SatMAE Weights&quot;">​</a></h3><p>SatMAE (Satellite Masked Autoencoder) specifically designed cho satellite imagery.</p><p><strong>Key Features:</strong></p><ul><li>Temporal encoding</li><li>Multi-spectral support</li><li>Global scale pre-training</li></ul><p><strong>Performance:</strong> SatMAE shows strong transfer performance:</p><ul><li>Outperforms ImageNet pretrained on most benchmarks</li><li>Particularly good for multi-spectral data</li><li>Better data efficiency</li></ul><h3 id="_6-13-3-imagenet-weights" tabindex="-1">6.13.3. ImageNet Weights <a class="header-anchor" href="#_6-13-3-imagenet-weights" aria-label="Permalink to &quot;6.13.3. ImageNet Weights&quot;">​</a></h3><p>Standard ImageNet weights cũng available:</p><ul><li>Baseline comparison</li><li>Good for RGB-only tasks</li><li>Wide architecture support</li></ul><p><strong>Adaptation for Multi-spectral:</strong> Khi sử dụng ImageNet weights với multi-spectral data:</p><ul><li>Modify first conv layer</li><li>Options: Duplicate RGB weights, random initialize extra channels, or learned adaptation</li></ul><h3 id="_6-13-4-domain-specific-weights" tabindex="-1">6.13.4. Domain-specific Weights <a class="header-anchor" href="#_6-13-4-domain-specific-weights" aria-label="Permalink to &quot;6.13.4. Domain-specific Weights&quot;">​</a></h3><p><strong>Million-AID:</strong></p><ul><li>Aerial image classification dataset</li><li>1 million images, 51 classes</li><li>Good for high-resolution aerial tasks</li></ul><p><strong>BigEarthNet:</strong></p><ul><li>Multi-label Sentinel-2 classification</li><li>590k patches, 19/43 labels</li><li>European land cover</li></ul><h2 id="_6-14-classification-datasets" tabindex="-1">6.14. Classification Datasets <a class="header-anchor" href="#_6-14-classification-datasets" aria-label="Permalink to &quot;6.14. Classification Datasets&quot;">​</a></h2><h3 id="_6-14-1-eurosat" tabindex="-1">6.14.1. EuroSAT <a class="header-anchor" href="#_6-14-1-eurosat" aria-label="Permalink to &quot;6.14.1. EuroSAT&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Attribute</th><th>Value</th></tr></thead><tbody><tr><td><strong>Source</strong></td><td>Sentinel-2</td></tr><tr><td><strong>Classes</strong></td><td>10 land use classes</td></tr><tr><td><strong>Samples</strong></td><td>27,000 patches</td></tr><tr><td><strong>Patch Size</strong></td><td>64×64 pixels</td></tr><tr><td><strong>Bands</strong></td><td>13 multispectral</td></tr></tbody></table><p><strong>Classes:</strong> Industrial, Residential, Annual Crop, Permanent Crop, River, Sea/Lake, Herbaceous Vegetation, Highway, Pasture, Forest</p><p><strong>Usage trong TorchGeo:</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>from torchgeo.datasets import EuroSAT</span></span>
<span class="line"><span>from torchgeo.datamodules import EuroSATDataModule</span></span>
<span class="line"><span></span></span>
<span class="line"><span>dataset = EuroSAT(root=&quot;data&quot;, split=&quot;train&quot;, download=True)</span></span>
<span class="line"><span># Or with DataModule</span></span>
<span class="line"><span>dm = EuroSATDataModule(root=&quot;data&quot;, batch_size=32)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><h3 id="_6-14-2-uc-merced-land-use" tabindex="-1">6.14.2. UC Merced Land Use <a class="header-anchor" href="#_6-14-2-uc-merced-land-use" aria-label="Permalink to &quot;6.14.2. UC Merced Land Use&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Attribute</th><th>Value</th></tr></thead><tbody><tr><td><strong>Source</strong></td><td>USGS aerial imagery</td></tr><tr><td><strong>Classes</strong></td><td>21 land use classes</td></tr><tr><td><strong>Samples</strong></td><td>2,100 images</td></tr><tr><td><strong>Size</strong></td><td>256×256 pixels</td></tr><tr><td><strong>Resolution</strong></td><td>0.3m</td></tr></tbody></table><p><strong>Classes:</strong> Agricultural, Airplane, Baseball Diamond, Beach, Buildings, Chaparral, Dense Residential, Forest, Freeway, Golf Course, Harbor, Intersection, Medium Residential, Mobile Home Park, Overpass, Parking Lot, River, Runway, Sparse Residential, Storage Tanks, Tennis Courts</p><h3 id="_6-14-3-bigearthnet" tabindex="-1">6.14.3. BigEarthNet <a class="header-anchor" href="#_6-14-3-bigearthnet" aria-label="Permalink to &quot;6.14.3. BigEarthNet&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Attribute</th><th>Value</th></tr></thead><tbody><tr><td><strong>Source</strong></td><td>Sentinel-2</td></tr><tr><td><strong>Patches</strong></td><td>590,326</td></tr><tr><td><strong>Size</strong></td><td>120×120 pixels</td></tr><tr><td><strong>Labels</strong></td><td>Multi-label (43 classes)</td></tr><tr><td><strong>Coverage</strong></td><td>10 European countries</td></tr></tbody></table><p><strong>Đặc điểm:</strong></p><ul><li>Large-scale dataset</li><li>Multi-label classification</li><li>Updated label scheme (19 classes) for cleaner taxonomy</li><li>Sentinel-1 version also available</li></ul><h3 id="_6-14-4-patternnet" tabindex="-1">6.14.4. PatternNet <a class="header-anchor" href="#_6-14-4-patternnet" aria-label="Permalink to &quot;6.14.4. PatternNet&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Attribute</th><th>Value</th></tr></thead><tbody><tr><td><strong>Classes</strong></td><td>38 classes</td></tr><tr><td><strong>Samples</strong></td><td>30,400 images</td></tr><tr><td><strong>Size</strong></td><td>256×256 pixels</td></tr><tr><td><strong>Resolution</strong></td><td>~0.06m to ~5m</td></tr></tbody></table><p><strong>Diverse classes:</strong> Từ natural (beach, forest, wetland) đến man-made (airport, bridge, stadium).</p><h3 id="_6-14-5-resisc45" tabindex="-1">6.14.5. RESISC45 <a class="header-anchor" href="#_6-14-5-resisc45" aria-label="Permalink to &quot;6.14.5. RESISC45&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Attribute</th><th>Value</th></tr></thead><tbody><tr><td><strong>Classes</strong></td><td>45 classes</td></tr><tr><td><strong>Samples</strong></td><td>31,500 images</td></tr><tr><td><strong>Size</strong></td><td>256×256 pixels</td></tr><tr><td><strong>Source</strong></td><td>Google Earth</td></tr></tbody></table><p><strong>Comprehensive coverage:</strong> Wide range of scene types cho robust evaluation.</p><h2 id="_6-15-classificationtask-trong-torchgeo" tabindex="-1">6.15. ClassificationTask trong TorchGeo <a class="header-anchor" href="#_6-15-classificationtask-trong-torchgeo" aria-label="Permalink to &quot;6.15. ClassificationTask trong TorchGeo&quot;">​</a></h2><h3 id="_6-15-1-overview" tabindex="-1">6.15.1. Overview <a class="header-anchor" href="#_6-15-1-overview" aria-label="Permalink to &quot;6.15.1. Overview&quot;">​</a></h3><p>TorchGeo cung cấp <code>ClassificationTask</code> Lightning module cho streamlined training.</p><p><strong>Key Features:</strong></p><ul><li>Configurable model và backbone</li><li>Support cho multi-class và multi-label</li><li>Standard metrics tracking</li><li>Learning rate scheduling</li></ul><h3 id="_6-15-2-configuration-options" tabindex="-1">6.15.2. Configuration Options <a class="header-anchor" href="#_6-15-2-configuration-options" aria-label="Permalink to &quot;6.15.2. Configuration Options&quot;">​</a></h3><p><strong>Model Selection:</strong></p><ul><li>Backbone architecture (resnet50, vit_small_patch16_224, etc.)</li><li>Pre-trained weights source</li><li>Number of output classes</li></ul><p><strong>Training:</strong></p><ul><li>Learning rate và scheduler</li><li>Loss function (CE, BCE, Focal)</li><li>Optimizer (Adam, SGD, AdamW)</li></ul><p><strong>Data:</strong></p><ul><li>Batch size</li><li>Number of workers</li><li>Augmentation pipeline</li></ul><h3 id="_6-15-3-multi-label-classification" tabindex="-1">6.15.3. Multi-label Classification <a class="header-anchor" href="#_6-15-3-multi-label-classification" aria-label="Permalink to &quot;6.15.3. Multi-label Classification&quot;">​</a></h3><p>Cho datasets như BigEarthNet với multiple labels per image:</p><ul><li>BCE loss thay vì Cross Entropy</li><li>Sigmoid activation thay vì Softmax</li><li>Threshold tuning cho optimal F1</li></ul><h3 id="_6-15-4-metrics" tabindex="-1">6.15.4. Metrics <a class="header-anchor" href="#_6-15-4-metrics" aria-label="Permalink to &quot;6.15.4. Metrics&quot;">​</a></h3><p><strong>Classification Metrics:</strong></p><ul><li>Overall Accuracy</li><li>Per-class Accuracy</li><li>F1 Score (macro, micro, weighted)</li><li>Precision và Recall</li><li>Confusion Matrix</li></ul><h2 id="_6-16-training-best-practices" tabindex="-1">6.16. Training Best Practices <a class="header-anchor" href="#_6-16-training-best-practices" aria-label="Permalink to &quot;6.16. Training Best Practices&quot;">​</a></h2><h3 id="_6-16-1-data-preprocessing" tabindex="-1">6.16.1. Data Preprocessing <a class="header-anchor" href="#_6-16-1-data-preprocessing" aria-label="Permalink to &quot;6.16.1. Data Preprocessing&quot;">​</a></h3><p><strong>Normalization:</strong> TorchGeo provides per-band statistics cho common sensors:</p><ul><li>Sentinel-2 mean/std</li><li>Landsat mean/std</li><li>Sensor-specific normalization</li></ul><p><strong>Band Selection:</strong> Not all bands equally useful:</p><ul><li>RGB (B4, B3, B2) cho visual</li><li>Near-infrared bands cho vegetation</li><li>SWIR cho moisture</li><li>Task-dependent selection</li></ul><h3 id="_6-16-2-augmentation" tabindex="-1">6.16.2. Augmentation <a class="header-anchor" href="#_6-16-2-augmentation" aria-label="Permalink to &quot;6.16.2. Augmentation&quot;">​</a></h3><p><strong>Recommended Augmentations:</strong></p><ul><li>Random horizontal/vertical flip</li><li>Random rotation</li><li>Random crop và resize</li><li>Color jittering (for RGB)</li></ul><p><strong>Multi-spectral Considerations:</strong></p><ul><li>Maintain band relationships</li><li>Avoid augmentations that break physical meaning</li><li>Consider sensor-specific constraints</li></ul><h3 id="_6-16-3-transfer-learning-strategy" tabindex="-1">6.16.3. Transfer Learning Strategy <a class="header-anchor" href="#_6-16-3-transfer-learning-strategy" aria-label="Permalink to &quot;6.16.3. Transfer Learning Strategy&quot;">​</a></h3><p><strong>Fine-tuning:</strong></p><ol><li>Load pre-trained weights</li><li>Replace classification head</li><li>Freeze backbone initially</li><li>Gradually unfreeze layers</li><li>Lower learning rate for pre-trained layers</li></ol><p><strong>Linear Probing:</strong></p><ul><li>Freeze all pre-trained layers</li><li>Only train classification head</li><li>Quick baseline evaluation</li><li>Test feature quality</li></ul><h3 id="_6-16-4-hyperparameter-tuning" tabindex="-1">6.16.4. Hyperparameter Tuning <a class="header-anchor" href="#_6-16-4-hyperparameter-tuning" aria-label="Permalink to &quot;6.16.4. Hyperparameter Tuning&quot;">​</a></h3><p><strong>Learning Rate:</strong></p><ul><li>Lower for pre-trained: 1e-4 to 1e-3</li><li>Higher for scratch: 1e-3 to 1e-2</li><li>Warmup recommended</li></ul><p><strong>Batch Size:</strong></p><ul><li>Larger batches: More stable, need higher LR</li><li>Typical: 32-128 depending on GPU memory</li></ul><p><strong>Epochs:</strong></p><ul><li>Dataset size dependent</li><li>Early stopping based on validation</li><li>Typically 50-200 epochs</li></ul><h2 id="_6-17-benchmark-results" tabindex="-1">6.17. Benchmark Results <a class="header-anchor" href="#_6-17-benchmark-results" aria-label="Permalink to &quot;6.17. Benchmark Results&quot;">​</a></h2><h3 id="_6-17-1-eurosat-results" tabindex="-1">6.17.1. EuroSAT Results <a class="header-anchor" href="#_6-17-1-eurosat-results" aria-label="Permalink to &quot;6.17.1. EuroSAT Results&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Model</th><th>Pre-training</th><th>Accuracy</th></tr></thead><tbody><tr><td>ResNet-50</td><td>ImageNet</td><td>95.5%</td></tr><tr><td>ResNet-50</td><td>SSL4EO MoCo</td><td>97.2%</td></tr><tr><td>ViT-B</td><td>SSL4EO MAE</td><td>97.8%</td></tr><tr><td>Swin-T</td><td>SSL4EO</td><td>97.5%</td></tr></tbody></table><h3 id="_6-17-2-uc-merced-results" tabindex="-1">6.17.2. UC Merced Results <a class="header-anchor" href="#_6-17-2-uc-merced-results" aria-label="Permalink to &quot;6.17.2. UC Merced Results&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Model</th><th>Pre-training</th><th>Accuracy</th></tr></thead><tbody><tr><td>ResNet-50</td><td>ImageNet</td><td>96.8%</td></tr><tr><td>ResNet-50</td><td>Million-AID</td><td>98.1%</td></tr><tr><td>ViT-B</td><td>SSL4EO</td><td>98.4%</td></tr></tbody></table><h3 id="_6-17-3-bigearthnet-results" tabindex="-1">6.17.3. BigEarthNet Results <a class="header-anchor" href="#_6-17-3-bigearthnet-results" aria-label="Permalink to &quot;6.17.3. BigEarthNet Results&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Model</th><th>Pre-training</th><th>mAP</th></tr></thead><tbody><tr><td>ResNet-50</td><td>ImageNet</td><td>75.2</td></tr><tr><td>ResNet-50</td><td>SSL4EO</td><td>79.8</td></tr><tr><td>ViT-B</td><td>SSL4EO MAE</td><td>82.3</td></tr></tbody></table><p><strong>Observations:</strong></p><ul><li>Domain-specific pre-training consistently outperforms ImageNet</li><li>Transformers show advantage on large datasets</li><li>Multi-spectral pre-training crucial for Sentinel-2 tasks</li></ul><h2 id="_6-18-advanced-topics" tabindex="-1">6.18. Advanced Topics <a class="header-anchor" href="#_6-18-advanced-topics" aria-label="Permalink to &quot;6.18. Advanced Topics&quot;">​</a></h2><h3 id="_6-18-1-few-shot-classification" tabindex="-1">6.18.1. Few-shot Classification <a class="header-anchor" href="#_6-18-1-few-shot-classification" aria-label="Permalink to &quot;6.18.1. Few-shot Classification&quot;">​</a></h3><p>Khi labeled data hạn chế:</p><ul><li>Linear probing với strong pre-trained features</li><li>Meta-learning approaches</li><li>Semi-supervised methods</li></ul><p>TorchGeo pre-trained models đặc biệt valuable cho few-shot scenarios.</p><h3 id="_6-18-2-temporal-classification" tabindex="-1">6.18.2. Temporal Classification <a class="header-anchor" href="#_6-18-2-temporal-classification" aria-label="Permalink to &quot;6.18.2. Temporal Classification&quot;">​</a></h3><p>For time-series classification:</p><ul><li>Stack temporal features</li><li>Use recurrent architectures on top</li><li>Temporal attention mechanisms</li></ul><h3 id="_6-18-3-multi-modal-fusion" tabindex="-1">6.18.3. Multi-modal Fusion <a class="header-anchor" href="#_6-18-3-multi-modal-fusion" aria-label="Permalink to &quot;6.18.3. Multi-modal Fusion&quot;">​</a></h3><p>Combine different data sources:</p><ul><li>Early fusion: Concatenate inputs</li><li>Late fusion: Combine predictions</li><li>Mid-level fusion: Merge features</li></ul><p>TorchGeo supports loading multiple datasets với IntersectionDataset.</p><h3 id="_6-18-4-uncertainty-estimation" tabindex="-1">6.18.4. Uncertainty Estimation <a class="header-anchor" href="#_6-18-4-uncertainty-estimation" aria-label="Permalink to &quot;6.18.4. Uncertainty Estimation&quot;">​</a></h3><p>Quantify prediction confidence:</p><ul><li>Monte Carlo Dropout</li><li>Deep Ensembles</li><li>Evidential Deep Learning</li></ul><p>Important cho operational remote sensing applications.</p><h2 id="_6-19-use-cases" tabindex="-1">6.19. Use Cases <a class="header-anchor" href="#_6-19-use-cases" aria-label="Permalink to &quot;6.19. Use Cases&quot;">​</a></h2><h3 id="_6-19-1-land-use-land-cover-mapping" tabindex="-1">6.19.1. Land Use/Land Cover Mapping <a class="header-anchor" href="#_6-19-1-land-use-land-cover-mapping" aria-label="Permalink to &quot;6.19.1. Land Use/Land Cover Mapping&quot;">​</a></h3><p><strong>Application:</strong> Classify land areas into categories (urban, forest, water, agriculture, etc.)</p><p><strong>Approach:</strong></p><ul><li>EuroSAT hoặc similar dataset cho training</li><li>ResNet-50 với SSL4EO weights</li><li>Fine-tune for target region</li></ul><h3 id="_6-19-2-crop-type-classification" tabindex="-1">6.19.2. Crop Type Classification <a class="header-anchor" href="#_6-19-2-crop-type-classification" aria-label="Permalink to &quot;6.19.2. Crop Type Classification&quot;">​</a></h3><p><strong>Application:</strong> Identify crop types from satellite imagery</p><p><strong>Approach:</strong></p><ul><li>Temporal stack of images (growing season)</li><li>Multi-spectral bands including red edge, NIR</li><li>Domain-specific pre-training valuable</li></ul><h3 id="_6-19-3-disaster-assessment" tabindex="-1">6.19.3. Disaster Assessment <a class="header-anchor" href="#_6-19-3-disaster-assessment" aria-label="Permalink to &quot;6.19.3. Disaster Assessment&quot;">​</a></h3><p><strong>Application:</strong> Classify damage levels sau natural disasters</p><p><strong>Approach:</strong></p><ul><li>Pre/post event image comparison</li><li>Fine-grained classification (intact, damaged, destroyed)</li><li>Transfer learning từ related tasks</li></ul><h3 id="_6-19-4-infrastructure-monitoring" tabindex="-1">6.19.4. Infrastructure Monitoring <a class="header-anchor" href="#_6-19-4-infrastructure-monitoring" aria-label="Permalink to &quot;6.19.4. Infrastructure Monitoring&quot;">​</a></h3><p><strong>Application:</strong> Detect và classify infrastructure (airports, ports, power plants)</p><p><strong>Approach:</strong></p><ul><li>High-resolution imagery</li><li>Fine-grained categories</li><li>Object-oriented classification</li></ul><p>Classification trong TorchGeo provides powerful tools cho diverse remote sensing applications, với pre-trained models significantly reducing data và compute requirements cho new tasks.</p>`,173)])])}const g=e(r,[["render",n]]);export{u as __pageData,g as default};
