import{_ as s,C as l,c as g,o as e,a2 as n,b as r,w as a,a as d,G as o,a3 as h}from"./chunks/framework.nRfFlDZQ.js";const T=JSON.parse('{"title":"6.3.3 Giải Pháp Hạng Nhì xView3: Multi-Task Segmentation","description":"","frontmatter":{},"headers":[],"relativePath":"chuong-06-xview-challenges/muc-03-xview3-maritime/03-giai-nhi.md","filePath":"chuong-06-xview-challenges/muc-03-xview3-maritime/03-giai-nhi.md","lastUpdated":1766163869000}'),c={name:"chuong-06-xview-challenges/muc-03-xview3-maritime/03-giai-nhi.md"};function u(A,t,E,b,p,m){const i=l("Mermaid");return e(),g("div",null,[t[6]||(t[6]=n('<h1 id="_6-3-3-giai-phap-hang-nhi-xview3-multi-task-segmentation" tabindex="-1">6.3.3 Giải Pháp Hạng Nhì xView3: Multi-Task Segmentation <a class="header-anchor" href="#_6-3-3-giai-phap-hang-nhi-xview3-multi-task-segmentation" aria-label="Permalink to &quot;6.3.3 Giải Pháp Hạng Nhì xView3: Multi-Task Segmentation&quot;">​</a></h1><h2 id="loi-dan" tabindex="-1">Lời Dẫn <a class="header-anchor" href="#loi-dan" aria-label="Permalink to &quot;Lời Dẫn&quot;">​</a></h2><p>Trong khi giải pháp hạng nhất CircleNet sử dụng kiến trúc tùy biến phức tạp với stride-2 output, giải pháp hạng nhì của Selim Sefidov - người đã đạt hạng nhì trong xView2 trước đó - đi theo hướng đơn giản và thực dụng hơn. Thay vì coi bài toán như object detection truyền thống, Sefidov reformulate thành multi-task segmentation, tận dụng kiến trúc U-Net quen thuộc. Đặc biệt, ông đưa ra quyết định táo bạo: chỉ train trên validation set chất lượng cao thay vì training set lớn nhưng nhiều noise.</p><table tabindex="0"><thead><tr><th>Thuộc tính</th><th>Giá trị</th></tr></thead><tbody><tr><td><strong>Xếp hạng</strong></td><td>2/1,900+ đội</td></tr><tr><td><strong>Tác giả</strong></td><td>Selim Sefidov (selimsef)</td></tr><tr><td><strong>Điểm holdout</strong></td><td>0.604</td></tr><tr><td><strong>Đóng góp chính</strong></td><td>Segmentation paradigm, Data quality &gt; quantity</td></tr><tr><td><strong>Kiến trúc</strong></td><td>EfficientNet-V2 + U-Net Decoder</td></tr></tbody></table><hr><h2 id="_1-paradigm-shift-detection-→-segmentation" tabindex="-1">1. Paradigm Shift: Detection → Segmentation <a class="header-anchor" href="#_1-paradigm-shift-detection-→-segmentation" aria-label="Permalink to &quot;1. Paradigm Shift: Detection → Segmentation&quot;">​</a></h2><h3 id="_1-1-quan-sat-then-chot" tabindex="-1">1.1 Quan Sát Then Chốt <a class="header-anchor" href="#_1-1-quan-sat-then-chot" aria-label="Permalink to &quot;1.1 Quan Sát Then Chốt&quot;">​</a></h3><p>Sefidov nhận ra rằng maritime object detection có thể được reformulate thành bài toán segmentation với dense predictions:</p>',8)),(e(),r(h,null,{default:a(()=>[o(i,{id:"mermaid-73",class:"mermaid",graph:"flowchart%20TB%0A%20%20%20%20subgraph%20DETECTION%5B%22Object%20Detection%20Truy%E1%BB%81n%20Th%E1%BB%91ng%22%5D%0A%20%20%20%20%20%20%20%20D1%5B%22Region%20Proposal%22%5D%0A%20%20%20%20%20%20%20%20D2%5B%22RoI%20Pooling%22%5D%0A%20%20%20%20%20%20%20%20D3%5B%22Box%20Regression%22%5D%0A%20%20%20%20%20%20%20%20D4%5B%22Classification%22%5D%0A%0A%20%20%20%20%20%20%20%20D1%20--%3E%20D2%20--%3E%20D3%20--%3E%20D4%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20SEGMENTATION%5B%22Segmentation%20Approach%22%5D%0A%20%20%20%20%20%20%20%20S1%5B%22Encoder%22%5D%0A%20%20%20%20%20%20%20%20S2%5B%22U-Net%20Decoder%22%5D%0A%20%20%20%20%20%20%20%20S3%5B%22Multi-Head%20Outputs%22%5D%0A%0A%20%20%20%20%20%20%20%20S1%20--%3E%20S2%20--%3E%20S3%0A%20%20%20%20end%0A"})]),fallback:a(()=>[...t[0]||(t[0]=[d(" Loading... ",-1)])]),_:1})),t[7]||(t[7]=n('<h3 id="_1-2-loi-ich-cua-segmentation" tabindex="-1">1.2 Lợi Ích Của Segmentation <a class="header-anchor" href="#_1-2-loi-ich-cua-segmentation" aria-label="Permalink to &quot;1.2 Lợi Ích Của Segmentation&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Khía cạnh</th><th>Object Detection</th><th>Segmentation</th></tr></thead><tbody><tr><td><strong>Localization</strong></td><td>Box-level</td><td>Pixel-level</td></tr><tr><td><strong>Multi-task</strong></td><td>Shared head</td><td>Independent heads</td></tr><tr><td><strong>Context</strong></td><td>Anchor-dependent</td><td>Full spatial info</td></tr><tr><td><strong>Inference</strong></td><td>Phức tạp</td><td>Đơn giản</td></tr></tbody></table><hr><h2 id="_2-kien-truc-mo-hinh" tabindex="-1">2. Kiến Trúc Mô Hình <a class="header-anchor" href="#_2-kien-truc-mo-hinh" aria-label="Permalink to &quot;2. Kiến Trúc Mô Hình&quot;">​</a></h2><h3 id="_2-1-thiet-ke-tong-the" tabindex="-1">2.1 Thiết Kế Tổng Thể <a class="header-anchor" href="#_2-1-thiet-ke-tong-the" aria-label="Permalink to &quot;2.1 Thiết Kế Tổng Thể&quot;">​</a></h3>',5)),(e(),r(h,null,{default:a(()=>[o(i,{id:"mermaid-145",class:"mermaid",graph:"flowchart%20TB%0A%20%20%20%20subgraph%20INPUT%5B%22%C4%90%E1%BA%A7u%20V%C3%A0o%22%5D%0A%20%20%20%20%20%20%20%20SAR%5B%22%E1%BA%A2nh%20SAR%3Cbr%2F%3E4%20k%C3%AAnh%3A%20VV%2C%20VH%2C%20bath%2C%20wind%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20ENCODER%5B%22Encoder%22%5D%0A%20%20%20%20%20%20%20%20EFF%5B%22EfficientNet-V2%20Large%3Cbr%2F%3EPretrained%20ImageNet%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20DECODER%5B%22U-Net%20Decoder%22%5D%0A%20%20%20%20%20%20%20%20SKIP%5B%22Skip%20Connections%3Cbr%2F%3EMulti-scale%20fusion%22%5D%0A%20%20%20%20%20%20%20%20UP%5B%22Progressive%20Upsampling%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20HEADS%5B%22Task%20Heads%20%C4%90%E1%BB%99c%20L%E1%BA%ADp%22%5D%0A%20%20%20%20%20%20%20%20H1%5B%22Detection%3Cbr%2F%3EGaussian%20Heatmap%22%5D%0A%20%20%20%20%20%20%20%20H2%5B%22Vessel%3Cbr%2F%3EClassification%22%5D%0A%20%20%20%20%20%20%20%20H3%5B%22Fishing%3Cbr%2F%3EClassification%22%5D%0A%20%20%20%20%20%20%20%20H4%5B%22Length%3Cbr%2F%3ERegression%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20INPUT%20--%3E%20ENCODER%20--%3E%20DECODER%20--%3E%20HEADS%0A"})]),fallback:a(()=>[...t[1]||(t[1]=[d(" Loading... ",-1)])]),_:1})),t[8]||(t[8]=n('<h3 id="_2-2-tai-sao-efficientnet-v2" tabindex="-1">2.2 Tại Sao EfficientNet-V2 <a class="header-anchor" href="#_2-2-tai-sao-efficientnet-v2" aria-label="Permalink to &quot;2.2 Tại Sao EfficientNet-V2&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Backbone</th><th>Params</th><th>ImageNet Acc</th><th>Phù hợp SAR</th></tr></thead><tbody><tr><td>ResNet-50</td><td>25M</td><td>76.1%</td><td>Tốt</td></tr><tr><td>EfficientNet-B5</td><td>30M</td><td>83.6%</td><td>Rất tốt</td></tr><tr><td><strong>EfficientNet-V2 L</strong></td><td>118M</td><td><strong>85.7%</strong></td><td><strong>Xuất sắc</strong></td></tr></tbody></table><p>EfficientNet-V2 cải thiện đáng kể so với phiên bản gốc nhờ:</p><ul><li>Fused-MBConv trong các stage đầu</li><li>Progressive learning với kích thước ảnh tăng dần</li><li>Regularization scaling</li></ul><hr><h2 id="_3-quyet-đinh-du-lieu-tao-bao" tabindex="-1">3. Quyết Định Dữ Liệu Táo Bạo <a class="header-anchor" href="#_3-quyet-đinh-du-lieu-tao-bao" aria-label="Permalink to &quot;3. Quyết Định Dữ Liệu Táo Bạo&quot;">​</a></h2><h3 id="_3-1-data-quality-quantity" tabindex="-1">3.1 Data Quality &gt; Quantity <a class="header-anchor" href="#_3-1-data-quality-quantity" aria-label="Permalink to &quot;3.1 Data Quality &gt; Quantity&quot;">​</a></h3><p>Đây là đóng góp quan trọng nhất của giải pháp. Thay vì dùng toàn bộ training set (~1,000 scenes), Sefidov chỉ train trên validation set (~200 scenes) chất lượng cao:</p>',8)),(e(),r(h,null,{default:a(()=>[o(i,{id:"mermaid-241",class:"mermaid",graph:"flowchart%20LR%0A%20%20%20%20subgraph%20TRAINING_SET%5B%22Training%20Set%22%5D%0A%20%20%20%20%20%20%20%20T1%5B%22~1%2C000%20scenes%22%5D%0A%20%20%20%20%20%20%20%20T2%5B%22Nhi%E1%BB%81u%20label%20noise%22%5D%0A%20%20%20%20%20%20%20%20T3%5B%22False%20positives%20t%E1%BB%AB%20s%C3%B3ng%22%5D%0A%20%20%20%20%20%20%20%20T4%5B%22Annotations%20thi%E1%BA%BFu%20nh%E1%BA%A5t%20qu%C3%A1n%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20VAL_SET%5B%22Validation%20Set%22%5D%0A%20%20%20%20%20%20%20%20V1%5B%22~200%20scenes%22%5D%0A%20%20%20%20%20%20%20%20V2%5B%22Review%20k%E1%BB%B9%20l%C6%B0%E1%BB%A1ng%22%5D%0A%20%20%20%20%20%20%20%20V3%5B%22Quality%20control%20cao%22%5D%0A%20%20%20%20%20%20%20%20V4%5B%22Ground%20truth%20%C4%91%C3%A1ng%20tin%20c%E1%BA%ADy%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20VAL_SET%20--%3E%7C%22Ch%E1%BB%8Dn%22%7C%20MODEL%5B%22Hu%E1%BA%A5n%20Luy%E1%BB%87n%22%5D%0A%20%20%20%20TRAINING_SET%20--%3E%7C%22B%E1%BB%8F%20qua%22%7C%20X%5B%22%E2%9D%8C%22%5D%0A"})]),fallback:a(()=>[...t[2]||(t[2]=[d(" Loading... ",-1)])]),_:1})),t[9]||(t[9]=n('<h3 id="_3-2-ly-do-va-ket-qua" tabindex="-1">3.2 Lý Do và Kết Quả <a class="header-anchor" href="#_3-2-ly-do-va-ket-qua" aria-label="Permalink to &quot;3.2 Lý Do và Kết Quả&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Khía cạnh</th><th>Train trên Training Set</th><th>Train trên Validation Set</th></tr></thead><tbody><tr><td><strong>Số lượng</strong></td><td>~1,000 scenes</td><td>~200 scenes</td></tr><tr><td><strong>Chất lượng</strong></td><td>Noise cao</td><td>Sạch</td></tr><tr><td><strong>Overfitting</strong></td><td>Fit vào noise</td><td>Fit vào signal</td></tr><tr><td><strong>Generalization</strong></td><td>Kém hơn</td><td><strong>Tốt hơn</strong></td></tr></tbody></table><p>Kết quả thực nghiệm cho thấy mô hình train trên validation set generalize tốt hơn đáng kể.</p><hr><h2 id="_4-multi-task-learning" tabindex="-1">4. Multi-Task Learning <a class="header-anchor" href="#_4-multi-task-learning" aria-label="Permalink to &quot;4. Multi-Task Learning&quot;">​</a></h2><h3 id="_4-1-bon-task-heads" tabindex="-1">4.1 Bốn Task Heads <a class="header-anchor" href="#_4-1-bon-task-heads" aria-label="Permalink to &quot;4.1 Bốn Task Heads&quot;">​</a></h3>',6)),(e(),r(h,null,{default:a(()=>[o(i,{id:"mermaid-316",class:"mermaid",graph:"flowchart%20TB%0A%20%20%20%20subgraph%20HEADS%5B%22B%E1%BB%91n%20Task%20Heads%22%5D%0A%20%20%20%20%20%20%20%20direction%20LR%0A%0A%20%20%20%20%20%20%20%20subgraph%20H1%5B%22Detection%20Head%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20H1_DESC%5B%22Gaussian%20Heatmap%3Cbr%2F%3E%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%3Cbr%2F%3EOutput%3A%201%20channel%3Cbr%2F%3ELoss%3A%20Focal%20Loss%3Cbr%2F%3EPeak%20detection%22%5D%0A%20%20%20%20%20%20%20%20end%0A%0A%20%20%20%20%20%20%20%20subgraph%20H2%5B%22Vessel%20Head%22%5D%0A%20%20%20%20%20%20%20%20H2_DESC%5B%22Binary%20Classification%3Cbr%2F%3E%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%3Cbr%2F%3EOutput%3A%201%20channel%3Cbr%2F%3ELoss%3A%20BCE%3Cbr%2F%3EVessel%20vs%20Infrastructure%22%5D%0A%20%20%20%20%20%20%20%20end%0A%0A%20%20%20%20%20%20%20%20subgraph%20H3%5B%22Fishing%20Head%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20H3_DESC%5B%22Binary%20Classification%3Cbr%2F%3E%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%3Cbr%2F%3EOutput%3A%201%20channel%3Cbr%2F%3ELoss%3A%20BCE%3Cbr%2F%3EFishing%20vs%20Non-fishing%22%5D%0A%20%20%20%20%20%20%20%20end%0A%0A%20%20%20%20%20%20%20%20subgraph%20H4%5B%22Length%20Head%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20H4_DESC%5B%22Regression%3Cbr%2F%3E%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%3Cbr%2F%3EOutput%3A%201%20channel%3Cbr%2F%3ELoss%3A%20L1%3Cbr%2F%3EMeters%20estimation%22%5D%0A%20%20%20%20%20%20%20%20end%0A%20%20%20%20end%0A"})]),fallback:a(()=>[...t[3]||(t[3]=[d(" Loading... ",-1)])]),_:1})),t[10]||(t[10]=n('<h3 id="_4-2-loss-weighting" tabindex="-1">4.2 Loss Weighting <a class="header-anchor" href="#_4-2-loss-weighting" aria-label="Permalink to &quot;4.2 Loss Weighting&quot;">​</a></h3><p>Mỗi task có trọng số loss khác nhau dựa trên độ quan trọng trong scoring:</p><table tabindex="0"><thead><tr><th>Task</th><th>Weight</th><th>Lý do</th></tr></thead><tbody><tr><td>Detection</td><td>1.0</td><td>Quan trọng nhất (50% score)</td></tr><tr><td>Vessel</td><td>0.5</td><td>20% score</td></tr><tr><td>Fishing</td><td>0.5</td><td>20% score</td></tr><tr><td>Length</td><td>0.2</td><td>10% score</td></tr></tbody></table><hr><h2 id="_5-processing-pipeline" tabindex="-1">5. Processing Pipeline <a class="header-anchor" href="#_5-processing-pipeline" aria-label="Permalink to &quot;5. Processing Pipeline&quot;">​</a></h2><h3 id="_5-1-tiling-strategy" tabindex="-1">5.1 Tiling Strategy <a class="header-anchor" href="#_5-1-tiling-strategy" aria-label="Permalink to &quot;5.1 Tiling Strategy&quot;">​</a></h3><p>Do scene SAR quá lớn (~700M pixels), cần chia thành tiles:</p>',7)),(e(),r(h,null,{default:a(()=>[o(i,{id:"mermaid-394",class:"mermaid",graph:"flowchart%20LR%0A%20%20%20%20subgraph%20FULL%5B%22Full%20Scene%22%5D%0A%20%20%20%20%20%20%20%20SCENE%5B%2229%2C400%20%C3%97%2024%2C400%3Cbr%2F%3Epixels%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20TILES%5B%22Tiling%22%5D%0A%20%20%20%20%20%20%20%20T1%5B%22Tile%201%3Cbr%2F%3E2048%C3%972048%22%5D%0A%20%20%20%20%20%20%20%20T2%5B%22Tile%202%3Cbr%2F%3E2048%C3%972048%22%5D%0A%20%20%20%20%20%20%20%20TN%5B%22Tile%20N%3Cbr%2F%3E...%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20OVERLAP%5B%22Overlap%22%5D%0A%20%20%20%20%20%20%20%20OV%5B%22512px%20overlap%3Cbr%2F%3EMerge%20predictions%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20FULL%20--%3E%20TILES%20--%3E%20OV%0A"})]),fallback:a(()=>[...t[4]||(t[4]=[d(" Loading... ",-1)])]),_:1})),t[11]||(t[11]=n('<h3 id="_5-2-augmentation" tabindex="-1">5.2 Augmentation <a class="header-anchor" href="#_5-2-augmentation" aria-label="Permalink to &quot;5.2 Augmentation&quot;">​</a></h3><p>Do đặc thù của SAR, augmentation cần cẩn thận:</p><table tabindex="0"><thead><tr><th>Augmentation</th><th>Áp dụng</th><th>Lý do</th></tr></thead><tbody><tr><td>Horizontal Flip</td><td>✅</td><td>SAR invariant</td></tr><tr><td>Vertical Flip</td><td>✅</td><td>SAR invariant</td></tr><tr><td>Rotation 90°</td><td>✅</td><td>SAR invariant</td></tr><tr><td>Color jitter</td><td>❌</td><td>SAR có ý nghĩa vật lý</td></tr><tr><td>Random erasing</td><td>❌</td><td>Có thể xóa targets</td></tr></tbody></table><hr><h2 id="_6-so-sanh-voi-hang-nhat" tabindex="-1">6. So Sánh Với Hạng Nhất <a class="header-anchor" href="#_6-so-sanh-voi-hang-nhat" aria-label="Permalink to &quot;6. So Sánh Với Hạng Nhất&quot;">​</a></h2><h3 id="_6-1-kien-truc" tabindex="-1">6.1 Kiến Trúc <a class="header-anchor" href="#_6-1-kien-truc" aria-label="Permalink to &quot;6.1 Kiến Trúc&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Khía cạnh</th><th>Hạng 1 (CircleNet)</th><th>Hạng 2 (U-Net)</th></tr></thead><tbody><tr><td><strong>Architecture</strong></td><td>Custom CircleNet</td><td>Standard U-Net</td></tr><tr><td><strong>Output stride</strong></td><td>Stride-2</td><td>Standard</td></tr><tr><td><strong>Complexity</strong></td><td>Cao</td><td>Thấp hơn</td></tr><tr><td><strong>Reproducibility</strong></td><td>Khó hơn</td><td>Dễ hơn</td></tr></tbody></table><h3 id="_6-2-chien-luoc" tabindex="-1">6.2 Chiến Lược <a class="header-anchor" href="#_6-2-chien-luoc" aria-label="Permalink to &quot;6.2 Chiến Lược&quot;">​</a></h3>',8)),(e(),r(h,null,{default:a(()=>[o(i,{id:"mermaid-544",class:"mermaid",graph:"flowchart%20TB%0A%20%20%20%20subgraph%20FIRST%5B%22H%E1%BA%A1ng%201%3A%20CircleNet%22%5D%0A%20%20%20%20%20%20%20%20F1%5B%2212%20model%20ensemble%22%5D%0A%20%20%20%20%20%20%20%20F2%5B%22Stride-2%20high-res%20output%22%5D%0A%20%20%20%20%20%20%20%20F3%5B%22Custom%20architecture%22%5D%0A%20%20%20%20%20%20%20%20F4%5B%22Full%20training%20set%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20SECOND%5B%22H%E1%BA%A1ng%202%3A%20U-Net%22%5D%0A%20%20%20%20%20%20%20%20S1%5B%22Smaller%20ensemble%22%5D%0A%20%20%20%20%20%20%20%20S2%5B%22Standard%20resolution%22%5D%0A%20%20%20%20%20%20%20%20S3%5B%22Standard%20U-Net%22%5D%0A%20%20%20%20%20%20%20%20S4%5B%22Validation%20set%20only%22%5D%0A%20%20%20%20end%0A"})]),fallback:a(()=>[...t[5]||(t[5]=[d(" Loading... ",-1)])]),_:1})),t[12]||(t[12]=n('<h3 id="_6-3-ket-qua" tabindex="-1">6.3 Kết Quả <a class="header-anchor" href="#_6-3-ket-qua" aria-label="Permalink to &quot;6.3 Kết Quả&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Metric</th><th>Hạng 1</th><th>Hạng 2</th><th>Gap</th></tr></thead><tbody><tr><td><strong>Holdout Score</strong></td><td>0.617</td><td>0.604</td><td>-2.1%</td></tr><tr><td><strong>Training Time</strong></td><td>Dài</td><td>Ngắn hơn</td><td>~40%</td></tr><tr><td><strong>Code Complexity</strong></td><td>Cao</td><td>Thấp</td><td>Đáng kể</td></tr></tbody></table><p>Với gap chỉ 2.1%, giải pháp đơn giản hơn của Sefidov có trade-off rất tốt giữa performance và complexity.</p><hr><h2 id="_7-bai-hoc-rut-ra" tabindex="-1">7. Bài Học Rút Ra <a class="header-anchor" href="#_7-bai-hoc-rut-ra" aria-label="Permalink to &quot;7. Bài Học Rút Ra&quot;">​</a></h2><h3 id="_7-1-cho-nghien-cuu" tabindex="-1">7.1 Cho Nghiên Cứu <a class="header-anchor" href="#_7-1-cho-nghien-cuu" aria-label="Permalink to &quot;7.1 Cho Nghiên Cứu&quot;">​</a></h3><ol><li><p><strong>Data quality quan trọng hơn quantity</strong>: Validation set nhỏ nhưng sạch tốt hơn training set lớn nhưng nhiễu</p></li><li><p><strong>Đơn giản có thể hiệu quả</strong>: U-Net tiêu chuẩn với encoder mạnh vẫn competitive</p></li><li><p><strong>Task-specific heads</strong>: Tách riêng các heads cho phép optimize từng task độc lập</p></li><li><p><strong>Paradigm shift giúp ích</strong>: Chuyển từ detection sang segmentation mang lại góc nhìn mới</p></li></ol><h3 id="_7-2-cho-thuc-hanh" tabindex="-1">7.2 Cho Thực Hành <a class="header-anchor" href="#_7-2-cho-thuc-hanh" aria-label="Permalink to &quot;7.2 Cho Thực Hành&quot;">​</a></h3><ol><li><p>Khi dữ liệu có noise cao, consider train trên subset chất lượng cao</p></li><li><p>U-Net vẫn là lựa chọn baseline rất mạnh cho dense prediction</p></li><li><p>Pretrained ImageNet weights vẫn hữu ích cho SAR dù domain khác biệt</p></li></ol><hr><h2 id="tai-lieu-tham-khao" tabindex="-1">Tài Liệu Tham Khảo <a class="header-anchor" href="#tai-lieu-tham-khao" aria-label="Permalink to &quot;Tài Liệu Tham Khảo&quot;">​</a></h2><ol><li><p>Ronneberger, O., Fischer, P., &amp; Brox, T. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation. MICCAI.</p></li><li><p>Tan, M., &amp; Le, Q. (2021). EfficientNetV2: Smaller Models and Faster Training. ICML.</p></li><li><p>Lin, T. Y., et al. (2017). Focal Loss for Dense Object Detection. ICCV.</p></li></ol><hr><p><em>Mục tiếp theo sẽ trình bày giải pháp hạng ba với kiến trúc Dual-Model Pipeline và HRNet backbone.</em></p>',14))])}const C=s(c,[["render",u]]);export{T as __pageData,C as default};
