import{_ as s,c as a,o as e,a2 as n}from"./chunks/framework.nRfFlDZQ.js";const k=JSON.parse('{"title":"Chương 5: Pre-trained Weights và Sensor Support trong TorchGeo","description":"","frontmatter":{},"headers":[],"relativePath":"chuong-05-torchgeo/muc-05-pretrained-weights/01-pretrained-weights.md","filePath":"chuong-05-torchgeo/muc-05-pretrained-weights/01-pretrained-weights.md","lastUpdated":null}'),t={name:"chuong-05-torchgeo/muc-05-pretrained-weights/01-pretrained-weights.md"};function l(r,i,h,p,o,d){return e(),a("div",null,[...i[0]||(i[0]=[n(`<h1 id="chuong-5-pre-trained-weights-va-sensor-support-trong-torchgeo" tabindex="-1">Chương 5: Pre-trained Weights và Sensor Support trong TorchGeo <a class="header-anchor" href="#chuong-5-pre-trained-weights-va-sensor-support-trong-torchgeo" aria-label="Permalink to &quot;Chương 5: Pre-trained Weights và Sensor Support trong TorchGeo&quot;">​</a></h1><h2 id="_6-40-tong-quan-pre-trained-weights" tabindex="-1">6.40. Tổng quan Pre-trained Weights <a class="header-anchor" href="#_6-40-tong-quan-pre-trained-weights" aria-label="Permalink to &quot;6.40. Tổng quan Pre-trained Weights&quot;">​</a></h2><p>Pre-trained weights là một trong những đóng góp quan trọng nhất của TorchGeo cho remote sensing community. Thay vì training models từ scratch hoặc sử dụng ImageNet pretrained weights không phù hợp với satellite imagery, TorchGeo cung cấp weights được train đặc biệt trên dữ liệu vệ tinh, cho performance tốt hơn đáng kể trên downstream tasks.</p><p>Trong phần này, chúng ta sẽ phân tích chi tiết các pre-trained weights có sẵn, sensor support, và cách sử dụng hiệu quả cho các ứng dụng khác nhau.</p><h2 id="_6-41-ssl4eo-pre-trained-weights" tabindex="-1">6.41. SSL4EO Pre-trained Weights <a class="header-anchor" href="#_6-41-ssl4eo-pre-trained-weights" aria-label="Permalink to &quot;6.41. SSL4EO Pre-trained Weights&quot;">​</a></h2><h3 id="_6-41-1-tong-quan-ssl4eo" tabindex="-1">6.41.1. Tổng quan SSL4EO <a class="header-anchor" href="#_6-41-1-tong-quan-ssl4eo" aria-label="Permalink to &quot;6.41.1. Tổng quan SSL4EO&quot;">​</a></h3><p>SSL4EO (Self-Supervised Learning for Earth Observation) là initiative để tạo pre-trained models cho Earth Observation data sử dụng self-supervised learning.</p><p><strong>SSL4EO-S12:</strong> Dataset và weights cho Sentinel-1 và Sentinel-2:</p><ul><li>200,000+ image triplets</li><li>European coverage</li><li>Seasonal variations captured</li><li>Multiple pre-training methods</li></ul><p><strong>Tại sao Self-supervised:</strong></p><ul><li>Không cần labeled data (expensive và limited cho remote sensing)</li><li>Learns general representations</li><li>Transfers well to various tasks</li><li>Scales với available data</li></ul><h3 id="_6-41-2-moco-pre-training" tabindex="-1">6.41.2. MoCo Pre-training <a class="header-anchor" href="#_6-41-2-moco-pre-training" aria-label="Permalink to &quot;6.41.2. MoCo Pre-training&quot;">​</a></h3><p>Momentum Contrast (MoCo) cho remote sensing:</p><p><strong>Method:</strong></p><ul><li>Contrastive learning framework</li><li>Query và key encoders</li><li>Momentum update cho key encoder</li><li>Large negative sample queue</li></ul><p><strong>SSL4EO MoCo Weights:</strong></p><table tabindex="0"><thead><tr><th>Model</th><th>Input</th><th>Weight Name</th></tr></thead><tbody><tr><td>ResNet-18</td><td>Sentinel-2 All Bands</td><td>SENTINEL2_ALL_MOCO</td></tr><tr><td>ResNet-50</td><td>Sentinel-2 All Bands</td><td>SENTINEL2_ALL_MOCO</td></tr><tr><td>ResNet-50</td><td>Sentinel-2 RGB Only</td><td>SENTINEL2_RGB_MOCO</td></tr><tr><td>ResNet-50</td><td>Sentinel-1 All Bands</td><td>SENTINEL1_ALL_MOCO</td></tr></tbody></table><p><strong>Usage:</strong></p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torchgeo.models </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ResNet50_Weights, resnet50</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Load với Sentinel-2 MoCo weights</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ResNet50_Weights.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SENTINEL2_ALL_MOCO</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> resnet50(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">weights</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Access transforms</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">transform </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> weights.transforms()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h3 id="_6-41-3-mae-pre-training" tabindex="-1">6.41.3. MAE Pre-training <a class="header-anchor" href="#_6-41-3-mae-pre-training" aria-label="Permalink to &quot;6.41.3. MAE Pre-training&quot;">​</a></h3><p>Masked Autoencoder pre-training cho Vision Transformers:</p><p><strong>Method:</strong></p><ul><li>Mask random patches of image</li><li>Reconstruct masked patches</li><li>Learns strong representations</li></ul><p><strong>SSL4EO MAE Weights:</strong></p><table tabindex="0"><thead><tr><th>Model</th><th>Input</th><th>Weight Name</th></tr></thead><tbody><tr><td>ViT-Small</td><td>Sentinel-2</td><td>SENTINEL2_ALL_MAE</td></tr><tr><td>ViT-Base</td><td>Sentinel-2</td><td>SENTINEL2_ALL_MAE</td></tr></tbody></table><p><strong>Advantages:</strong></p><ul><li>Excellent cho ViT architectures</li><li>Data-efficient training</li><li>Strong transfer performance</li></ul><h3 id="_6-41-4-dino-pre-training" tabindex="-1">6.41.4. DINO Pre-training <a class="header-anchor" href="#_6-41-4-dino-pre-training" aria-label="Permalink to &quot;6.41.4. DINO Pre-training&quot;">​</a></h3><p>Self-Distillation với No Labels:</p><p><strong>Method:</strong></p><ul><li>Student-teacher framework</li><li>Teacher is momentum-updated student</li><li>Knowledge distillation without labels</li></ul><p><strong>SSL4EO DINO Weights:</strong></p><table tabindex="0"><thead><tr><th>Model</th><th>Input</th><th>Weight Name</th></tr></thead><tbody><tr><td>ViT-Small</td><td>Sentinel-2</td><td>SENTINEL2_ALL_DINO</td></tr><tr><td>ViT-Base</td><td>Sentinel-2</td><td>SENTINEL2_ALL_DINO</td></tr></tbody></table><p><strong>Characteristics:</strong></p><ul><li>Good for ViT models</li><li>Learns semantic features</li><li>Works well on diverse tasks</li></ul><h2 id="_6-42-satmae-weights" tabindex="-1">6.42. SatMAE Weights <a class="header-anchor" href="#_6-42-satmae-weights" aria-label="Permalink to &quot;6.42. SatMAE Weights&quot;">​</a></h2><h3 id="_6-42-1-overview" tabindex="-1">6.42.1. Overview <a class="header-anchor" href="#_6-42-1-overview" aria-label="Permalink to &quot;6.42.1. Overview&quot;">​</a></h3><p>SatMAE (Satellite Masked Autoencoder) specifically designed cho satellite imagery:</p><p><strong>Key Features:</strong></p><ul><li>Temporal encoding cho time series</li><li>Multi-spectral positional embeddings</li><li>Global-scale pre-training</li><li>Designed cho fMoW dataset</li></ul><h3 id="_6-42-2-available-weights" tabindex="-1">6.42.2. Available Weights <a class="header-anchor" href="#_6-42-2-available-weights" aria-label="Permalink to &quot;6.42.2. Available Weights&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Model</th><th>Dataset</th><th>Resolution</th></tr></thead><tbody><tr><td>ViT-Large</td><td>fMoW RGB</td><td>Various</td></tr><tr><td>ViT-Large</td><td>fMoW Temporal</td><td>Multi-date</td></tr></tbody></table><h3 id="_6-42-3-temporal-capabilities" tabindex="-1">6.42.3. Temporal Capabilities <a class="header-anchor" href="#_6-42-3-temporal-capabilities" aria-label="Permalink to &quot;6.42.3. Temporal Capabilities&quot;">​</a></h3><p>SatMAE handles temporal dimension:</p><ul><li>Multiple dates as input</li><li>Temporal position encoding</li><li>Good for change detection và time series</li></ul><h2 id="_6-43-sensor-specific-weights" tabindex="-1">6.43. Sensor-specific Weights <a class="header-anchor" href="#_6-43-sensor-specific-weights" aria-label="Permalink to &quot;6.43. Sensor-specific Weights&quot;">​</a></h2><h3 id="_6-43-1-sentinel-2-weights" tabindex="-1">6.43.1. Sentinel-2 Weights <a class="header-anchor" href="#_6-43-1-sentinel-2-weights" aria-label="Permalink to &quot;6.43.1. Sentinel-2 Weights&quot;">​</a></h3><p><strong>Available Pre-training:</strong></p><ul><li>SSL4EO MoCo (ResNet)</li><li>SSL4EO MAE (ViT)</li><li>SSL4EO DINO (ViT)</li><li>SatMAE (ViT)</li><li>BigEarthNet supervised</li></ul><p><strong>Band Support:</strong></p><ul><li>All 13 bands: Complete spectral information</li><li>RGB only: B4, B3, B2 (10m resolution)</li><li>RGB + NIR: B4, B3, B2, B8</li></ul><p><strong>Usage với All Bands:</strong></p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># ResNet-50 với 13-band Sentinel-2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ResNet50_Weights.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SENTINEL2_ALL_MOCO</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> resnet50(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">weights</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_chans</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">13</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h3 id="_6-43-2-sentinel-1-weights" tabindex="-1">6.43.2. Sentinel-1 Weights <a class="header-anchor" href="#_6-43-2-sentinel-1-weights" aria-label="Permalink to &quot;6.43.2. Sentinel-1 Weights&quot;">​</a></h3><p><strong>Available Pre-training:</strong></p><ul><li>SSL4EO MoCo</li></ul><p><strong>Polarization Support:</strong></p><ul><li>VV + VH: Dual polarization</li><li>Single polarization options</li></ul><p><strong>SAR-specific Considerations:</strong></p><ul><li>Log-scale normalization</li><li>Speckle handling</li><li>Different value distributions than optical</li></ul><p><strong>Usage:</strong></p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># ResNet-50 cho Sentinel-1</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ResNet50_Weights.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SENTINEL1_ALL_MOCO</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> resnet50(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">weights</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_chans</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># VV, VH</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h3 id="_6-43-3-landsat-weights" tabindex="-1">6.43.3. Landsat Weights <a class="header-anchor" href="#_6-43-3-landsat-weights" aria-label="Permalink to &quot;6.43.3. Landsat Weights&quot;">​</a></h3><p><strong>Current Status:</strong></p><ul><li>Fewer dedicated weights than Sentinel</li><li>Can use Sentinel weights với adaptation</li><li>Some benchmark-specific weights</li></ul><p><strong>Approach:</strong></p><ul><li>Use Sentinel-2 weights (similar bands)</li><li>Adapt first layer for Landsat bands</li><li>Fine-tune on Landsat data</li></ul><h3 id="_6-43-4-high-resolution-imagery" tabindex="-1">6.43.4. High-resolution Imagery <a class="header-anchor" href="#_6-43-4-high-resolution-imagery" aria-label="Permalink to &quot;6.43.4. High-resolution Imagery&quot;">​</a></h3><p>For aerial và very-high-resolution satellite:</p><p><strong>Options:</strong></p><ul><li>NAIP-specific training</li><li>ImageNet weights (often sufficient for RGB)</li><li>Million-AID pre-training</li></ul><p><strong>Considerations:</strong></p><ul><li>Usually RGB or RGBIR</li><li>Higher spatial resolution</li><li>Different object scales</li></ul><h2 id="_6-44-weight-comparison-va-selection" tabindex="-1">6.44. Weight Comparison và Selection <a class="header-anchor" href="#_6-44-weight-comparison-va-selection" aria-label="Permalink to &quot;6.44. Weight Comparison và Selection&quot;">​</a></h2><h3 id="_6-44-1-performance-comparison" tabindex="-1">6.44.1. Performance Comparison <a class="header-anchor" href="#_6-44-1-performance-comparison" aria-label="Permalink to &quot;6.44.1. Performance Comparison&quot;">​</a></h3><p><strong>EuroSAT (Sentinel-2 Classification):</strong></p><table tabindex="0"><thead><tr><th>Weights</th><th>ResNet-50 Accuracy</th></tr></thead><tbody><tr><td>Random Init</td><td>89.2%</td></tr><tr><td>ImageNet</td><td>95.5%</td></tr><tr><td>SSL4EO MoCo</td><td>97.2%</td></tr><tr><td>SSL4EO MAE (ViT)</td><td>97.8%</td></tr></tbody></table><p><strong>Key Insight:</strong> Domain-specific pre-training outperforms ImageNet by 1.5-2%.</p><h3 id="_6-44-2-selection-guidelines" tabindex="-1">6.44.2. Selection Guidelines <a class="header-anchor" href="#_6-44-2-selection-guidelines" aria-label="Permalink to &quot;6.44.2. Selection Guidelines&quot;">​</a></h3><p><strong>Sentinel-2 Tasks:</strong></p><ul><li>First choice: SSL4EO MoCo/MAE weights</li><li>Alternative: BigEarthNet pre-trained</li></ul><p><strong>Sentinel-1 Tasks:</strong></p><ul><li>Use: SSL4EO Sentinel-1 weights</li><li>Critical: Match polarization channels</li></ul><p><strong>High-resolution RGB:</strong></p><ul><li>ImageNet weights often sufficient</li><li>Million-AID for aerial specific</li><li>Fine-tuning usually needed</li></ul><p><strong>Multi-sensor:</strong></p><ul><li>Separate encoders với sensor-specific weights</li><li>Fusion at feature level</li></ul><h3 id="_6-44-3-when-to-use-what" tabindex="-1">6.44.3. When to Use What <a class="header-anchor" href="#_6-44-3-when-to-use-what" aria-label="Permalink to &quot;6.44.3. When to Use What&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Scenario</th><th>Recommended Weights</th></tr></thead><tbody><tr><td>Sentinel-2 classification</td><td>SSL4EO MoCo/MAE</td></tr><tr><td>Sentinel-2 segmentation</td><td>SSL4EO MoCo encoder</td></tr><tr><td>Sentinel-1 classification</td><td>SSL4EO S1 MoCo</td></tr><tr><td>SAR ship detection</td><td>SSL4EO S1 or ImageNet</td></tr><tr><td>High-res buildings</td><td>ImageNet or Million-AID</td></tr><tr><td>Temporal analysis</td><td>SatMAE</td></tr></tbody></table><h2 id="_6-45-adapting-weights-cho-different-inputs" tabindex="-1">6.45. Adapting Weights cho Different Inputs <a class="header-anchor" href="#_6-45-adapting-weights-cho-different-inputs" aria-label="Permalink to &quot;6.45. Adapting Weights cho Different Inputs&quot;">​</a></h2><h3 id="_6-45-1-channel-mismatch" tabindex="-1">6.45.1. Channel Mismatch <a class="header-anchor" href="#_6-45-1-channel-mismatch" aria-label="Permalink to &quot;6.45.1. Channel Mismatch&quot;">​</a></h3><p>When input channels differ từ pre-trained weights:</p><p><strong>Fewer Channels:</strong></p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Pre-trained on 13 bands, using 4 (RGBIR)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Option 1: Select matching weights</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> resnet50(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">weights</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Manually select first conv weights for bands</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Option 2: Average redundant channels</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Pre-trained weights: 13 channels</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># New input: 4 channels</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Average groups of weights</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p><strong>More Channels:</strong></p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Pre-trained on 3 (RGB), using 13</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Duplicate và tile RGB weights</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Or initialize extra channels randomly</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p><strong>TorchGeo Approach:</strong> TorchGeo models often handle this automatically với in_chans parameter.</p><h3 id="_6-45-2-resolution-mismatch" tabindex="-1">6.45.2. Resolution Mismatch <a class="header-anchor" href="#_6-45-2-resolution-mismatch" aria-label="Permalink to &quot;6.45.2. Resolution Mismatch&quot;">​</a></h3><p>When spatial resolution differs:</p><p><strong>Interpolation:</strong></p><ul><li>Bilinear resize input to expected resolution</li><li>Or modify patch/window sizes</li></ul><p><strong>Considerations:</strong></p><ul><li>Very different resolutions may need different architectures</li><li>Feature scales may not transfer well</li></ul><h3 id="_6-45-3-value-range-adaptation" tabindex="-1">6.45.3. Value Range Adaptation <a class="header-anchor" href="#_6-45-3-value-range-adaptation" aria-label="Permalink to &quot;6.45.3. Value Range Adaptation&quot;">​</a></h3><p>Different sensors have different value ranges:</p><p><strong>Normalization:</strong></p><ul><li>Use sensor-specific statistics</li><li>Match distribution của pre-training data</li><li>TorchGeo provides normalization stats</li></ul><h2 id="_6-46-fine-tuning-strategies" tabindex="-1">6.46. Fine-tuning Strategies <a class="header-anchor" href="#_6-46-fine-tuning-strategies" aria-label="Permalink to &quot;6.46. Fine-tuning Strategies&quot;">​</a></h2><h3 id="_6-46-1-full-fine-tuning" tabindex="-1">6.46.1. Full Fine-tuning <a class="header-anchor" href="#_6-46-1-full-fine-tuning" aria-label="Permalink to &quot;6.46.1. Full Fine-tuning&quot;">​</a></h3><p>Update all parameters:</p><ul><li>Best when sufficient data available</li><li>Highest performance potential</li><li>Risk of overfitting on small datasets</li></ul><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> resnet50(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">weights</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ssl4eo_weights)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">optimizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Adam(model.parameters(), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">lr</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h3 id="_6-46-2-linear-probing" tabindex="-1">6.46.2. Linear Probing <a class="header-anchor" href="#_6-46-2-linear-probing" aria-label="Permalink to &quot;6.46.2. Linear Probing&quot;">​</a></h3><p>Freeze pre-trained layers, only train classifier:</p><ul><li>Quick baseline</li><li>Tests feature quality</li><li>Works với minimal data</li></ul><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> resnet50(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">weights</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ssl4eo_weights)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Freeze backbone</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> param </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.parameters():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    param.requires_grad </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> False</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Unfreeze classifier</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> param </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.fc.parameters():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    param.requires_grad </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h3 id="_6-46-3-progressive-unfreezing" tabindex="-1">6.46.3. Progressive Unfreezing <a class="header-anchor" href="#_6-46-3-progressive-unfreezing" aria-label="Permalink to &quot;6.46.3. Progressive Unfreezing&quot;">​</a></h3><p>Gradually unfreeze layers:</p><ol><li>Train classifier only</li><li>Unfreeze last block</li><li>Unfreeze more blocks</li><li>Fine-tune entire model</li></ol><p><strong>Benefits:</strong></p><ul><li>Stable training</li><li>Preserves pre-trained features</li><li>Good for limited data</li></ul><h3 id="_6-46-4-layer-wise-learning-rates" tabindex="-1">6.46.4. Layer-wise Learning Rates <a class="header-anchor" href="#_6-46-4-layer-wise-learning-rates" aria-label="Permalink to &quot;6.46.4. Layer-wise Learning Rates&quot;">​</a></h3><p>Different learning rates for different depths:</p><ul><li>Lower LR for early (pre-trained) layers</li><li>Higher LR for later layers và new heads</li></ul><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">optimizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Adam([</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;params&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: model.layer1.parameters(), </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;lr&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;params&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: model.layer2.parameters(), </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;lr&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;params&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: model.layer3.parameters(), </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;lr&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;params&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: model.layer4.parameters(), </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;lr&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;params&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: model.fc.parameters(), </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;lr&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h2 id="_6-47-practical-considerations" tabindex="-1">6.47. Practical Considerations <a class="header-anchor" href="#_6-47-practical-considerations" aria-label="Permalink to &quot;6.47. Practical Considerations&quot;">​</a></h2><h3 id="_6-47-1-memory-va-compute" tabindex="-1">6.47.1. Memory và Compute <a class="header-anchor" href="#_6-47-1-memory-va-compute" aria-label="Permalink to &quot;6.47.1. Memory và Compute&quot;">​</a></h3><p><strong>Model Sizes:</strong></p><table tabindex="0"><thead><tr><th>Model</th><th>Parameters</th><th>Memory (inference)</th></tr></thead><tbody><tr><td>ResNet-18</td><td>11M</td><td>~200MB</td></tr><tr><td>ResNet-50</td><td>25M</td><td>~400MB</td></tr><tr><td>ViT-Base</td><td>86M</td><td>~700MB</td></tr><tr><td>ViT-Large</td><td>307M</td><td>~2.5GB</td></tr></tbody></table><p><strong>Considerations:</strong></p><ul><li>Edge deployment: ResNet-18, MobileNet</li><li>Server deployment: ResNet-50, ViT-Base</li><li>Research: ViT-Large</li></ul><h3 id="_6-47-2-inference-speed" tabindex="-1">6.47.2. Inference Speed <a class="header-anchor" href="#_6-47-2-inference-speed" aria-label="Permalink to &quot;6.47.2. Inference Speed&quot;">​</a></h3><p><strong>Typical FPS (GPU):</strong></p><table tabindex="0"><thead><tr><th>Model</th><th>Input Size</th><th>FPS</th></tr></thead><tbody><tr><td>ResNet-18</td><td>224×224</td><td>~500</td></tr><tr><td>ResNet-50</td><td>224×224</td><td>~200</td></tr><tr><td>ViT-Base</td><td>224×224</td><td>~100</td></tr></tbody></table><p><strong>Considerations:</strong></p><ul><li>Real-time applications: ResNet-18, MobileNet</li><li>Batch processing: ResNet-50, ViT-Base acceptable</li></ul><h3 id="_6-47-3-data-requirements" tabindex="-1">6.47.3. Data Requirements <a class="header-anchor" href="#_6-47-3-data-requirements" aria-label="Permalink to &quot;6.47.3. Data Requirements&quot;">​</a></h3><p><strong>Guidelines:</strong></p><table tabindex="0"><thead><tr><th>Data Amount</th><th>Strategy</th></tr></thead><tbody><tr><td>&lt;100 samples</td><td>Linear probing only</td></tr><tr><td>100-1000</td><td>Progressive unfreezing</td></tr><tr><td>1000-10000</td><td>Full fine-tuning với care</td></tr><tr><td>&gt;10000</td><td>Full fine-tuning</td></tr></tbody></table><p>Pre-trained weights reduce data requirements by 10x or more.</p><h2 id="_6-48-accessing-weights" tabindex="-1">6.48. Accessing Weights <a class="header-anchor" href="#_6-48-accessing-weights" aria-label="Permalink to &quot;6.48. Accessing Weights&quot;">​</a></h2><h3 id="_6-48-1-torchgeo-weight-enum" tabindex="-1">6.48.1. TorchGeo Weight Enum <a class="header-anchor" href="#_6-48-1-torchgeo-weight-enum" aria-label="Permalink to &quot;6.48.1. TorchGeo Weight Enum&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torchgeo.models </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ResNet18_Weights,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ResNet50_Weights,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ViTSmall16_Weights,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># List available weights</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(ResNet50_Weights.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__members__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h3 id="_6-48-2-loading-weights" tabindex="-1">6.48.2. Loading Weights <a class="header-anchor" href="#_6-48-2-loading-weights" aria-label="Permalink to &quot;6.48.2. Loading Weights&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Method 1: Through model factory</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> resnet50(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">weights</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ResNet50_Weights.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SENTINEL2_ALL_MOCO</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Method 2: Load và apply manually</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ResNet50_Weights.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SENTINEL2_ALL_MOCO</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> resnet50()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model.load_state_dict(weights.get_state_dict(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">progress</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Method 3: Custom loading</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">state_dict </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.load(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;path/to/weights.pth&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model.load_state_dict(state_dict)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><h3 id="_6-48-3-weight-metadata" tabindex="-1">6.48.3. Weight Metadata <a class="header-anchor" href="#_6-48-3-weight-metadata" aria-label="Permalink to &quot;6.48.3. Weight Metadata&quot;">​</a></h3><p>Weights include metadata:</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ResNet50_Weights.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SENTINEL2_ALL_MOCO</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Access metadata</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(weights.meta)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># {&#39;bands&#39;: [&#39;B01&#39;, &#39;B02&#39;, ...], &#39;mean&#39;: [...], &#39;std&#39;: [...]}</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Get transforms</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">transform </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> weights.transforms()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h2 id="_6-49-future-directions" tabindex="-1">6.49. Future Directions <a class="header-anchor" href="#_6-49-future-directions" aria-label="Permalink to &quot;6.49. Future Directions&quot;">​</a></h2><h3 id="_6-49-1-more-sensors" tabindex="-1">6.49.1. More Sensors <a class="header-anchor" href="#_6-49-1-more-sensors" aria-label="Permalink to &quot;6.49.1. More Sensors&quot;">​</a></h3><p>Expanding support cho:</p><ul><li>MODIS</li><li>VIIRS</li><li>Pléiades, WorldView</li><li>Commercial SAR (ICEYE, Capella)</li><li>Hyperspectral</li></ul><h3 id="_6-49-2-foundation-models" tabindex="-1">6.49.2. Foundation Models <a class="header-anchor" href="#_6-49-2-foundation-models" aria-label="Permalink to &quot;6.49.2. Foundation Models&quot;">​</a></h3><p>Trend toward large foundation models:</p><ul><li>IBM/NASA Prithvi</li><li>Google/DeepMind Earth models</li><li>Generalist remote sensing models</li></ul><h3 id="_6-49-3-multi-modal-pre-training" tabindex="-1">6.49.3. Multi-modal Pre-training <a class="header-anchor" href="#_6-49-3-multi-modal-pre-training" aria-label="Permalink to &quot;6.49.3. Multi-modal Pre-training&quot;">​</a></h3><p>Joint pre-training on:</p><ul><li>Optical + SAR</li><li>Satellite + text</li><li>Image + location</li></ul><h3 id="_6-49-4-efficient-pre-training" tabindex="-1">6.49.4. Efficient Pre-training <a class="header-anchor" href="#_6-49-4-efficient-pre-training" aria-label="Permalink to &quot;6.49.4. Efficient Pre-training&quot;">​</a></h3><p>Reducing compute requirements:</p><ul><li>Knowledge distillation</li><li>Efficient architectures</li><li>Progressive training</li></ul><h2 id="_6-50-summary-va-recommendations" tabindex="-1">6.50. Summary và Recommendations <a class="header-anchor" href="#_6-50-summary-va-recommendations" aria-label="Permalink to &quot;6.50. Summary và Recommendations&quot;">​</a></h2><h3 id="_6-50-1-quick-start-recommendations" tabindex="-1">6.50.1. Quick Start Recommendations <a class="header-anchor" href="#_6-50-1-quick-start-recommendations" aria-label="Permalink to &quot;6.50.1. Quick Start Recommendations&quot;">​</a></h3><p><strong>Sentinel-2 RGB:</strong></p><ul><li>ResNet-50 + SSL4EO MoCo</li><li>Good balance of performance và efficiency</li></ul><p><strong>Sentinel-2 All Bands:</strong></p><ul><li>ResNet-50 + SSL4EO MoCo (all bands)</li><li>Use all spectral information</li></ul><p><strong>Sentinel-1 SAR:</strong></p><ul><li>ResNet-50 + SSL4EO S1 MoCo</li><li>Essential cho SAR applications</li></ul><p><strong>Vision Transformer:</strong></p><ul><li>ViT-Base + SSL4EO MAE</li><li>Best overall performance</li></ul><h3 id="_6-50-2-best-practices" tabindex="-1">6.50.2. Best Practices <a class="header-anchor" href="#_6-50-2-best-practices" aria-label="Permalink to &quot;6.50.2. Best Practices&quot;">​</a></h3><ol><li><strong>Always use domain-specific weights</strong> when available</li><li><strong>Match input channels</strong> to pre-training</li><li><strong>Use appropriate normalization</strong> statistics</li><li><strong>Start với linear probing</strong> to test</li><li><strong>Progressive unfreezing</strong> for limited data</li><li><strong>Monitor validation metrics</strong> for overfitting</li></ol><h3 id="_6-50-3-common-mistakes" tabindex="-1">6.50.3. Common Mistakes <a class="header-anchor" href="#_6-50-3-common-mistakes" aria-label="Permalink to &quot;6.50.3. Common Mistakes&quot;">​</a></h3><ul><li>Using ImageNet weights without adaptation for multi-spectral</li><li>Ignoring normalization differences</li><li>Full fine-tuning với insufficient data</li><li>Wrong input channel configuration</li><li>Mismatched transforms</li></ul><p>TorchGeo pre-trained weights represent significant advancement cho remote sensing deep learning, enabling practitioners to achieve strong performance với reduced data và compute requirements.</p>`,176)])])}const c=s(t,[["render",l]]);export{k as __pageData,c as default};
