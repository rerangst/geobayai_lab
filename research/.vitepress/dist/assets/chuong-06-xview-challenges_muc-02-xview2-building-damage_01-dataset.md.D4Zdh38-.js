import{_ as e,C as h,c as l,o as a,a2 as i,b as r,w as s,a as p,G as o,a3 as c}from"./chunks/framework.nRfFlDZQ.js";const d="/sen_doc/assets/fig1-disaster-examples.hwdQmHNn.png",g="/sen_doc/assets/fig3-disaster-types-map.BRZH0h5u.png",u="/sen_doc/assets/fig9-damage-distribution.fBFEflMl.png",k="/sen_doc/assets/fig4-joint-damage-scale.Dyi8twA3.png",m="/sen_doc/assets/fig5-building-polygons.Cqp_pOp9.png",D=JSON.parse('{"title":"Chương 6: Bộ Dữ Liệu xView2 (xBD): Đánh Giá Thiệt Hại Công Trình Từ Ảnh Vệ Tinh","description":"","frontmatter":{},"headers":[],"relativePath":"chuong-06-xview-challenges/muc-02-xview2-building-damage/01-dataset.md","filePath":"chuong-06-xview-challenges/muc-02-xview2-building-damage/01-dataset.md","lastUpdated":null}'),b={name:"chuong-06-xview-challenges/muc-02-xview2-building-damage/01-dataset.md"};function E(y,n,v,C,F,B){const t=h("Mermaid");return a(),l("div",null,[n[1]||(n[1]=i('<h1 id="chuong-6-bo-du-lieu-xview2-xbd-đanh-gia-thiet-hai-cong-trinh-tu-anh-ve-tinh" tabindex="-1">Chương 6: Bộ Dữ Liệu xView2 (xBD): Đánh Giá Thiệt Hại Công Trình Từ Ảnh Vệ Tinh <a class="header-anchor" href="#chuong-6-bo-du-lieu-xview2-xbd-đanh-gia-thiet-hai-cong-trinh-tu-anh-ve-tinh" aria-label="Permalink to &quot;Chương 6: Bộ Dữ Liệu xView2 (xBD): Đánh Giá Thiệt Hại Công Trình Từ Ảnh Vệ Tinh&quot;">​</a></h1><h2 id="tong-quan" tabindex="-1">Tổng Quan <a class="header-anchor" href="#tong-quan" aria-label="Permalink to &quot;Tổng Quan&quot;">​</a></h2><table tabindex="0"><thead><tr><th>Thuộc tính</th><th>Giá trị</th></tr></thead><tbody><tr><td><strong>Tên chính thức</strong></td><td>xBD (xView Building Damage Dataset)</td></tr><tr><td><strong>Năm phát hành</strong></td><td>2019</td></tr><tr><td><strong>Đơn vị tổ chức</strong></td><td>Defense Innovation Unit (DIU), Carnegie Mellon University SEI</td></tr><tr><td><strong>Nhiệm vụ</strong></td><td>Building Localization + Damage Classification</td></tr><tr><td><strong>Cuộc thi</strong></td><td>xView2: Assess Building Damage Challenge</td></tr><tr><td><strong>Số người đăng ký</strong></td><td>2,000+</td></tr><tr><td><strong>Bài báo</strong></td><td><a href="https://arxiv.org/abs/1911.09296" target="_blank" rel="noreferrer">Creating xBD: A Dataset for Assessing Building Damage (CVPR 2019)</a></td></tr><tr><td><strong>GitHub</strong></td><td><a href="https://github.com/DIUx-xView/xView2_baseline" target="_blank" rel="noreferrer">DIUx-xView/xView2_baseline</a></td></tr></tbody></table><hr><h2 id="_1-gioi-thieu-va-boi-canh" tabindex="-1">1. Giới Thiệu và Bối Cảnh <a class="header-anchor" href="#_1-gioi-thieu-va-boi-canh" aria-label="Permalink to &quot;1. Giới Thiệu và Bối Cảnh&quot;">​</a></h2><h3 id="_1-1-nhu-cau-đanh-gia-thiet-hai-tu-đong" tabindex="-1">1.1. Nhu Cầu Đánh Giá Thiệt Hại Tự Động <a class="header-anchor" href="#_1-1-nhu-cau-đanh-gia-thiet-hai-tu-đong" aria-label="Permalink to &quot;1.1. Nhu Cầu Đánh Giá Thiệt Hại Tự Động&quot;">​</a></h3><p><img src="'+d+'" alt="Ví dụ các loại thảm họa"><em>Hình 1: Ví dụ về các loại thảm họa trong dataset xBD - Hurricane Harvey, Palu Tsunami, Mexico Earthquake, Santa Rosa Fire</em></p><p>Khi thảm họa thiên nhiên xảy ra, việc đánh giá nhanh chóng và chính xác mức độ thiệt hại trở thành yếu tố then chốt cho công tác cứu hộ và phân bổ nguồn lực. Trước đây, quy trình này phụ thuộc hoàn toàn vào các đội khảo sát thực địa - một phương pháp không chỉ tốn kém về thời gian mà còn tiềm ẩn nhiều nguy hiểm cho nhân viên khi di chuyển qua các khu vực bị tàn phá. Một trận động đất có thể phá hủy hàng chục nghìn công trình, và việc kiểm tra từng tòa nhà theo phương pháp truyền thống có thể mất nhiều ngày đến nhiều tuần.</p><p>Ảnh vệ tinh độ phân giải cao mở ra khả năng thay thế hoặc bổ sung cho phương pháp khảo sát thực địa. Các vệ tinh thương mại như WorldView, GeoEye, và Pléiades có thể chụp ảnh bất kỳ điểm nào trên Trái Đất với độ phân giải dưới một mét, cho phép nhận diện rõ ràng các công trình riêng lẻ và các dấu hiệu thiệt hại như sụp đổ mái, cháy rụi, hoặc ngập lụt. Tuy nhiên, việc phân tích thủ công khối lượng lớn ảnh vệ tinh vẫn là nút thắt cổ chai - một chuyên gia có thể mất hàng giờ để đánh giá một khu vực nhỏ.</p><p>Đây chính là lý do dataset xBD (xView Building Damage) được tạo ra. Được phát triển bởi Defense Innovation Unit (DIU) phối hợp với Carnegie Mellon University Software Engineering Institute (CMU SEI), xBD cung cấp nền tảng dữ liệu cho việc huấn luyện các mô hình deep learning có khả năng tự động đánh giá thiệt hại công trình từ ảnh vệ tinh. Mục tiêu cuối cùng là tạo ra hệ thống có thể phân tích toàn bộ một thành phố bị ảnh hưởng trong vòng vài phút, thay vì nhiều ngày như trước đây.</p><h3 id="_1-2-lich-su-phat-trien-xbd" tabindex="-1">1.2. Lịch Sử Phát Triển xBD <a class="header-anchor" href="#_1-2-lich-su-phat-trien-xbd" aria-label="Permalink to &quot;1.2. Lịch Sử Phát Triển xBD&quot;">​</a></h3><p>xBD ra đời như phần tiếp nối tự nhiên của xView1. Trong khi xView1 tập trung vào object detection đa lớp trong điều kiện bình thường, xView2 hướng đến một bài toán chuyên biệt hơn nhưng có tính ứng dụng trực tiếp cao hơn: đánh giá thiệt hại sau thảm họa.</p><p>Quá trình phát triển xBD bắt đầu từ năm 2018 khi nhóm nghiên cứu CMU SEI nhận ra thiếu sót lớn trong các dataset hiện có. Các tập dữ liệu trước đó như Harvey Homes Dataset chỉ chứa vài nghìn công trình từ một thảm họa duy nhất, không đủ để huấn luyện mô hình có khả năng tổng quát hóa tốt. Hơn nữa, không có thang đo thiệt hại chuẩn hóa - mỗi nghiên cứu sử dụng tiêu chí riêng, gây khó khăn cho việc so sánh và đánh giá.</p><p>Nhóm nghiên cứu đã hợp tác với các chuyên gia ứng phó thảm họa từ NASA, FEMA (Federal Emergency Management Agency), CAL FIRE, và California Air National Guard để xây dựng Joint Damage Scale - thang đo thiệt hại bốn cấp độ được thiết kế để vừa có ý nghĩa thực tiễn cho công tác cứu trợ, vừa có thể phân biệt được từ ảnh vệ tinh. Đây là một trong những đóng góp quan trọng nhất của xBD: lần đầu tiên có một tiêu chuẩn thống nhất cho việc phân loại thiệt hại công trình từ góc nhìn trên không.</p><p>Dataset chính thức được công bố tại CVPR 2019 Workshop on Computer Vision for Global Challenges, cùng với baseline model và challenge platform. Cuộc thi xView2 thu hút hơn 2,000 người đăng ký từ các trường đại học, phòng thí nghiệm nghiên cứu, và công ty công nghệ trên toàn thế giới.</p><h3 id="_1-3-maxar-open-data-program" tabindex="-1">1.3. Maxar Open Data Program <a class="header-anchor" href="#_1-3-maxar-open-data-program" aria-label="Permalink to &quot;1.3. Maxar Open Data Program&quot;">​</a></h3><p>Một yếu tố then chốt cho sự thành công của xBD là Maxar (trước đây là DigitalGlobe) Open Data Program. Đây là chương trình mà Maxar - công ty sở hữu các vệ tinh độ phân giải cao nhất thế giới - phát hành ảnh vệ tinh miễn phí sau các thảm họa lớn để hỗ trợ công tác cứu trợ và nghiên cứu.</p><p>Maxar Open Data Program cung cấp ảnh từ các vệ tinh WorldView-1, WorldView-2, WorldView-3, và GeoEye-1 với ground sample distance (GSD) từ 0.3 đến 0.8 mét. Điều đặc biệt quan trọng là chương trình thường phát hành cả ảnh trước thảm họa (pre-disaster) lẫn ảnh sau thảm họa (post-disaster), tạo điều kiện cho việc so sánh trực tiếp và phát hiện thay đổi.</p><p>Nhờ nguồn dữ liệu này, xBD có thể bao phủ 19 sự kiện thảm họa khác nhau trên 15 quốc gia, từ động đất ở Mexico đến sóng thần ở Indonesia, từ cháy rừng ở California đến lũ lụt ở Bangladesh. Sự đa dạng này là điểm mạnh quan trọng của dataset, giúp mô hình học được các pattern thiệt hại phổ quát thay vì chỉ chuyên biệt cho một loại thảm họa.</p><h3 id="_1-4-muc-tieu-nghien-cuu-va-ung-dung-thuc-tien" tabindex="-1">1.4. Mục Tiêu Nghiên Cứu và Ứng Dụng Thực Tiễn <a class="header-anchor" href="#_1-4-muc-tieu-nghien-cuu-va-ung-dung-thuc-tien" aria-label="Permalink to &quot;1.4. Mục Tiêu Nghiên Cứu và Ứng Dụng Thực Tiễn&quot;">​</a></h3><p>xBD được thiết kế với hai mục tiêu chính: thúc đẩy nghiên cứu computer vision trong lĩnh vực remote sensing, và cung cấp giải pháp thực tiễn cho ứng phó thảm họa.</p><p>Về mặt nghiên cứu, xBD đặt ra bài toán two-stage prediction đầy thách thức: đầu tiên phải định vị (localize) các công trình trong ảnh, sau đó phân loại mức độ thiệt hại của từng công trình. Bài toán này yêu cầu kết hợp nhiều kỹ thuật: semantic segmentation cho building footprint extraction, change detection giữa cặp ảnh pre/post-disaster, và fine-grained classification cho damage assessment. Các giải pháp chiến thắng đã sử dụng Siamese networks, multi-task learning, và các kỹ thuật xử lý class imbalance tiên tiến.</p><p>Về mặt ứng dụng thực tiễn, xBD đã được chứng minh hiệu quả trong các tình huống thực tế. California Air National Guard đã sử dụng mô hình huấn luyện trên xBD để đánh giá thiệt hại từ các trận cháy rừng năm 2020. Theo báo cáo, hệ thống có thể phân tích một khu vực rộng lớn trong 10-20 phút, so với 1-2 ngày khi sử dụng phương pháp thủ công. Kết quả này không chỉ tiết kiệm thời gian mà còn cho phép các đội cứu hộ ưu tiên những khu vực bị ảnh hưởng nặng nhất.</p><h3 id="_1-5-so-sanh-voi-cac-dataset-lien-quan" tabindex="-1">1.5. So Sánh Với Các Dataset Liên Quan <a class="header-anchor" href="#_1-5-so-sanh-voi-cac-dataset-lien-quan" aria-label="Permalink to &quot;1.5. So Sánh Với Các Dataset Liên Quan&quot;">​</a></h3><p>Trước khi xBD xuất hiện, các dataset về building damage assessment có quy mô hạn chế. Harvey Homes Dataset chỉ chứa khoảng 5,000 công trình từ Hurricane Harvey. Tomnod crowdsourcing data có số lượng lớn hơn nhưng thiếu consistency trong annotation và không có cặp ảnh pre/post-disaster. OpenStreetMap cung cấp building footprint nhưng không có thông tin về thiệt hại.</p><p>xBD vượt trội về mọi khía cạnh: 850,736 building polygon - gấp 170 lần Harvey Homes; 19 sự kiện thảm họa đa dạng thay vì chỉ một; thang đo thiệt hại chuẩn hóa với bốn cấp độ; và cặp ảnh pre/post-disaster cho mọi location. Đây là lý do xBD nhanh chóng trở thành benchmark tiêu chuẩn cho bài toán building damage assessment từ ảnh vệ tinh.</p><hr><h2 id="_2-thong-so-ky-thuat-va-thong-ke" tabindex="-1">2. Thông Số Kỹ Thuật và Thống Kê <a class="header-anchor" href="#_2-thong-so-ky-thuat-va-thong-ke" aria-label="Permalink to &quot;2. Thông Số Kỹ Thuật và Thống Kê&quot;">​</a></h2><h3 id="_2-1-quy-mo-tong-the" tabindex="-1">2.1. Quy Mô Tổng Thể <a class="header-anchor" href="#_2-1-quy-mo-tong-the" aria-label="Permalink to &quot;2.1. Quy Mô Tổng Thể&quot;">​</a></h3><p>xBD là một trong những dataset lớn nhất cho bài toán building damage assessment, với quy mô được thiết kế để hỗ trợ huấn luyện các mô hình deep learning phức tạp.</p><table tabindex="0"><thead><tr><th>Chỉ số</th><th>Giá trị</th></tr></thead><tbody><tr><td><strong>Số annotation công trình</strong></td><td>850,736 polygon</td></tr><tr><td><strong>Diện tích bao phủ</strong></td><td>45,362 km²</td></tr><tr><td><strong>Tổng số ảnh</strong></td><td>22,068</td></tr><tr><td><strong>Số cặp ảnh pre/post</strong></td><td>11,034</td></tr><tr><td><strong>Kích thước ảnh</strong></td><td>1024 × 1024 pixel</td></tr><tr><td><strong>Định dạng màu</strong></td><td>RGB (3-band)</td></tr><tr><td><strong>Số sự kiện thảm họa</strong></td><td>19</td></tr><tr><td><strong>Số loại thảm họa</strong></td><td>6</td></tr><tr><td><strong>Số quốc gia</strong></td><td>15+</td></tr><tr><td><strong>Ground sample distance</strong></td><td>&lt; 0.8 mét</td></tr><tr><td><strong>Dung lượng download</strong></td><td>~10 GB (compressed), ~11 GB (uncompressed)</td></tr></tbody></table><p>Với hơn 850,000 building polygon, xBD cung cấp đủ dữ liệu để huấn luyện các kiến trúc deep learning phức tạp mà không bị overfitting. Con số này đặc biệt ấn tượng khi so sánh với các dataset trước đó - Harvey Homes chỉ có 5,000 công trình, trong khi xBD có gấp 170 lần.</p><h3 id="_2-2-phan-chia-du-lieu" tabindex="-1">2.2. Phân Chia Dữ Liệu <a class="header-anchor" href="#_2-2-phan-chia-du-lieu" aria-label="Permalink to &quot;2.2. Phân Chia Dữ Liệu&quot;">​</a></h3><p>Dataset được chia thành ba tập với tỷ lệ được thiết kế để cân bằng giữa training capacity và evaluation reliability.</p><table tabindex="0"><thead><tr><th>Tập</th><th>Số polygon công trình</th><th>Số ảnh</th><th>Số cặp pre/post</th><th>Mục đích</th></tr></thead><tbody><tr><td><strong>Train</strong></td><td>632,228</td><td>18,336</td><td>9,168</td><td>Huấn luyện mô hình</td></tr><tr><td><strong>Test</strong></td><td>109,724</td><td>1,866</td><td>933</td><td>Đánh giá trong cuộc thi</td></tr><tr><td><strong>Holdout</strong></td><td>108,784</td><td>1,866</td><td>933</td><td>Đánh giá cuối cùng</td></tr><tr><td><strong>Tổng</strong></td><td>850,736</td><td>22,068</td><td>11,034</td><td>-</td></tr></tbody></table><p>Training set chiếm khoảng 74% tổng số polygon, đủ lớn để mô hình học được các pattern đa dạng. Test và Holdout set mỗi cái chiếm khoảng 13%, đảm bảo đánh giá reliable trên dữ liệu chưa thấy.</p><p>Đáng chú ý là sự phân chia được thực hiện theo disaster event - các ảnh từ cùng một thảm họa không bị chia ra giữa train và test. Điều này đảm bảo mô hình được đánh giá về khả năng generalization sang các thảm họa mới, thay vì chỉ memorize các pattern từ thảm họa đã thấy.</p><h3 id="_2-3-thong-so-ky-thuat-anh" tabindex="-1">2.3. Thông Số Kỹ Thuật Ảnh <a class="header-anchor" href="#_2-3-thong-so-ky-thuat-anh" aria-label="Permalink to &quot;2.3. Thông Số Kỹ Thuật Ảnh&quot;">​</a></h3><p>Ảnh trong xBD đến từ Maxar Open Data Program với các thông số kỹ thuật được tối ưu hóa cho computer vision.</p><p><strong>Nguồn ảnh vệ tinh:</strong></p><ul><li>WorldView-1, WorldView-2, WorldView-3 (Maxar)</li><li>GeoEye-1 (Maxar)</li><li>Ground sample distance: 0.3 - 0.8 mét</li></ul><p><strong>Thông số ảnh được cung cấp:</strong></p><ul><li>Định dạng: PNG (RGB, 24-bit)</li><li>Kích thước: 1024 × 1024 pixel</li><li>Color space: sRGB</li><li>Bit depth: 8-bit per channel</li><li>Off-nadir angle: Variable (thực tế từ các góc chụp khác nhau)</li></ul><p><strong>Metadata đi kèm:</strong></p><ul><li>Tọa độ địa lý (longitude, latitude)</li><li>Thông tin sự kiện thảm họa</li><li>Timestamp chụp ảnh</li><li>Thông tin sensor (khi available)</li></ul><p>Kích thước ảnh 1024×1024 được chọn như một cân bằng giữa context coverage và computational efficiency. Với GSD &lt; 0.8m, mỗi ảnh cover một diện tích khoảng 0.65-0.85 km², đủ để chứa nhiều công trình nhưng vẫn giữ được chi tiết cần thiết cho damage assessment.</p><h3 id="_2-4-cac-su-kien-tham-hoa" tabindex="-1">2.4. Các Sự Kiện Thảm Họa <a class="header-anchor" href="#_2-4-cac-su-kien-tham-hoa" aria-label="Permalink to &quot;2.4. Các Sự Kiện Thảm Họa&quot;">​</a></h3><p>xBD bao phủ 19 sự kiện thảm họa từ 6 loại khác nhau, đảm bảo diversity cho việc huấn luyện mô hình generalizable.</p><p><img src="'+g+'" alt="Phân bố địa lý các thảm họa"><em>Hình 2: Phân bố địa lý của các sự kiện thảm họa trong dataset xBD</em></p><table tabindex="0"><thead><tr><th>Loại thảm họa</th><th>Số sự kiện</th><th>Các sự kiện tiêu biểu</th></tr></thead><tbody><tr><td><strong>Hurricane/Typhoon</strong></td><td>5</td><td>Harvey (TX), Michael (FL), Florence (NC), Maria (PR), Matthew (Haiti)</td></tr><tr><td><strong>Wildfire</strong></td><td>4</td><td>Paradise Fire (CA), Woolsey Fire (CA), Santa Rosa Fire (CA), Pinery Bushfire (AU)</td></tr><tr><td><strong>Earthquake/Tsunami</strong></td><td>4</td><td>Mexico City 2017, Palu-Sulawesi 2018, Nepal 2015, Lombok 2018</td></tr><tr><td><strong>Flooding</strong></td><td>3</td><td>Midwest Flooding 2019, Bangladesh Monsoon, Nepal Flood</td></tr><tr><td><strong>Tornado</strong></td><td>2</td><td>Joplin 2011, Tuscaloosa 2011</td></tr><tr><td><strong>Volcanic</strong></td><td>1</td><td>Guatemala Fuego 2018</td></tr></tbody></table><p><strong>Phân bố địa lý:</strong></p><ul><li>Bắc Mỹ (USA, Mexico): ~60%</li><li>Trung Mỹ (Guatemala, Honduras): ~15%</li><li>Châu Á (Indonesia, Nepal, Bangladesh): ~15%</li><li>Châu Úc (Australia): ~5%</li><li>Khác: ~5%</li></ul><p>Sự phân bố này phản ánh availability của Maxar Open Data - các thảm họa ở Mỹ thường được cover nhanh hơn và đầy đủ hơn. Tuy nhiên, sự đa dạng về loại thảm họa và kiến trúc công trình (từ nhà gỗ California đến nhà bê tông Indonesia) vẫn đảm bảo mô hình có thể học được các damage pattern phổ quát.</p><h3 id="_2-5-phan-bo-label-va-class-imbalance" tabindex="-1">2.5. Phân Bố Label và Class Imbalance <a class="header-anchor" href="#_2-5-phan-bo-label-va-class-imbalance" aria-label="Permalink to &quot;2.5. Phân Bố Label và Class Imbalance&quot;">​</a></h3><p>Một trong những thách thức lớn nhất của xBD là class imbalance nghiêm trọng trong damage labels.</p><p><img src="'+u+`" alt="Damage Distribution"><em>Hình 5: Phân bố các cấp độ thiệt hại trong dataset</em></p><table tabindex="0"><thead><tr><th>Cấp độ thiệt hại</th><th>Số polygon</th><th>Tỷ lệ</th><th>Ghi chú</th></tr></thead><tbody><tr><td><strong>Không thiệt hại (0)</strong></td><td>313,033</td><td>36.8%</td><td>~73.5% trong số có label</td></tr><tr><td><strong>Thiệt hại nhỏ (1)</strong></td><td>36,860</td><td>4.3%</td><td>~8.6% trong số có label</td></tr><tr><td><strong>Thiệt hại lớn (2)</strong></td><td>29,904</td><td>3.5%</td><td>~7.0% trong số có label</td></tr><tr><td><strong>Bị phá hủy (3)</strong></td><td>31,560</td><td>3.7%</td><td>~7.4% trong số có label</td></tr><tr><td><strong>Chưa phân loại</strong></td><td>~440,000</td><td>51.7%</td><td>Background/không có công trình</td></tr></tbody></table><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Phân bố (chỉ tính các công trình có label):</span></span>
<span class="line"><span>Không thiệt hại: ████████████████████████████████████████████████████████████  73.5%</span></span>
<span class="line"><span>Thiệt hại nhỏ:   ████████                                                        8.6%</span></span>
<span class="line"><span>Thiệt hại lớn:   ███████                                                         7.0%</span></span>
<span class="line"><span>Bị phá hủy:      ███████                                                         7.4%</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p><strong>Imbalance ratio:</strong> Class &quot;không thiệt hại&quot; có số lượng gấp ~8 lần mỗi class thiệt hại khác. Đây là thực tế của đánh giá thiệt hại: ngay cả trong các thảm họa lớn nhất, đa số công trình vẫn sống sót mà không bị hư hại.</p><p><strong>Tác động đến training:</strong></p><ul><li>Naive training sẽ tạo ra mô hình bias toward &quot;không thiệt hại&quot;</li><li>Cần sử dụng weighted loss function hoặc oversampling strategies</li><li>Focal loss đặc biệt hiệu quả cho bài toán này</li><li>Các giải pháp top thường sử dụng class weights từ 2-4x cho các class thiệt hại</li></ul><hr><h2 id="_3-he-thong-phan-loai-va-annotation" tabindex="-1">3. Hệ Thống Phân Loại và Annotation <a class="header-anchor" href="#_3-he-thong-phan-loai-va-annotation" aria-label="Permalink to &quot;3. Hệ Thống Phân Loại và Annotation&quot;">​</a></h2><h3 id="_3-1-joint-damage-scale-thang-đo-thiet-hai-chuan-hoa" tabindex="-1">3.1. Joint Damage Scale: Thang Đo Thiệt Hại Chuẩn Hóa <a class="header-anchor" href="#_3-1-joint-damage-scale-thang-đo-thiet-hai-chuan-hoa" aria-label="Permalink to &quot;3.1. Joint Damage Scale: Thang Đo Thiệt Hại Chuẩn Hóa&quot;">​</a></h3><p>Một trong những đóng góp quan trọng nhất của xBD là việc phát triển Joint Damage Scale - thang đo thiệt hại bốn cấp độ được xây dựng với sự tham gia của các chuyên gia ứng phó thảm họa hàng đầu. Nhóm nghiên cứu đã làm việc trực tiếp với các chuyên gia từ NASA Disasters Program, FEMA Urban Search and Rescue, CAL FIRE, và California Air National Guard để đảm bảo thang đo vừa có ý nghĩa thực tiễn cho công tác cứu trợ, vừa có thể phân biệt được từ ảnh vệ tinh.</p><p><img src="`+k+`" alt="Joint Damage Scale"><em>Hình 3: Joint Damage Scale - Thang đo thiệt hại 4 cấp độ (0: No Damage, 1: Minor, 2: Major, 3: Destroyed)</em></p><p><strong>Nguyên tắc thiết kế:</strong></p><ol><li><strong>Ordinal scale:</strong> Các cấp độ có thứ tự rõ ràng từ nhẹ đến nặng</li><li><strong>Observable from above:</strong> Có thể nhận diện được từ góc nhìn vệ tinh</li><li><strong>Actionable:</strong> Phản ánh khả năng sử dụng của công trình</li><li><strong>Cross-disaster applicable:</strong> Áp dụng được cho mọi loại thảm họa</li></ol><h3 id="_3-2-chi-tiet-bon-cap-đo-thiet-hai" tabindex="-1">3.2. Chi Tiết Bốn Cấp Độ Thiệt Hại <a class="header-anchor" href="#_3-2-chi-tiet-bon-cap-đo-thiet-hai" aria-label="Permalink to &quot;3.2. Chi Tiết Bốn Cấp Độ Thiệt Hại&quot;">​</a></h3><p><strong>Cấp độ 0: Không thiệt hại (No Damage)</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Đặc điểm nhận dạng:</span></span>
<span class="line"><span>├── Mái nhà nguyên vẹn, không có vết nứt hoặc hư hỏng</span></span>
<span class="line"><span>├── Không có mảnh vỡ xung quanh công trình</span></span>
<span class="line"><span>├── Ngoại quan hoàn toàn bình thường</span></span>
<span class="line"><span>├── Có thể có thay đổi môi trường (nước, bụi) nhưng công trình không bị ảnh hưởng</span></span>
<span class="line"><span>└── Công trình có thể sử dụng được ngay</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>Đây là class phổ biến nhất trong dataset, chiếm ~73% các công trình có label. Ngay cả trong các thảm họa lớn, phần lớn công trình vẫn sống sót mà không bị thiệt hại nhìn thấy được từ vệ tinh.</p><p><strong>Cấp độ 1: Thiệt hại nhỏ (Minor Damage)</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Đặc điểm nhận dạng:</span></span>
<span class="line"><span>├── Mái nhà bị hư hỏng &lt; 25% diện tích</span></span>
<span class="line"><span>├── Một số ngói hoặc tấm lợp bị mất</span></span>
<span class="line"><span>├── Mảnh vỡ nhỏ xung quanh công trình</span></span>
<span class="line"><span>├── Có thể có vết cháy xém hoặc nước đọng xung quanh</span></span>
<span class="line"><span>├── Cấu trúc chính còn nguyên vẹn</span></span>
<span class="line"><span>└── Công trình còn có thể sử dụng với sửa chữa nhỏ</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>Đây là class khó nhận diện nhất vì thiệt hại thường tinh tế và khó phân biệt với class 0 từ độ cao vệ tinh. Các annotator cần xem xét kỹ các chi tiết như màu sắc mái thay đổi, mảnh vỡ nhỏ, hoặc các dấu hiệu cháy xém nhẹ.</p><p><strong>Cấp độ 2: Thiệt hại lớn (Major Damage)</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Đặc điểm nhận dạng:</span></span>
<span class="line"><span>├── Mái nhà bị hư hỏng 25-50% diện tích</span></span>
<span class="line"><span>├── Một phần tường hoặc mái bị sụp đổ</span></span>
<span class="line"><span>├── Mảnh vỡ lớn xung quanh công trình</span></span>
<span class="line"><span>├── Có thể nhìn thấy nội thất từ trên cao</span></span>
<span class="line"><span>├── Cấu trúc bị ảnh hưởng nghiêm trọng</span></span>
<span class="line"><span>└── Cần sửa chữa lớn trước khi sử dụng được</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>Class này thể hiện thiệt hại đáng kể nhưng chưa phải phá hủy hoàn toàn. Các dấu hiệu thường rõ ràng hơn class 1: phần mái bị thiếu, tường nghiêng, hoặc mảnh vỡ rõ ràng.</p><p><strong>Cấp độ 3: Bị phá hủy (Destroyed)</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Đặc điểm nhận dạng:</span></span>
<span class="line"><span>├── Mái nhà bị hư hỏng &gt; 50% hoặc hoàn toàn mất</span></span>
<span class="line"><span>├── Sụp đổ hoàn toàn hoặc gần như hoàn toàn</span></span>
<span class="line"><span>├── Chỉ còn lại nền móng hoặc một phần tường</span></span>
<span class="line"><span>├── Mảnh vỡ phủ khắp khu vực công trình</span></span>
<span class="line"><span>├── Không còn nhận ra hình dạng công trình ban đầu</span></span>
<span class="line"><span>└── Không thể sử dụng được, cần xây dựng lại</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>Đây là class dễ nhận diện nhất vì thiệt hại rất rõ ràng. Tuy nhiên, cần phân biệt với class 2 khi công trình bị hư hỏng nặng nhưng vẫn còn cấu trúc cơ bản.</p><h3 id="_3-3-quy-trinh-annotation" tabindex="-1">3.3. Quy Trình Annotation <a class="header-anchor" href="#_3-3-quy-trinh-annotation" aria-label="Permalink to &quot;3.3. Quy Trình Annotation&quot;">​</a></h3><p>Annotation xBD được thực hiện theo quy trình hai giai đoạn để đảm bảo chất lượng và consistency.</p><p><strong>Giai đoạn 1: Building Polygon Annotation (trên ảnh pre-disaster)</strong></p><p>Các annotator vẽ polygon cho tất cả công trình có thể nhìn thấy trên ảnh trước thảm họa. Việc annotate trên ảnh pre-disaster có hai lợi thế: công trình còn nguyên vẹn nên dễ xác định ranh giới chính xác, và đảm bảo mọi công trình (kể cả những công trình bị phá hủy hoàn toàn sau đó) đều được ghi nhận.</p><p><img src="`+m+`" alt="Building Polygon Annotations"><em>Hình 4: Ví dụ về building polygon annotations trên ảnh vệ tinh</em></p><p>Polygon được vẽ bám sát building footprint - ranh giới của công trình khi nhìn từ trên cao. Công cụ annotation sử dụng QGIS với các extension tùy chỉnh để tăng tốc độ và đảm bảo format chuẩn.</p><p><strong>Giai đoạn 2: Damage Classification (trên ảnh post-disaster)</strong></p><p>Các polygon từ giai đoạn 1 được overlay lên ảnh sau thảm họa. Annotator so sánh trực tiếp giữa pre và post để xác định mức độ thiệt hại của từng công trình theo Joint Damage Scale.</p><p><strong>Quality Control:</strong></p><ul><li>Mỗi annotation được review bởi ít nhất một chuyên gia khác</li><li>Các trường hợp khó được escalate cho nhóm chuyên gia thảm họa</li><li>Estimated error rate: ~2-3% annotations bị mislabel</li><li>Systematic corrections được áp dụng sau khi phát hiện patterns lỗi</li></ul><h3 id="_3-4-annotation-bo-sung-environmental-factors" tabindex="-1">3.4. Annotation Bổ Sung: Environmental Factors <a class="header-anchor" href="#_3-4-annotation-bo-sung-environmental-factors" aria-label="Permalink to &quot;3.4. Annotation Bổ Sung: Environmental Factors&quot;">​</a></h3><p>Ngoài damage labels cho công trình, xBD còn cung cấp polygon annotation cho các yếu tố môi trường liên quan đến thảm họa.</p><table tabindex="0"><thead><tr><th>Yếu tố</th><th>Loại thảm họa áp dụng</th><th>Mô tả</th></tr></thead><tbody><tr><td><strong>Smoke</strong></td><td>Wildfire</td><td>Vùng bị che phủ bởi khói, ảnh hưởng visibility</td></tr><tr><td><strong>Fire</strong></td><td>Wildfire</td><td>Vùng đang cháy hoặc có dấu hiệu lửa</td></tr><tr><td><strong>Flood water</strong></td><td>Flood, Hurricane</td><td>Vùng ngập nước</td></tr><tr><td><strong>Pyroclastic flow</strong></td><td>Volcanic</td><td>Dòng chảy pyroclastic từ núi lửa</td></tr><tr><td><strong>Lava</strong></td><td>Volcanic</td><td>Dòng dung nham</td></tr></tbody></table><p>Các environmental labels này hữu ích cho việc phân tích context và có thể được sử dụng như features bổ sung trong mô hình prediction.</p><h3 id="_3-5-đinh-dang-du-lieu" tabindex="-1">3.5. Định Dạng Dữ Liệu <a class="header-anchor" href="#_3-5-đinh-dang-du-lieu" aria-label="Permalink to &quot;3.5. Định Dạng Dữ Liệu&quot;">​</a></h3><p><strong>Cấu trúc thư mục:</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>xBD/</span></span>
<span class="line"><span>├── train/</span></span>
<span class="line"><span>│   ├── images/</span></span>
<span class="line"><span>│   │   ├── {disaster}_{id}_pre_disaster.png</span></span>
<span class="line"><span>│   │   ├── {disaster}_{id}_post_disaster.png</span></span>
<span class="line"><span>│   │   └── ...</span></span>
<span class="line"><span>│   └── labels/</span></span>
<span class="line"><span>│       ├── {disaster}_{id}_pre_disaster.json</span></span>
<span class="line"><span>│       ├── {disaster}_{id}_post_disaster.json</span></span>
<span class="line"><span>│       └── ...</span></span>
<span class="line"><span>├── test/</span></span>
<span class="line"><span>│   ├── images/</span></span>
<span class="line"><span>│   └── labels/</span></span>
<span class="line"><span>└── holdout/</span></span>
<span class="line"><span>    ├── images/</span></span>
<span class="line"><span>    └── labels/</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><p><strong>Quy ước đặt tên:</strong></p><ul><li>Format: <code>{disaster_name}_{image_id}_{pre|post}_disaster.{ext}</code></li><li>Ví dụ: <code>hurricane-michael_00123_post_disaster.png</code></li><li>Disaster name sử dụng kebab-case (hurricane-harvey, santa-rosa-wildfire)</li></ul><p><strong>Format label JSON:</strong></p><div class="language-json vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;features&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;lng_lat&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">longitude</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">latitude</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;xy&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">      {</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">&quot;wkt&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;POLYGON ((x1 y1, x2 y2, x3 y3, ...))&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  },</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;metadata&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;disaster&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;hurricane-michael&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;disaster_type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;hurricane&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;img_name&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;hurricane-michael_00123_post_disaster.png&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  },</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;properties&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;subtype&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;residential&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;feature_type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;building&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;uid&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;unique_building_id_string&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  },</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;labels&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;damage&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;destroyed&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br></div></div><p><strong>Damage label values:</strong></p><ul><li><code>&quot;no-damage&quot;</code> → Cấp độ 0</li><li><code>&quot;minor-damage&quot;</code> → Cấp độ 1</li><li><code>&quot;major-damage&quot;</code> → Cấp độ 2</li><li><code>&quot;destroyed&quot;</code> → Cấp độ 3</li><li><code>&quot;un-classified&quot;</code> → Không có công trình (background)</li></ul><hr><h2 id="_4-quy-trinh-tao-dataset" tabindex="-1">4. Quy Trình Tạo Dataset <a class="header-anchor" href="#_4-quy-trinh-tao-dataset" aria-label="Permalink to &quot;4. Quy Trình Tạo Dataset&quot;">​</a></h2><h3 id="_4-1-tong-quan-pipeline" tabindex="-1">4.1. Tổng Quan Pipeline <a class="header-anchor" href="#_4-1-tong-quan-pipeline" aria-label="Permalink to &quot;4.1. Tổng Quan Pipeline&quot;">​</a></h3><p>Việc tạo xBD là một quy trình phức tạp đòi hỏi sự phối hợp giữa nhiều đơn vị và chuyên gia. Pipeline tổng thể bao gồm sáu bước chính, từ thu thập ảnh vệ tinh đến kiểm tra chất lượng cuối cùng.</p>`,108)),(a(),r(c,null,{default:s(()=>[o(t,{id:"mermaid-976",class:"mermaid",graph:"flowchart%20TB%0A%20%20%20%20subgraph%20Phase1%5BThu%20Th%E1%BA%ADp%20D%E1%BB%AF%20Li%E1%BB%87u%5D%0A%20%20%20%20%20%20%20%20A1%5BMaxar%20Open%20Data%3Cbr%2F%3EProgram%20ph%C3%A1t%20h%C3%A0nh%3Cbr%2F%3E%E1%BA%A3nh%20sau%20th%E1%BA%A3m%20h%E1%BB%8Da%5D%20--%3E%20A2%5BThu%20th%E1%BA%ADp%20%E1%BA%A3nh%3Cbr%2F%3Epre%20v%C3%A0%20post%3Cbr%2F%3Edisaster%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20Phase2%5BS%C3%A0ng%20L%E1%BB%8Dc%5D%0A%20%20%20%20%20%20%20%20B1%5BL%E1%BB%8Dc%20%E1%BA%A3nh%20theo%3Cbr%2F%3Ech%E1%BA%A5t%20l%C6%B0%E1%BB%A3ng%20v%C3%A0%3Cbr%2F%3Ecoverage%5D%20--%3E%20B2%5BX%C3%A1c%20%C4%91%E1%BB%8Bnh%20khu%3Cbr%2F%3Ev%E1%BB%B1c%20c%C3%B3%20thi%E1%BB%87t%20h%E1%BA%A1i%3Cbr%2F%3Eth%E1%BB%B1c%20t%E1%BA%BF%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20Phase3%5BAnnotation%5D%0A%20%20%20%20%20%20%20%20C1%5BV%E1%BA%BD%20building%3Cbr%2F%3Epolygon%20tr%C3%AAn%3Cbr%2F%3E%E1%BA%A3nh%20pre-disaster%5D%20--%3E%20C2%5BPh%C3%A2n%20lo%E1%BA%A1i%20thi%E1%BB%87t%3Cbr%2F%3Eh%E1%BA%A1i%20b%E1%BA%B1ng%20so%20s%C3%A1nh%3Cbr%2F%3Epre%2Fpost%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20Phase4%5BQuality%20Control%5D%0A%20%20%20%20%20%20%20%20D1%5BReview%20b%E1%BB%9Fi%3Cbr%2F%3Eannotator%20th%E1%BB%A9%20hai%5D%20--%3E%20D2%5BX%C3%A1c%20th%E1%BB%B1c%20b%E1%BB%9Fi%3Cbr%2F%3Echuy%C3%AAn%20gia%3Cbr%2F%3Eth%E1%BA%A3m%20h%E1%BB%8Da%5D%0A%20%20%20%20end%0A%0A%20%20%20%20Phase1%20--%3E%20Phase2%20--%3E%20Phase3%20--%3E%20Phase4%0A"})]),fallback:s(()=>[...n[0]||(n[0]=[p(" Loading... ",-1)])]),_:1})),n[2]||(n[2]=i(`<h3 id="_4-2-buoc-1-thu-thap-anh-tu-maxar-open-data" tabindex="-1">4.2. Bước 1: Thu Thập Ảnh Từ Maxar Open Data <a class="header-anchor" href="#_4-2-buoc-1-thu-thap-anh-tu-maxar-open-data" aria-label="Permalink to &quot;4.2. Bước 1: Thu Thập Ảnh Từ Maxar Open Data&quot;">​</a></h3><p>Khi một thảm họa lớn xảy ra, Maxar thường phát hành ảnh vệ tinh trong vòng 24-48 giờ thông qua Open Data Program. Nhóm nghiên cứu xBD monitor các phát hành này và đánh giá khả năng sử dụng cho dataset.</p><p><strong>Tiêu chí lựa chọn:</strong></p><ul><li><strong>GSD:</strong> &lt; 0.8 mét để đảm bảo có thể nhận diện công trình riêng lẻ</li><li><strong>Cloud cover:</strong> &lt; 20% để đảm bảo visibility</li><li><strong>Pre-disaster availability:</strong> Phải có ảnh trước thảm họa của cùng khu vực</li><li><strong>Alignment quality:</strong> Pre và post phải có thể align được với sai số chấp nhận được</li><li><strong>Damage presence:</strong> Khu vực phải có thiệt hại thực tế (không chọn vùng không bị ảnh hưởng)</li></ul><p><strong>Xử lý ảnh:</strong></p><ul><li>Download ảnh GeoTIFF gốc từ Maxar</li><li>Chuyển đổi sang PNG RGB 8-bit</li><li>Tile ảnh lớn thành các tile 1024×1024</li><li>Loại bỏ các tile chủ yếu là nước, rừng, hoặc không có công trình</li></ul><h3 id="_4-3-buoc-2-pre-processing-va-alignment" tabindex="-1">4.3. Bước 2: Pre-processing và Alignment <a class="header-anchor" href="#_4-3-buoc-2-pre-processing-va-alignment" aria-label="Permalink to &quot;4.3. Bước 2: Pre-processing và Alignment&quot;">​</a></h3><p>Một trong những thách thức kỹ thuật lớn nhất là alignment giữa ảnh pre và post-disaster. Do các ảnh được chụp từ các góc off-nadir khác nhau, có thể có pixel shift đáng kể.</p><p><strong>Quy trình alignment:</strong></p><ol><li>Sử dụng feature matching (SIFT/ORB) để tìm control points</li><li>Compute affine transformation matrix</li><li>Warp ảnh post-disaster để align với pre-disaster</li><li>Tính toán residual shift và document trong metadata</li></ol><p><strong>Vấn đề không thể giải quyết hoàn toàn:</strong></p><ul><li>Building parallax do góc chụp khác nhau</li><li>Một số khu vực không có đủ feature để align</li><li>Mây hoặc smoke che phủ một phần ảnh</li></ul><p>Nhóm nghiên cứu đã đo lường và ghi nhận pixel offset cho mỗi tile, cho phép các nghiên cứu sau có thể áp dụng correction nếu cần.</p><h3 id="_4-4-buoc-3-building-polygon-annotation" tabindex="-1">4.4. Bước 3: Building Polygon Annotation <a class="header-anchor" href="#_4-4-buoc-3-building-polygon-annotation" aria-label="Permalink to &quot;4.4. Bước 3: Building Polygon Annotation&quot;">​</a></h3><p>Annotation polygon được thực hiện trên ảnh pre-disaster sử dụng QGIS với các extension tùy chỉnh.</p><p><strong>Quy tắc annotation:</strong></p><ul><li>Vẽ polygon bám sát building footprint (không bao gồm shadow)</li><li>Mỗi công trình một polygon, không merge các công trình liền kề</li><li>Bao gồm tất cả structures có thể nhận diện (nhà ở, công nghiệp, agricultural)</li><li>Không annotate các object không phải công trình (containers, vehicles, tents)</li></ul><p><strong>Công cụ và workflow:</strong></p><ul><li>QGIS với Python plugin tùy chỉnh</li><li>Layer-based workflow với auto-save</li><li>Built-in validation cho polygon validity</li><li>Export sang JSON format chuẩn</li></ul><p><strong>Productivity metrics:</strong></p><ul><li>Trung bình: 50-100 buildings/hour cho annotator có kinh nghiệm</li><li>Phụ thuộc vào density và complexity của khu vực</li></ul><h3 id="_4-5-buoc-4-damage-classification" tabindex="-1">4.5. Bước 4: Damage Classification <a class="header-anchor" href="#_4-5-buoc-4-damage-classification" aria-label="Permalink to &quot;4.5. Bước 4: Damage Classification&quot;">​</a></h3><p>Sau khi có building polygon, nhóm annotation thực hiện damage classification bằng cách overlay polygon lên ảnh post-disaster.</p><p><strong>Workflow:</strong></p><ol><li>Load pre-disaster image với polygon overlay</li><li>Switch sang post-disaster image (polygon giữ nguyên vị trí)</li><li>So sánh trực quan và assign damage level</li><li>Sử dụng reference images để đảm bảo consistency</li></ol><p><strong>Training cho annotator:</strong></p><ul><li>2-4 giờ training session với reference examples</li><li>Calibration exercises để đảm bảo inter-annotator agreement</li><li>Regular sync meetings để discuss edge cases</li></ul><p><strong>Edge cases và guidelines:</strong></p><ul><li>Công trình bị mây che: <code>un-classified</code></li><li>Không thể align chính xác: Document và cố gắng estimate</li><li>Thiệt hại không rõ ràng: Err toward lower damage level</li></ul><h3 id="_4-6-buoc-5-quality-assurance" tabindex="-1">4.6. Bước 5: Quality Assurance <a class="header-anchor" href="#_4-6-buoc-5-quality-assurance" aria-label="Permalink to &quot;4.6. Bước 5: Quality Assurance&quot;">​</a></h3><p>QA là giai đoạn critical để đảm bảo consistency và accuracy của dataset.</p><p><strong>Multi-level review:</strong></p><ol><li><strong>First-pass review:</strong> Annotator thứ hai review 100% annotations</li><li><strong>Expert review:</strong> Mẫu 10-20% được review bởi disaster response experts</li><li><strong>Systematic audit:</strong> Phân tích statistical để phát hiện systematic biases</li></ol><p><strong>Metrics tracking:</strong></p><ul><li>Inter-annotator agreement (Cohen&#39;s kappa)</li><li>Error rate by disaster type</li><li>Error rate by damage class</li><li>Systematic bias detection</li></ul><p><strong>Kết quả QA:</strong></p><ul><li>Overall error rate: ~2-3%</li><li>Highest confusion: Between minor (1) và major (2) damage</li><li>Corrections applied: Several thousand annotations revised</li></ul><h3 id="_4-7-buoc-6-format-va-distribution" tabindex="-1">4.7. Bước 6: Format và Distribution <a class="header-anchor" href="#_4-7-buoc-6-format-va-distribution" aria-label="Permalink to &quot;4.7. Bước 6: Format và Distribution&quot;">​</a></h3><p><strong>Final processing:</strong></p><ul><li>Standardize image format (PNG, RGB, 1024×1024)</li><li>Validate JSON labels for schema compliance</li><li>Generate train/test/holdout splits</li><li>Create documentation và baseline code</li></ul><p><strong>Distribution:</strong></p><ul><li>xView2.org website với registration</li><li>Compressed archive (~10 GB)</li><li>Documentation và baseline repository trên GitHub</li></ul><hr><h2 id="_5-thach-thuc-computer-vision" tabindex="-1">5. Thách Thức Computer Vision <a class="header-anchor" href="#_5-thach-thuc-computer-vision" aria-label="Permalink to &quot;5. Thách Thức Computer Vision&quot;">​</a></h2><h3 id="_5-1-bai-toan-two-stage-prediction" tabindex="-1">5.1. Bài Toán Two-Stage Prediction <a class="header-anchor" href="#_5-1-bai-toan-two-stage-prediction" aria-label="Permalink to &quot;5.1. Bài Toán Two-Stage Prediction&quot;">​</a></h3><p>xView2 Challenge đặt ra bài toán two-stage độc đáo, yêu cầu mô hình thực hiện cả building localization và damage classification.</p><p><strong>Stage 1: Building Localization</strong></p><ul><li>Input: Pre-disaster image (1024×1024×3)</li><li>Output: Building segmentation mask (1024×1024, binary hoặc multi-instance)</li><li>Metric: F1 score at IoU threshold</li></ul><p><strong>Stage 2: Damage Classification</strong></p><ul><li>Input: Pre-disaster image + Post-disaster image + Building masks</li><li>Output: Damage level for each building (0-3)</li><li>Metric: Weighted F1 score across damage classes</li></ul><p><strong>Scoring formula:</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Final Score = 0.3 × Localization_F1 + 0.7 × Damage_F1</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>Tỷ lệ 30-70 phản ánh rằng damage classification là task khó hơn và có giá trị ứng dụng cao hơn. Localization với accuracy cao là prerequisite, nhưng true value nằm ở việc classify damage correctly.</p><h3 id="_5-2-class-imbalance-problem" tabindex="-1">5.2. Class Imbalance Problem <a class="header-anchor" href="#_5-2-class-imbalance-problem" aria-label="Permalink to &quot;5.2. Class Imbalance Problem&quot;">​</a></h3><p>Class imbalance là thách thức lớn nhất của xBD. Với &quot;no damage&quot; class chiếm ~73% và các damage classes chỉ chiếm ~27% cộng lại, naive training sẽ tạo ra mô hình chỉ predict &quot;no damage&quot; và vẫn đạt accuracy 73%.</p><p><strong>Chiến lược xử lý class imbalance:</strong></p><p><strong>1. Weighted Loss Functions</strong></p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Inverse frequency weighting</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">weights </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">8.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">9.9</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Or Focal Loss</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">focal_loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">alpha </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> p)</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">^</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gamma </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> log(p)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>Focal loss đặc biệt hiệu quả vì nó down-weight các easy examples (thường là &quot;no damage&quot;) và focus vào hard examples.</p><p><strong>2. Oversampling và Data Augmentation</strong></p><ul><li>Oversample tiles chứa nhiều damaged buildings (2-4x)</li><li>Apply data augmentation chủ yếu cho damage classes</li><li>Careful với augmentation: rotation OK, color augmentation cần cẩn thận (không làm mất damage indicators)</li></ul><p><strong>3. Multi-Task Learning</strong></p><ul><li>Train localization và classification jointly</li><li>Share features giữa hai tasks</li><li>Classification benefits từ localization features</li></ul><h3 id="_5-3-siamese-network-architecture" tabindex="-1">5.3. Siamese Network Architecture <a class="header-anchor" href="#_5-3-siamese-network-architecture" aria-label="Permalink to &quot;5.3. Siamese Network Architecture&quot;">​</a></h3><p>Hầu hết các giải pháp top đều sử dụng Siamese network architecture để xử lý cặp ảnh pre/post-disaster.</p><p><strong>Concept:</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Pre-disaster image ─────┐</span></span>
<span class="line"><span>                        ├───&gt; Shared Encoder ───&gt; Feature Fusion ───&gt; Prediction</span></span>
<span class="line"><span>Post-disaster image ────┘</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p><strong>Ưu điểm của Siamese:</strong></p><ul><li>Shared encoder ensures cùng feature space cho cả pre và post</li><li>Feature difference có thể capture change (damage) trực tiếp</li><li>Efficient về parameters (chỉ cần train một encoder)</li></ul><p><strong>Variations:</strong></p><ul><li>Early fusion: Concatenate images trước encoder</li><li>Late fusion: Separate encoders, fuse features</li><li>Difference-based: Compute feature difference as primary signal</li></ul><p>Giải pháp Hạng 1 sử dụng Siamese U-Net với shared encoder, đạt cải thiện 266% so với baseline.</p><h3 id="_5-4-multi-scale-object-handling" tabindex="-1">5.4. Multi-Scale Object Handling <a class="header-anchor" href="#_5-4-multi-scale-object-handling" aria-label="Permalink to &quot;5.4. Multi-Scale Object Handling&quot;">​</a></h3><p>Công trình trong xBD có kích thước rất đa dạng, từ nhà ở nhỏ (10-20 pixels) đến warehouse lớn (200+ pixels).</p><p><strong>Thách thức:</strong></p><ul><li>Small buildings có thể bị miss bởi models với large receptive field</li><li>Large buildings cần context rộng để assess damage correctly</li><li>Mixed scales trong cùng một image</li></ul><p><strong>Giải pháp:</strong></p><ul><li>Feature Pyramid Networks (FPN) cho multi-scale feature extraction</li><li>Multi-resolution input (process cùng tile ở nhiều scales)</li><li>Atrous Spatial Pyramid Pooling (ASPP)</li></ul><h3 id="_5-5-fine-grained-classification-challenge" tabindex="-1">5.5. Fine-Grained Classification Challenge <a class="header-anchor" href="#_5-5-fine-grained-classification-challenge" aria-label="Permalink to &quot;5.5. Fine-Grained Classification Challenge&quot;">​</a></h3><p>Phân biệt giữa các damage levels, đặc biệt &quot;minor&quot; vs &quot;major&quot;, là task rất khó.</p><p><strong>Vấn đề:</strong></p><ul><li>Visual differences có thể rất subtle từ satellite view</li><li>Damage indicators có thể bị occluded (bởi smoke, debris)</li><li>Subjective judgment ngay cả với human annotators</li></ul><p><strong>Approaches:</strong></p><ul><li>Attention mechanisms để focus vào relevant regions</li><li>Context features (surrounding buildings, debris patterns)</li><li>Ordinal classification (leverage ordering: 0 &lt; 1 &lt; 2 &lt; 3)</li></ul><h3 id="_5-6-change-detection-vs-direct-classification" tabindex="-1">5.6. Change Detection vs Direct Classification <a class="header-anchor" href="#_5-6-change-detection-vs-direct-classification" aria-label="Permalink to &quot;5.6. Change Detection vs Direct Classification&quot;">​</a></h3><p>Có hai paradigm chính cho damage assessment từ pre/post pairs.</p><p><strong>Change Detection Approach:</strong></p><ul><li>Focus vào detecting changes giữa pre và post</li><li>Assume change = damage</li><li>Pros: Robust to absolute appearance variations</li><li>Cons: May miss damage types that don&#39;t cause obvious change</li></ul><p><strong>Direct Classification Approach:</strong></p><ul><li>Classify damage level trực tiếp từ post-disaster image</li><li>Use pre-disaster image as context/reference</li><li>Pros: Can capture subtle damage patterns</li><li>Cons: May confuse normal variations with damage</li></ul><p><strong>Hybrid Approach (most successful):</strong></p><ul><li>Combine change features với appearance features</li><li>Use pre-disaster để understand normal state</li><li>Use post-disaster để classify current state</li><li>Weigh both signals trong final prediction</li></ul><h3 id="_5-7-baseline-model-architecture" tabindex="-1">5.7. Baseline Model Architecture <a class="header-anchor" href="#_5-7-baseline-model-architecture" aria-label="Permalink to &quot;5.7. Baseline Model Architecture&quot;">​</a></h3><p>xBD cung cấp baseline model để establish benchmark và starting point cho participants.</p><p><strong>Localization Model:</strong></p><ul><li>Architecture: U-Net với ResNet50 encoder</li><li>Input: Pre-disaster image (1024×1024×3)</li><li>Output: Building mask (1024×1024×1)</li><li>Loss: Binary cross-entropy</li></ul><p><strong>Classification Model:</strong></p><ul><li>Architecture: ResNet50 classifier</li><li>Input: Cropped building patches từ pre và post images</li><li>Output: Damage class (4 classes)</li><li>Loss: Cross-entropy với class weights</li></ul><p><strong>Baseline Performance:</strong></p><ul><li>Localization F1: ~0.80</li><li>Localization IoU: ~0.66</li><li>Classification F1: Varies by class</li><li>Combined Score: ~0.50</li></ul><p>Top solutions achieved combined scores above 0.80, representing 60%+ improvement over baseline.</p><hr><h2 id="_6-huong-dan-su-dung-va-tai-nguyen" tabindex="-1">6. Hướng Dẫn Sử Dụng và Tài Nguyên <a class="header-anchor" href="#_6-huong-dan-su-dung-va-tai-nguyen" aria-label="Permalink to &quot;6. Hướng Dẫn Sử Dụng và Tài Nguyên&quot;">​</a></h2><h3 id="_6-1-truy-cap-va-download-dataset" tabindex="-1">6.1. Truy Cập và Download Dataset <a class="header-anchor" href="#_6-1-truy-cap-va-download-dataset" aria-label="Permalink to &quot;6.1. Truy Cập và Download Dataset&quot;">​</a></h3><p><strong>Phương pháp 1: Official xView2 Portal (Recommended)</strong></p><ol><li>Truy cập <a href="https://xview2.org/dataset" target="_blank" rel="noreferrer">https://xview2.org/dataset</a></li><li>Tạo account và đăng nhập</li><li>Accept challenge terms và data use agreement</li><li>Download data archive (~10 GB compressed)</li><li>Extract và verify integrity</li></ol><p><strong>Phương pháp 2: Roboflow Universe (Quick Start)</strong></p><ul><li>URL: <a href="https://universe.roboflow.com/ozu/xview2" target="_blank" rel="noreferrer">https://universe.roboflow.com/ozu/xview2</a></li><li>520 sample images, CC BY 4.0 license</li><li>Không cần registration</li><li>Bao gồm pre-trained model và API access</li></ul><p><strong>Phương pháp 3: TorchGeo (Python)</strong></p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torchgeo.datasets </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> XView2</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Downloads automatically if not present</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">dataset </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> XView2(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    root</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;path/to/data&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    split</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;train&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    transforms</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    download</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p><strong>Phương pháp 4: Hugging Face</strong></p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> datasets </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> load_dataset</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Requires login và acceptance of terms</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ds </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> load_dataset(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;danielz01/xView2&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h3 id="_6-2-data-loading-va-preprocessing" tabindex="-1">6.2. Data Loading và Preprocessing <a class="header-anchor" href="#_6-2-data-loading-va-preprocessing" aria-label="Permalink to &quot;6.2. Data Loading và Preprocessing&quot;">​</a></h3><p><strong>Recommended preprocessing pipeline:</strong></p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> albumentations </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> A</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> albumentations.pytorch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ToTensorV2</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Training transforms</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">train_transform </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> A.Compose([</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    A.RandomCrop(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">512</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">512</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    A.HorizontalFlip(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">p</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    A.VerticalFlip(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">p</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    A.RandomRotate90(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">p</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Be careful with color augmentation - may affect damage indicators</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    A.ColorJitter(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">brightness</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">contrast</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">p</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    A.Normalize(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        mean</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.485</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.456</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.406</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        std</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.229</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.224</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.225</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ToTensorV2()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">additional_targets</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;post_image&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;image&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">})</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Apply same spatial transforms to both pre and post</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">transformed </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> train_transform(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    image</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">pre_image,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    post_image</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">post_image,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    mask</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">mask</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br></div></div><p><strong>Key considerations:</strong></p><ul><li>Apply spatial transforms consistently to pre, post, và mask</li><li>Be conservative với color augmentation</li><li>Consider class-balanced sampling</li></ul><h3 id="_6-3-model-training-best-practices" tabindex="-1">6.3. Model Training Best Practices <a class="header-anchor" href="#_6-3-model-training-best-practices" aria-label="Permalink to &quot;6.3. Model Training Best Practices&quot;">​</a></h3><p><strong>Architecture recommendations:</strong></p><ol><li><strong>Siamese U-Net</strong> với shared encoder (top performing)</li><li><strong>EfficientNet</strong> hoặc <strong>ResNet</strong> backbone</li><li><strong>FPN</strong> hoặc <strong>DeepLabV3+</strong> cho multi-scale features</li><li><strong>Multi-task head</strong> cho joint localization + classification</li></ol><p><strong>Loss function:</strong></p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Recommended: Combination of Dice và Focal Loss</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> CombinedLoss</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, alpha</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dice </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> DiceLoss()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.focal </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> FocalLoss(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">gamma</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.alpha </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> alpha</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, pred, target):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.alpha </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dice(pred, target) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> \\</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">               (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.alpha) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.focal(pred, target)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p><strong>Training hyperparameters (typical):</strong></p><ul><li>Learning rate: 1e-4 với cosine annealing</li><li>Batch size: 8-16 (phụ thuộc GPU memory)</li><li>Epochs: 50-100</li><li>Optimizer: AdamW với weight decay 1e-4</li><li>Class weights: [1.0, 8.5, 10.5, 9.9] for [0, 1, 2, 3]</li></ul><h3 id="_6-4-evaluation-metrics" tabindex="-1">6.4. Evaluation Metrics <a class="header-anchor" href="#_6-4-evaluation-metrics" aria-label="Permalink to &quot;6.4. Evaluation Metrics&quot;">​</a></h3><p><strong>Official metrics:</strong></p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> compute_score</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(loc_f1, dam_f1):</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    Official xView2 combined score</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.3</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> *</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> loc_f1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.7</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> *</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dam_f1</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p><strong>Localization F1:</strong></p><ul><li>Computed at pixel level</li><li>True positive: predicted building pixel overlaps with ground truth</li><li>IoU threshold typically 0.5</li></ul><p><strong>Damage F1:</strong></p><ul><li>Weighted average across damage classes</li><li>Per-class F1 weighted by class support</li><li>Only computed for correctly localized buildings</li></ul><h3 id="_6-5-common-pitfalls-va-solutions" tabindex="-1">6.5. Common Pitfalls và Solutions <a class="header-anchor" href="#_6-5-common-pitfalls-va-solutions" aria-label="Permalink to &quot;6.5. Common Pitfalls và Solutions&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Pitfall</th><th>Symptom</th><th>Solution</th></tr></thead><tbody><tr><td>Class imbalance</td><td>Model always predicts &quot;no damage&quot;</td><td>Weighted loss, oversampling</td></tr><tr><td>Overfitting</td><td>High train accuracy, low val accuracy</td><td>More augmentation, dropout, early stopping</td></tr><tr><td>Poor generalization</td><td>Good on seen disasters, bad on new</td><td>Cross-disaster validation, diverse training</td></tr><tr><td>Alignment issues</td><td>Misaligned predictions</td><td>Account for pixel shift, use robust features</td></tr><tr><td>Small objects missed</td><td>Low recall on small buildings</td><td>Multi-scale input, FPN architecture</td></tr></tbody></table><h3 id="_6-6-tai-nguyen-chinh-thuc" tabindex="-1">6.6. Tài Nguyên Chính Thức <a class="header-anchor" href="#_6-6-tai-nguyen-chinh-thuc" aria-label="Permalink to &quot;6.6. Tài Nguyên Chính Thức&quot;">​</a></h3><p><strong>Websites:</strong></p><ul><li>xView2 Challenge: <a href="https://xview2.org" target="_blank" rel="noreferrer">https://xview2.org</a></li><li>DIU xView Series: <a href="https://www.diu.mil/ai-xview-challenge" target="_blank" rel="noreferrer">https://www.diu.mil/ai-xview-challenge</a></li><li>Maxar Open Data: <a href="https://www.digitalglobe.com/ecosystem/open-data" target="_blank" rel="noreferrer">https://www.digitalglobe.com/ecosystem/open-data</a></li></ul><p><strong>Papers:</strong></p><ul><li><a href="https://arxiv.org/abs/1911.09296" target="_blank" rel="noreferrer">Creating xBD (CVPR 2019)</a></li><li><a href="https://arxiv.org/abs/2212.13876" target="_blank" rel="noreferrer">xFBD: Focused Building Damage (2022)</a></li><li><a href="https://arxiv.org/abs/2405.04800" target="_blank" rel="noreferrer">DeepDamageNet (2024)</a></li></ul><p><strong>GitHub Repositories:</strong></p><ul><li><a href="https://github.com/DIUx-xView/xView2_baseline" target="_blank" rel="noreferrer">xView2 Baseline</a></li><li><a href="https://github.com/DIUx-xView/xView2_scoring" target="_blank" rel="noreferrer">xView2 Scoring</a></li><li><a href="https://github.com/DIUx-xView/xView2_first_place" target="_blank" rel="noreferrer">1st Place Solution</a></li><li><a href="https://github.com/ashnair1/xview2-toolkit" target="_blank" rel="noreferrer">xView2 Toolkit</a></li></ul><h3 id="_6-7-ung-dung-thuc-te" tabindex="-1">6.7. Ứng Dụng Thực Tế <a class="header-anchor" href="#_6-7-ung-dung-thuc-te" aria-label="Permalink to &quot;6.7. Ứng Dụng Thực Tế&quot;">​</a></h3><p>xBD và các mô hình huấn luyện trên dataset này đã được triển khai trong các tình huống thực tế:</p><p><strong>California Wildfire Assessment (2020):</strong></p><ul><li>Sử dụng bởi California Air National Guard</li><li>Thời gian phân tích: 10-20 phút cho khu vực rộng</li><li>So với 1-2 ngày cho phương pháp thủ công</li><li>Hỗ trợ ưu tiên nguồn lực cứu trợ</li></ul><p><strong>Hurricane Response:</strong></p><ul><li>Đánh giá nhanh sau bão</li><li>Xác định khu vực ưu tiên cho đội cứu hộ</li><li>Ước tính thiệt hại cho mục đích bảo hiểm</li></ul><p><strong>International Disaster Response:</strong></p><ul><li>UN và các NGO sử dụng cho đánh giá thảm họa quốc tế</li><li>Hỗ trợ coordination giữa các tổ chức cứu trợ</li></ul><h3 id="_6-8-trich-dan" tabindex="-1">6.8. Trích Dẫn <a class="header-anchor" href="#_6-8-trich-dan" aria-label="Permalink to &quot;6.8. Trích Dẫn&quot;">​</a></h3><div class="language-bibtex vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">bibtex</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">@inproceedings</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">gupta2019xbd</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  title</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Creating xBD: A Dataset for Assessing Building Damage</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">         from Satellite Imagery</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  author</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Gupta, Ritwik and Goodman, Bryce and Patel, Nirav and</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">          Hosfelt, Ricky and Sajeev, Sandra and Heim, Eric and</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">          Doshi, Jigar and Lucas, Keane and Choset, Howie and</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">          Gaston, Matthew</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  booktitle</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Proceedings of the IEEE Conference on Computer Vision</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">             and Pattern Recognition Workshops</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  pages</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">18--26</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  year</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">2019</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">}</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><hr><h2 id="phu-luc" tabindex="-1">Phụ Lục <a class="header-anchor" href="#phu-luc" aria-label="Permalink to &quot;Phụ Lục&quot;">​</a></h2><h3 id="a-danh-sach-19-su-kien-tham-hoa" tabindex="-1">A. Danh Sách 19 Sự Kiện Thảm Họa <a class="header-anchor" href="#a-danh-sach-19-su-kien-tham-hoa" aria-label="Permalink to &quot;A. Danh Sách 19 Sự Kiện Thảm Họa&quot;">​</a></h3><table tabindex="0"><thead><tr><th>#</th><th>Disaster</th><th>Type</th><th>Region</th><th>Year</th></tr></thead><tbody><tr><td>1</td><td>Hurricane Harvey</td><td>Wind</td><td>Texas, USA</td><td>2017</td></tr><tr><td>2</td><td>Hurricane Maria</td><td>Wind</td><td>Puerto Rico</td><td>2017</td></tr><tr><td>3</td><td>Hurricane Michael</td><td>Wind</td><td>Florida, USA</td><td>2018</td></tr><tr><td>4</td><td>Hurricane Florence</td><td>Wind</td><td>Carolinas, USA</td><td>2018</td></tr><tr><td>5</td><td>Hurricane Matthew</td><td>Wind</td><td>Haiti</td><td>2016</td></tr><tr><td>6</td><td>Joplin Tornado</td><td>Tornado</td><td>Missouri, USA</td><td>2011</td></tr><tr><td>7</td><td>Tuscaloosa Tornado</td><td>Tornado</td><td>Alabama, USA</td><td>2011</td></tr><tr><td>8</td><td>Mexico City Earthquake</td><td>Earthquake</td><td>Mexico</td><td>2017</td></tr><tr><td>9</td><td>Nepal Earthquake</td><td>Earthquake</td><td>Nepal</td><td>2015</td></tr><tr><td>10</td><td>Lombok Earthquake</td><td>Earthquake</td><td>Indonesia</td><td>2018</td></tr><tr><td>11</td><td>Palu-Sulawesi Tsunami</td><td>Tsunami</td><td>Indonesia</td><td>2018</td></tr><tr><td>12</td><td>Paradise Fire</td><td>Wildfire</td><td>California, USA</td><td>2018</td></tr><tr><td>13</td><td>Woolsey Fire</td><td>Wildfire</td><td>California, USA</td><td>2018</td></tr><tr><td>14</td><td>Santa Rosa Fire</td><td>Wildfire</td><td>California, USA</td><td>2017</td></tr><tr><td>15</td><td>Pinery Bushfire</td><td>Wildfire</td><td>Australia</td><td>2015</td></tr><tr><td>16</td><td>Midwest Flooding</td><td>Flood</td><td>Midwest, USA</td><td>2019</td></tr><tr><td>17</td><td>Bangladesh Monsoon</td><td>Flood</td><td>Bangladesh</td><td>2017</td></tr><tr><td>18</td><td>Nepal Flood</td><td>Flood</td><td>Nepal</td><td>2017</td></tr><tr><td>19</td><td>Guatemala Fuego</td><td>Volcanic</td><td>Guatemala</td><td>2018</td></tr></tbody></table><h3 id="b-thong-so-performance-baseline" tabindex="-1">B. Thông Số Performance Baseline <a class="header-anchor" href="#b-thong-so-performance-baseline" aria-label="Permalink to &quot;B. Thông Số Performance Baseline&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Metric</th><th>U-Net Baseline</th><th>Top Solutions</th></tr></thead><tbody><tr><td>Localization F1</td><td>0.80</td><td>0.90+</td></tr><tr><td>Localization IoU</td><td>0.66</td><td>0.85+</td></tr><tr><td>Damage F1 (no damage)</td><td>0.85</td><td>0.95</td></tr><tr><td>Damage F1 (minor)</td><td>0.40</td><td>0.70</td></tr><tr><td>Damage F1 (major)</td><td>0.35</td><td>0.65</td></tr><tr><td>Damage F1 (destroyed)</td><td>0.50</td><td>0.80</td></tr><tr><td>Combined Score</td><td>0.50</td><td>0.80+</td></tr></tbody></table><h3 id="c-hardware-requirements" tabindex="-1">C. Hardware Requirements <a class="header-anchor" href="#c-hardware-requirements" aria-label="Permalink to &quot;C. Hardware Requirements&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Component</th><th>Minimum</th><th>Recommended</th></tr></thead><tbody><tr><td>GPU</td><td>GTX 1080 (8GB)</td><td>RTX 3090 (24GB)</td></tr><tr><td>RAM</td><td>16 GB</td><td>64 GB</td></tr><tr><td>Storage</td><td>50 GB SSD</td><td>200 GB NVMe</td></tr><tr><td>CPU</td><td>4 cores</td><td>8+ cores</td></tr></tbody></table><hr><p><em>Tài liệu tạo: 2024-12-18</em><em>Cập nhật lần cuối: 2025-12-19</em><em>Số từ: ~7,500</em></p>`,160))])}const x=e(b,[["render",E]]);export{D as __pageData,x as default};
