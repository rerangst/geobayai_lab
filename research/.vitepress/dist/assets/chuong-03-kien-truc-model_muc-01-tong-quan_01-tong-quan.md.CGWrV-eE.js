import{_ as s,C as g,c as l,o as i,a2 as a,b as e,w as t,a as r,G as c,a3 as o}from"./chunks/framework.nRfFlDZQ.js";const u="/sen_doc/assets/torchgeo_page2_fig1.UM0ZJ2CO.png",T=JSON.parse('{"title":"Chương 3: Kiến Trúc Mô Hình - TorchGeo Framework","description":"","frontmatter":{},"headers":[],"relativePath":"chuong-03-kien-truc-model/muc-01-tong-quan/01-tong-quan.md","filePath":"chuong-03-kien-truc-model/muc-01-tong-quan/01-tong-quan.md","lastUpdated":1766302189000}'),p={name:"chuong-03-kien-truc-model/muc-01-tong-quan/01-tong-quan.md"};function d(m,n,v,b,k,C){const h=g("Mermaid");return i(),l("div",null,[n[2]||(n[2]=a('<h1 id="chuong-3-kien-truc-mo-hinh-torchgeo-framework" tabindex="-1">Chương 3: Kiến Trúc Mô Hình - TorchGeo Framework <a class="header-anchor" href="#chuong-3-kien-truc-mo-hinh-torchgeo-framework" aria-label="Permalink to &quot;Chương 3: Kiến Trúc Mô Hình - TorchGeo Framework&quot;">​</a></h1><h2 id="_3-1-gioi-thieu" tabindex="-1">3.1. Giới Thiệu <a class="header-anchor" href="#_3-1-gioi-thieu" aria-label="Permalink to &quot;3.1. Giới Thiệu&quot;">​</a></h2><p>Dựa trên nền tảng lý thuyết CNN đã trình bày ở <strong>Chương 2</strong>, chương này giới thiệu các kiến trúc mô hình cụ thể được triển khai trong thư viện TorchGeo - công cụ chuyên biệt cho xử lý ảnh viễn thám. TorchGeo [Stewart et al., 2022] ra đời như một giải pháp toàn diện, cung cấp hệ sinh thái datasets, samplers, transforms và pre-trained models được thiết kế riêng cho các bài toán geospatial machine learning trên nền tảng PyTorch.</p><p>Khác với các thư viện deep learning thông thường vốn được phát triển chủ yếu cho natural images, TorchGeo nhận thức rõ những đặc thù riêng biệt của dữ liệu viễn thám: từ số kênh phổ đa dạng (13 bands Sentinel-2), kiểu dữ liệu 16/32-bit, đến hệ tọa độ tham chiếu phức tạp. Thư viện này đóng vai trò cầu nối quan trọng giữa cộng đồng viễn thám và cộng đồng học sâu, giúp các nhà nghiên cứu tập trung vào giải quyết bài toán thay vì xử lý các vấn đề kỹ thuật dữ liệu.</p><p>Chương này được tổ chức thành 5 mục chính:</p><ul><li><strong>Mục 3.1:</strong> Tổng quan TorchGeo framework và đặc thù dữ liệu viễn thám</li><li><strong>Mục 3.2:</strong> Backbone models cho classification (ResNet, ViT, Swin, EfficientNet)</li><li><strong>Mục 3.3:</strong> Segmentation architectures (U-Net, DeepLabV3+, FPN, PSPNet, HRNet)</li><li><strong>Mục 3.4:</strong> Change detection models (FC-Siam, BIT-Transformer, STANet)</li><li><strong>Mục 3.5:</strong> Pre-trained weights và transfer learning (SSL4EO, SatMAE, Prithvi)</li></ul><p>Các kiến trúc mô hình được trình bày trong chương này sẽ là nền tảng cho việc phân tích các giải pháp chiến thắng trong <strong>Chương 4 - xView Challenges</strong>, và ứng dụng thực tế trong <strong>Chương 5</strong> (phát hiện tàu biển) và <strong>Chương 6</strong> (phát hiện dầu loang).</p><h2 id="_5-2-đong-co-phat-trien-torchgeo" tabindex="-1">5.2. Động Cơ Phát Triển TorchGeo <a class="header-anchor" href="#_5-2-đong-co-phat-trien-torchgeo" aria-label="Permalink to &quot;5.2. Động Cơ Phát Triển TorchGeo&quot;">​</a></h2><h3 id="_5-2-1-đac-điem-rieng-biet-cua-du-lieu-đia-khong-gian" tabindex="-1">5.2.1. Đặc Điểm Riêng Biệt của Dữ Liệu Địa Không Gian <a class="header-anchor" href="#_5-2-1-đac-điem-rieng-biet-cua-du-lieu-đia-khong-gian" aria-label="Permalink to &quot;5.2.1. Đặc Điểm Riêng Biệt của Dữ Liệu Địa Không Gian&quot;">​</a></h3><p>Dữ liệu viễn thám khác biệt căn bản với natural images ở nhiều khía cạnh, đòi hỏi các phương pháp xử lý chuyên biệt. Những khác biệt này không chỉ mang tính kỹ thuật mà còn ảnh hưởng trực tiếp đến thiết kế kiến trúc mô hình và chiến lược huấn luyện.</p><p><strong>Số lượng kênh phổ (Spectral Bands):</strong> Trong khi ảnh tự nhiên thông thường có 3 kênh RGB với giá trị 8-bit (0-255), ảnh vệ tinh có thể chứa từ vài đến hàng trăm kênh phổ. Sentinel-2 cung cấp 13 kênh phổ bao gồm cả vùng cận hồng ngoại (NIR) và hồng ngoại sóng ngắn (SWIR), trong khi các cảm biến siêu phổ (hyperspectral) có thể ghi nhận hàng trăm kênh. Các mô hình chuẩn như ResNet, VGG được thiết kế cho đầu vào 3 kênh, do đó cần được điều chỉnh đáng kể khi áp dụng cho dữ liệu đa phổ.</p><p><strong>Kiểu dữ liệu và dải giá trị:</strong> Ảnh vệ tinh thường được lưu trữ ở định dạng 16-bit hoặc 32-bit floating point, có thể chứa giá trị âm (như trong dữ liệu phản xạ đã hiệu chỉnh khí quyển hoặc nhiệt độ bề mặt). Dữ liệu radar SAR thường ở dạng số phức hoặc thang logarit (decibel). Sự đa dạng này đòi hỏi các pipeline tiền xử lý linh hoạt hơn so với chuẩn hóa đơn giản 0-255.</p><p><strong>Kích thước không gian và phạm vi phủ:</strong> Một cảnh ảnh vệ tinh có thể bao phủ hàng nghìn km² với hàng tỷ pixel, vượt xa khả năng xử lý của bộ nhớ GPU thông thường. Điều này đặt ra yêu cầu về chiến lược tiling và sampling hiệu quả để chia nhỏ dữ liệu thành các mảnh (patches) có kích thước phù hợp cho huấn luyện.</p><p><strong>Hệ tọa độ tham chiếu (CRS):</strong> Mỗi ảnh viễn thám mang thông tin vị trí địa lý được mã hóa trong các hệ tọa độ khác nhau như UTM, WGS84, hay các CRS địa phương. Việc kết hợp dữ liệu từ nhiều nguồn đòi hỏi phép chiếu và căn chỉnh chính xác (reprojection and alignment).</p><p><strong>Chiều thời gian (Temporal Dimension):</strong> Nhiều ứng dụng viễn thám như giám sát cây trồng, phát hiện thay đổi đô thị, hay theo dõi thiên tai yêu cầu phân tích chuỗi thời gian. Dữ liệu từ các thời điểm khác nhau cần được đồng bộ hóa và xử lý theo trình tự hợp lý.</p><h3 id="_5-2-2-han-che-cua-cac-cong-cu-hien-co" tabindex="-1">5.2.2. Hạn Chế của Các Công Cụ Hiện Có <a class="header-anchor" href="#_5-2-2-han-che-cua-cac-cong-cu-hien-co" aria-label="Permalink to &quot;5.2.2. Hạn Chế của Các Công Cụ Hiện Có&quot;">​</a></h3><p>Trước khi TorchGeo ra đời, các nhà nghiên cứu viễn thám phải đối mặt với khoảng cách đáng kể giữa các công cụ xử lý dữ liệu địa không gian và các framework deep learning. Bảng 5.1 tổng hợp những hạn chế chính của từng nhóm công cụ.</p><table tabindex="0"><thead><tr><th>Công cụ</th><th>Mục đích chính</th><th>Hạn chế với Viễn thám</th></tr></thead><tbody><tr><td>torchvision</td><td>Natural images (RGB, 8-bit)</td><td>Không hỗ trợ đa phổ, transforms giả định 3 kênh</td></tr><tr><td>scikit-learn</td><td>ML truyền thống</td><td>Không native cho deep learning</td></tr><tr><td>TensorFlow/Keras</td><td>Deep learning tổng quát</td><td>Không có geospatial-aware components</td></tr><tr><td>GDAL/Rasterio</td><td>Đọc/ghi dữ liệu địa không gian</td><td>Không tích hợp ML, cần bridge sang PyTorch</td></tr></tbody></table><p><strong>Bảng 5.1:</strong> So sánh hạn chế của các công cụ hiện có trong xử lý dữ liệu viễn thám</p><p>TorchGeo được thiết kế để lấp đầy khoảng trống này bằng cách cung cấp: (1) các dataset classes có nhận thức về CRS và bounds, (2) transforms tương thích với dữ liệu đa phổ, (3) samplers cho raster lớn, (4) pre-trained weights được huấn luyện trên dữ liệu vệ tinh, và (5) tích hợp với các công cụ geospatial chuẩn như rasterio và pyproj.</p><h2 id="_5-3-kien-truc-he-thong" tabindex="-1">5.3. Kiến Trúc Hệ Thống <a class="header-anchor" href="#_5-3-kien-truc-he-thong" aria-label="Permalink to &quot;5.3. Kiến Trúc Hệ Thống&quot;">​</a></h2><h3 id="_5-3-1-tong-quan-cac-thanh-phan" tabindex="-1">5.3.1. Tổng Quan Các Thành Phần <a class="header-anchor" href="#_5-3-1-tong-quan-cac-thanh-phan" aria-label="Permalink to &quot;5.3.1. Tổng Quan Các Thành Phần&quot;">​</a></h3><p>TorchGeo được tổ chức theo kiến trúc module hóa cao, tuân theo các quy ước thiết kế của PyTorch nhằm giảm thiểu learning curve cho người dùng đã quen thuộc với hệ sinh thái này. Hình 5.1 minh họa kiến trúc tổng thể của thư viện.</p>',23)),(i(),e(o,null,{default:t(()=>[c(h,{id:"mermaid-151",class:"mermaid",graph:"graph%20TD%0A%20%20%20%20subgraph%20%22TorchGeo%20Core%22%0A%20%20%20%20%20%20%20%20A%5B%22Datasets%3Cbr%2F%3E(GeoDataset%2C%20NonGeoDataset)%22%5D%20--%3E%20D%5B%22DataLoaders%22%5D%0A%20%20%20%20%20%20%20%20B%5B%22Samplers%3Cbr%2F%3E(Random%2C%20Grid%2C%20PreChipped)%22%5D%20--%3E%20D%0A%20%20%20%20%20%20%20%20C%5B%22Transforms%3Cbr%2F%3E(Kornia-based)%22%5D%20--%3E%20D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20%22Models%22%0A%20%20%20%20%20%20%20%20E%5B%22Backbones%3Cbr%2F%3E(ResNet%2C%20ViT%2C%20Swin)%22%5D%0A%20%20%20%20%20%20%20%20F%5B%22Task%20Heads%3Cbr%2F%3E(Classification%2C%20Segmentation)%22%5D%0A%20%20%20%20%20%20%20%20G%5B%22Pre-trained%20Weights%3Cbr%2F%3E(SSL4EO%2C%20SatMAE)%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20%22Training%22%0A%20%20%20%20%20%20%20%20H%5B%22Lightning%20Trainers%3Cbr%2F%3E(Classification%2C%20Segmentation%2C%20Detection)%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20D%20--%3E%20E%0A%20%20%20%20E%20--%3E%20F%0A%20%20%20%20G%20--%3E%20E%0A%20%20%20%20F%20--%3E%20H%0A%0A%20%20%20%20style%20A%20fill%3A%23e3f2fd%0A%20%20%20%20style%20B%20fill%3A%23e3f2fd%0A%20%20%20%20style%20C%20fill%3A%23e3f2fd%0A%20%20%20%20style%20E%20fill%3A%23fff3e0%0A%20%20%20%20style%20F%20fill%3A%23fff3e0%0A%20%20%20%20style%20G%20fill%3A%23fff3e0%0A%20%20%20%20style%20H%20fill%3A%23e8f5e9%0A"})]),fallback:t(()=>[...n[0]||(n[0]=[r(" Loading... ",-1)])]),_:1})),n[3]||(n[3]=a('<p><strong>Hình 5.1:</strong> Kiến trúc module hóa của TorchGeo</p><p>Các thành phần chính bao gồm:</p><ul><li><p><strong>Datasets:</strong> Lớp trừu tượng cho dữ liệu địa không gian với GeoDataset (có CRS và bounds) và NonGeoDataset (wrapper cho datasets chuẩn). Hỗ trợ 15+ benchmark datasets như EuroSAT, BigEarthNet, LEVIR-CD.</p></li><li><p><strong>Samplers:</strong> Các chiến lược lấy mẫu cho raster lớn, bao gồm RandomGeoSampler (lấy mẫu ngẫu nhiên), GridGeoSampler (lấy mẫu có hệ thống), và PreChippedGeoSampler (cho dữ liệu đã chia sẵn).</p></li><li><p><strong>Transforms:</strong> Các phép biến đổi dựa trên Kornia, hỗ trợ GPU-accelerated augmentation cho dữ liệu đa phổ và tính toán các chỉ số phổ như NDVI, NDWI.</p></li><li><p><strong>Models:</strong> Các backbone architectures với pre-trained weights từ self-supervised learning trên dữ liệu vệ tinh, cùng các task-specific heads cho classification, segmentation, và object detection.</p></li><li><p><strong>Trainers:</strong> Các Lightning modules chuẩn hóa quy trình huấn luyện, đánh giá và inference cho các bài toán phổ biến.</p></li></ul><h3 id="_5-3-2-abstraction-layer-cho-dataset" tabindex="-1">5.3.2. Abstraction Layer cho Dataset <a class="header-anchor" href="#_5-3-2-abstraction-layer-cho-dataset" aria-label="Permalink to &quot;5.3.2. Abstraction Layer cho Dataset&quot;">​</a></h3><p>Lõi của TorchGeo là khái niệm GeoDataset - lớp trừu tượng cơ sở cho mọi dữ liệu có thuộc tính địa không gian. Mỗi GeoDataset chứa các thông tin cốt lõi về CRS, độ phân giải không gian (resolution), và phạm vi địa lý (bounds). Điểm khác biệt quan trọng so với PyTorch Dataset thông thường là phương thức <code>__getitem__</code> nhận đầu vào là một BoundingBox thay vì index số nguyên, cho phép truy vấn dữ liệu theo vị trí địa lý.</p>',5)),(i(),e(o,null,{default:t(()=>[c(h,{id:"mermaid-191",class:"mermaid",graph:"graph%20LR%0A%20%20%20%20subgraph%20%22GeoDataset%20Properties%22%0A%20%20%20%20%20%20%20%20A%5B%22crs%3Cbr%2F%3E(H%E1%BB%87%20t%E1%BB%8Da%20%C4%91%E1%BB%99)%22%5D%0A%20%20%20%20%20%20%20%20B%5B%22res%3Cbr%2F%3E(%C4%90%E1%BB%99%20ph%C3%A2n%20gi%E1%BA%A3i)%22%5D%0A%20%20%20%20%20%20%20%20C%5B%22bounds%3Cbr%2F%3E(Ph%E1%BA%A1m%20vi%20%C4%91%E1%BB%8Ba%20l%C3%BD)%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20%22Set%20Operations%22%0A%20%20%20%20%20%20%20%20D%5B%22Union%20(%7C)%3Cbr%2F%3EK%E1%BA%BFt%20h%E1%BB%A3p%20datasets%22%5D%0A%20%20%20%20%20%20%20%20E%5B%22Intersection%20(%26)%3Cbr%2F%3EGiao%20datasets%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20A%20--%3E%20F%5B%22GeoDataset%22%5D%0A%20%20%20%20B%20--%3E%20F%0A%20%20%20%20C%20--%3E%20F%0A%20%20%20%20F%20--%3E%20D%0A%20%20%20%20F%20--%3E%20E%0A%0A%20%20%20%20style%20F%20fill%3A%23bbdefb%0A"})]),fallback:t(()=>[...n[1]||(n[1]=[r(" Loading... ",-1)])]),_:1})),n[4]||(n[4]=a('<p><strong>Hình 5.2:</strong> Các thuộc tính và phép toán trên GeoDataset</p><p>Một tính năng mạnh mẽ của GeoDataset là khả năng kết hợp thông qua phép toán tập hợp. Phép Union (|) cho phép ghép nhiều nguồn dữ liệu, trả về dữ liệu từ nguồn đầu tiên có sẵn. Phép Intersection (&amp;) chỉ trả về dữ liệu tại các vùng mà tất cả các nguồn đều có phủ. Đây là cơ chế quan trọng khi cần kết hợp ảnh quang học với DEM, hoặc ảnh từ nhiều thời điểm khác nhau.</p><h3 id="_5-3-3-chien-luoc-lay-mau" tabindex="-1">5.3.3. Chiến Lược Lấy Mẫu <a class="header-anchor" href="#_5-3-3-chien-luoc-lay-mau" aria-label="Permalink to &quot;5.3.3. Chiến Lược Lấy Mẫu&quot;">​</a></h3><p>Với dữ liệu raster có kích thước lớn, việc chọn chiến lược sampling phù hợp là yếu tố quyết định đến hiệu quả huấn luyện. TorchGeo cung cấp ba loại sampler chính, mỗi loại phục vụ các mục đích khác nhau.</p><table tabindex="0"><thead><tr><th>Sampler</th><th>Đặc điểm</th><th>Trường hợp sử dụng</th></tr></thead><tbody><tr><td>RandomGeoSampler</td><td>Lấy mẫu ngẫu nhiên trong bounds</td><td>Huấn luyện, augmentation</td></tr><tr><td>GridGeoSampler</td><td>Lấy mẫu có hệ thống trên lưới</td><td>Inference, evaluation</td></tr><tr><td>PreChippedGeoSampler</td><td>Dùng cho dữ liệu đã chia sẵn</td><td>Benchmark datasets</td></tr></tbody></table><p><strong>Bảng 5.2:</strong> So sánh các chiến lược sampling trong TorchGeo</p><p>RandomGeoSampler tự động nhận biết vùng có dữ liệu hợp lệ và chỉ lấy mẫu từ những vùng đó, tránh trường hợp lấy phải pixel NoData. GridGeoSampler hỗ trợ configurable stride và overlap, đặc biệt hữu ích khi cần inference trên toàn bộ vùng nghiên cứu với các patch chồng lấn để tránh boundary artifacts.</p><h2 id="_5-4-datasets-va-pre-trained-models" tabindex="-1">5.4. Datasets và Pre-trained Models <a class="header-anchor" href="#_5-4-datasets-va-pre-trained-models" aria-label="Permalink to &quot;5.4. Datasets và Pre-trained Models&quot;">​</a></h2><h3 id="_5-4-1-datasets-co-san" tabindex="-1">5.4.1. Datasets Có Sẵn <a class="header-anchor" href="#_5-4-1-datasets-co-san" aria-label="Permalink to &quot;5.4.1. Datasets Có Sẵn&quot;">​</a></h3><p>TorchGeo tích hợp sẵn nhiều benchmark datasets phổ biến trong cộng đồng viễn thám, được tổ chức theo từng bài toán. Việc chuẩn hóa giao diện truy cập giúp so sánh công bằng giữa các phương pháp và đảm bảo tính tái lập của kết quả nghiên cứu.</p><p>Hình 5.3 minh họa cách TorchGeo xử lý việc sampling dữ liệu từ nhiều nguồn (Landsat + Cropland Data Layer) với căn chỉnh CRS tự động.</p><p><img src="'+u+'" alt="TorchGeo Geospatial Data Sampling"></p><p><strong>Hình 5.3:</strong> Minh họa cơ chế geospatial data sampling của TorchGeo, kết hợp ảnh Landsat với Cropland Data Layer [Stewart et al., 2022]</p><p><strong>Classification Datasets:</strong></p><ul><li>EuroSAT: 27,000 mẫu, 10 lớp land use, Sentinel-2</li><li>BigEarthNet: 590,000 mẫu multi-label, Sentinel-1 và Sentinel-2</li><li>UC Merced: 21 lớp, aerial imagery 30cm</li><li>PatternNet: 38 lớp, high-resolution satellite</li></ul><p><strong>Segmentation Datasets:</strong></p><ul><li>LandCover.ai: 41 orthophotos, 4 lớp, 25-50cm</li><li>ChesapeakeCVPR: Land cover, NAIP imagery</li><li>GeoNRW: Germany land cover mapping</li></ul><p><strong>Change Detection Datasets:</strong></p><ul><li>OSCD: Onera Satellite Change Detection, 24 pairs Sentinel-2</li><li>LEVIR-CD: 637 pairs, building change, 0.5m resolution</li><li>xView2: Damage assessment, 8,399 pairs</li></ul><h3 id="_5-4-2-pre-trained-weights" tabindex="-1">5.4.2. Pre-trained Weights <a class="header-anchor" href="#_5-4-2-pre-trained-weights" aria-label="Permalink to &quot;5.4.2. Pre-trained Weights&quot;">​</a></h3><p>Một đóng góp quan trọng của TorchGeo là việc cung cấp pre-trained weights được huấn luyện trực tiếp trên dữ liệu vệ tinh thay vì chỉ dựa vào ImageNet pre-training. Các nghiên cứu [Cong et al., 2022; Wang et al., 2022] đã chứng minh rằng domain-specific pre-training cho kết quả vượt trội trong nhiều downstream tasks.</p><p>TorchGeo tích hợp weights từ các dự án SSL nổi bật:</p><ul><li><strong>SSL4EO-S12:</strong> Pre-trained trên cặp Sentinel-1/Sentinel-2, hỗ trợ nhiều kiến trúc (ResNet, ViT) với các chiến lược MoCo v2, DINO, MAE</li><li><strong>SatMAE:</strong> Masked autoencoder với temporal encoding, +14% accuracy trên land cover classification</li><li><strong>GASSL:</strong> Geography-aware SSL, +3.77% improvement trên NAIP so với supervised baseline</li></ul><p>Các weights này được tổ chức theo naming convention rõ ràng, ví dụ <code>ResNet50_Weights.SENTINEL2_ALL_MOCO</code> cho ResNet-50 với MoCo v2 pre-training trên tất cả 13 bands Sentinel-2.</p><h2 id="_5-5-tich-hop-voi-he-sinh-thai-pytorch" tabindex="-1">5.5. Tích Hợp với Hệ Sinh Thái PyTorch <a class="header-anchor" href="#_5-5-tich-hop-voi-he-sinh-thai-pytorch" aria-label="Permalink to &quot;5.5. Tích Hợp với Hệ Sinh Thái PyTorch&quot;">​</a></h2><h3 id="_5-5-1-pytorch-lightning-integration" tabindex="-1">5.5.1. PyTorch Lightning Integration <a class="header-anchor" href="#_5-5-1-pytorch-lightning-integration" aria-label="Permalink to &quot;5.5.1. PyTorch Lightning Integration&quot;">​</a></h3><p>TorchGeo cung cấp các Lightning modules chuẩn hóa cho các bài toán phổ biến, giúp giảm thiểu boilerplate code và đảm bảo best practices trong huấn luyện. Các modules này bao gồm:</p><ul><li><strong>ClassificationTask:</strong> Multi-class và multi-label classification với configurable backbone và loss function</li><li><strong>SemanticSegmentationTask:</strong> Pixel-wise classification với encoder-decoder architectures</li><li><strong>ObjectDetectionTask:</strong> Bounding box prediction dựa trên Faster R-CNN</li></ul><p>Mỗi task đã tích hợp sẵn các metrics phù hợp (accuracy, F1, IoU, mAP), logging, và checkpointing. Người dùng chỉ cần configure model architecture và hyperparameters để bắt đầu huấn luyện.</p><h3 id="_5-5-2-kornia-transforms" tabindex="-1">5.5.2. Kornia Transforms <a class="header-anchor" href="#_5-5-2-kornia-transforms" aria-label="Permalink to &quot;5.5.2. Kornia Transforms&quot;">​</a></h3><p>Các augmentations trong TorchGeo được xây dựng trên Kornia, cho phép:</p><ul><li><strong>GPU acceleration:</strong> Transforms thực hiện trực tiếp trên tensor, tận dụng parallel processing</li><li><strong>Differentiability:</strong> Hữu ích cho các kỹ thuật như adversarial training</li><li><strong>Batch processing:</strong> Áp dụng transforms cho toàn bộ batch thay vì từng sample</li></ul><p>Ngoài các augmentations chuẩn (rotation, flip, scale), TorchGeo bổ sung các transforms chuyên biệt như tính toán spectral indices (NDVI = (NIR-Red)/(NIR+Red)) và normalization cho dữ liệu đa phổ.</p><h2 id="_5-6-uu-điem-va-han-che" tabindex="-1">5.6. Ưu Điểm và Hạn Chế <a class="header-anchor" href="#_5-6-uu-điem-va-han-che" aria-label="Permalink to &quot;5.6. Ưu Điểm và Hạn Chế&quot;">​</a></h2><h3 id="_5-6-1-uu-điem" tabindex="-1">5.6.1. Ưu Điểm <a class="header-anchor" href="#_5-6-1-uu-điem" aria-label="Permalink to &quot;5.6.1. Ưu Điểm&quot;">​</a></h3><p><strong>Chuẩn hóa (Standardization):</strong> TorchGeo thiết lập các chuẩn giao diện cho geospatial deep learning, cho phép so sánh công bằng giữa các phương pháp và tái lập kết quả nghiên cứu.</p><p><strong>Domain-specific Pre-training:</strong> Weights huấn luyện trên dữ liệu vệ tinh thường cho kết quả tốt hơn ImageNet pre-training, đặc biệt với dữ liệu đa phổ.</p><p><strong>Ease of Use:</strong> API thiết kế nhất quán với PyTorch conventions, giảm learning curve cho người đã quen hệ sinh thái này.</p><p><strong>Extensibility:</strong> Dễ dàng mở rộng với custom datasets, transforms, và models theo các base classes đã định nghĩa.</p><h3 id="_5-6-2-han-che" tabindex="-1">5.6.2. Hạn Chế <a class="header-anchor" href="#_5-6-2-han-che" aria-label="Permalink to &quot;5.6.2. Hạn Chế&quot;">​</a></h3><p><strong>Learning Curve cho Geospatial Concepts:</strong> Người dùng cần hiểu các khái niệm như CRS, projections, và geospatial data formats để sử dụng hiệu quả.</p><p><strong>Data Access:</strong> Nhiều datasets yêu cầu download thủ công hoặc đăng ký tài khoản (như BigEarthNet), và kích thước dữ liệu có thể rất lớn.</p><p><strong>Performance Overhead:</strong> Việc xử lý on-the-fly và reprojection có thể tạo overhead đáng kể với datasets rất lớn, đôi khi cần cân nhắc pre-processing.</p><h2 id="_3-7-ket-luan-muc" tabindex="-1">3.7. Kết Luận Mục <a class="header-anchor" href="#_3-7-ket-luan-muc" aria-label="Permalink to &quot;3.7. Kết Luận Mục&quot;">​</a></h2><p>TorchGeo đại diện cho một bước tiến quan trọng trong việc chuẩn hóa geospatial deep learning trên PyTorch. Bằng cách cung cấp các abstraction layer phù hợp với đặc thù của dữ liệu viễn thám—từ GeoDataset với CRS awareness, samplers cho raster lớn, đến transforms đa phổ—thư viện này cho phép các nhà nghiên cứu tập trung vào phát triển phương pháp thay vì xử lý vấn đề kỹ thuật dữ liệu.</p><p>Các mục tiếp theo sẽ đi sâu vào từng nhóm mô hình được hỗ trợ bởi TorchGeo:</p><ul><li><strong>Mục 3.2:</strong> Backbone models cho classification (ResNet, ViT, Swin, EfficientNet)</li><li><strong>Mục 3.3:</strong> Segmentation architectures (U-Net, DeepLabV3+, FPN, PSPNet, HRNet)</li><li><strong>Mục 3.4:</strong> Change detection models (FC-Siam, BIT-Transformer, STANet)</li><li><strong>Mục 3.5:</strong> Pre-trained weights (SSL4EO, SatMAE, Prithvi)</li></ul><hr><h2 id="tai-lieu-tham-khao" tabindex="-1">Tài Liệu Tham Khảo <a class="header-anchor" href="#tai-lieu-tham-khao" aria-label="Permalink to &quot;Tài Liệu Tham Khảo&quot;">​</a></h2><p>[1] Stewart, A. J., Robinson, C., Corley, I. A., Ortiz, A., Ferres, J. M. L., &amp; Banber, A. (2022). &quot;TorchGeo: Deep learning with geospatial data.&quot; In Proceedings of the 30th International Conference on Advances in Geographic Information Systems (SIGSPATIAL &#39;22). arXiv:2111.08872.</p><p>[2] Cong, Y., Khanna, S., Meng, C., Liu, P., Rozi, E., He, Y., ... &amp; Hoyer, P. (2022). &quot;SatMAE: Pre-training Transformers for Temporal and Multi-Spectral Satellite Imagery.&quot; Advances in Neural Information Processing Systems, 35. arXiv:2207.08051.</p><p>[3] Wang, Y., Braham, N. A. A., Xiong, Z., Liu, C., Albrecht, C. M., &amp; Zhu, X. X. (2022). &quot;SSL4EO-S12: A large-scale multi-modal, multi-temporal dataset for self-supervised learning in Earth observation.&quot; arXiv:2211.07044.</p><p>[4] Ayush, K., Uzkent, B., Meng, C., Tanmay, K., Burke, M., Lobell, D., &amp; Ermon, S. (2021). &quot;Geography-Aware Self-Supervised Learning.&quot; In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). arXiv:2011.09980.</p>',53))])}const y=s(p,[["render",d]]);export{T as __pageData,y as default};
