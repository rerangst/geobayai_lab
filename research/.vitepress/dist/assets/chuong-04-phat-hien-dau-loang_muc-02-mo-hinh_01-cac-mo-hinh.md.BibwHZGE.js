import{_ as i,c as t,o,a2 as a}from"./chunks/framework.nRfFlDZQ.js";const u=JSON.parse('{"title":"Chương 4: Các Model Deep Learning cho Oil Spill Detection","description":"","frontmatter":{},"headers":[],"relativePath":"chuong-04-phat-hien-dau-loang/muc-02-mo-hinh/01-cac-mo-hinh.md","filePath":"chuong-04-phat-hien-dau-loang/muc-02-mo-hinh/01-cac-mo-hinh.md","lastUpdated":1766163869000}'),n={name:"chuong-04-phat-hien-dau-loang/muc-02-mo-hinh/01-cac-mo-hinh.md"};function l(r,e,s,c,p,d){return o(),t("div",null,[...e[0]||(e[0]=[a('<h1 id="chuong-4-cac-model-deep-learning-cho-oil-spill-detection" tabindex="-1">Chương 4: Các Model Deep Learning cho Oil Spill Detection <a class="header-anchor" href="#chuong-4-cac-model-deep-learning-cho-oil-spill-detection" aria-label="Permalink to &quot;Chương 4: Các Model Deep Learning cho Oil Spill Detection&quot;">​</a></h1><h2 id="_5-9-tong-quan-ve-approaches" tabindex="-1">5.9. Tổng quan về Approaches <a class="header-anchor" href="#_5-9-tong-quan-ve-approaches" aria-label="Permalink to &quot;5.9. Tổng quan về Approaches&quot;">​</a></h2><p>Các phương pháp deep learning cho oil spill detection có thể được phân loại theo nhiều tiêu chí. Theo kiến trúc, có encoder-decoder networks, fully convolutional networks, và attention-based models. Theo task formulation, có binary segmentation, multi-class segmentation, và detection-based approaches. Theo input, có single-polarization, multi-polarization, và multi-sensor fusion approaches.</p><p>Khác với ship detection nơi object detection (bounding box) là approach chính, oil spill detection thường formulated như segmentation problem do nature của oil spill là extended irregular region thay vì compact object. Tuy nhiên, một số approaches sử dụng detection để find candidate regions trước khi segment.</p><h2 id="_5-10-encoder-decoder-architectures" tabindex="-1">5.10. Encoder-Decoder Architectures <a class="header-anchor" href="#_5-10-encoder-decoder-architectures" aria-label="Permalink to &quot;5.10. Encoder-Decoder Architectures&quot;">​</a></h2><h3 id="_5-10-1-u-net-cho-oil-spill-detection" tabindex="-1">5.10.1. U-Net cho Oil Spill Detection <a class="header-anchor" href="#_5-10-1-u-net-cho-oil-spill-detection" aria-label="Permalink to &quot;5.10.1. U-Net cho Oil Spill Detection&quot;">​</a></h3><p>U-Net là architecture phổ biến nhất cho oil spill segmentation, với cấu trúc symmetric encoder-decoder và skip connections.</p><p><strong>Encoder Path:</strong> Encoder sử dụng repeated blocks của convolution layers theo sau bởi max pooling để extract hierarchical features. Mỗi block giảm spatial resolution đi một nửa trong khi tăng số channels. Typical configuration có 4-5 pooling operations, tạo feature maps ở multiple scales.</p><p>Cho oil spill detection từ SAR, encoder được adapted để handle single-channel hoặc dual-polarization input:</p><ul><li>Single-channel (VV hoặc VH): Input 1×H×W</li><li>Dual-polarization: Input 2×H×W (VV và VH stacked)</li><li>Multi-look combinations: Input có thể include intensity và phase information</li></ul><p><strong>Decoder Path:</strong> Decoder progressively upsamples feature maps và combines với corresponding encoder features qua skip connections. Transposed convolutions hoặc bilinear upsampling được sử dụng. Skip connections preserve fine-grained spatial information quan trọng cho accurate boundary delineation.</p><p><strong>Modifications cho SAR Oil Spill:</strong></p><ol><li><p><strong>Attention Gates:</strong> Thêm attention mechanisms vào skip connections để focus vào relevant regions. Attention U-Net variant được áp dụng thành công cho oil spill detection, helping model focus vào dark regions while ignoring irrelevant background.</p></li><li><p><strong>Deep Supervision:</strong> Thêm auxiliary outputs ở multiple decoder levels, forcing intermediate layers to produce meaningful segmentation. Deep supervision improves gradient flow và helps với class imbalance.</p></li><li><p><strong>Residual Connections:</strong> Thay basic convolution blocks bằng residual blocks (inspired by ResNet) cho better gradient flow và deeper networks.</p></li><li><p><strong>Dilated Convolutions:</strong> Sử dụng dilated convolutions trong bottleneck để increase receptive field without losing resolution, helpful cho capturing large oil spill extents.</p></li></ol><p><strong>Kết quả điển hình:</strong> Trên các datasets chuẩn, U-Net variants đạt IoU 70-85% tùy dataset và configuration. Attention U-Net và residual U-Net thường outperform vanilla U-Net.</p><h3 id="_5-10-2-segnet" tabindex="-1">5.10.2. SegNet <a class="header-anchor" href="#_5-10-2-segnet" aria-label="Permalink to &quot;5.10.2. SegNet&quot;">​</a></h3><p>SegNet là một encoder-decoder architecture với đặc điểm sử dụng max pooling indices trong decoder thay vì full feature maps trong skip connections.</p><p><strong>Encoder:</strong> Tương tự VGG network, với 13 convolutional layers grouped into 5 blocks với max pooling. Trong quá trình pooling, indices của max values được lưu lại.</p><p><strong>Decoder:</strong> Sử dụng stored pooling indices để upsample, sau đó apply convolutions. Approach này giảm memory usage so với U-Net (chỉ store indices thay vì full feature maps) nhưng có thể lose một số fine-grained information.</p><p><strong>Cho Oil Spill Detection:</strong> SegNet được sử dụng trong một số early works về oil spill detection từ SAR. Performance thường thấp hơn U-Net variants do loss of information trong pooling indices approach.</p><h3 id="_5-10-3-deeplabv3-cho-oil-spill-detection" tabindex="-1">5.10.3. DeepLabV3+ cho Oil Spill Detection <a class="header-anchor" href="#_5-10-3-deeplabv3-cho-oil-spill-detection" aria-label="Permalink to &quot;5.10.3. DeepLabV3+ cho Oil Spill Detection&quot;">​</a></h3><p>DeepLabV3+ với atrous spatial pyramid pooling (ASPP) module đã được áp dụng cho oil spill detection với kết quả tốt.</p><p><strong>Architecture Overview:</strong></p><ul><li><strong>Encoder:</strong> Backbone network (ResNet, Xception) với output stride 8 hoặc 16</li><li><strong>ASPP Module:</strong> Multiple atrous convolutions với different dilation rates để capture multi-scale context</li><li><strong>Decoder:</strong> Simple decoder với skip connection từ low-level features</li></ul><p><strong>Ưu điểm cho Oil Spill:</strong></p><ul><li>Multi-scale feature aggregation phù hợp cho variable oil spill sizes</li><li>Large receptive field captures context for look-alike discrimination</li><li>State-of-the-art encoder (ResNet, Xception) provides strong features</li></ul><p><strong>Modifications:</strong></p><ul><li>Adapted first convolutional layer cho single/dual-channel SAR input</li><li>Modified output channels (2 cho binary, hoặc nhiều hơn cho multi-class)</li><li>Fine-tuned atrous rates cho typical oil spill scales</li></ul><h3 id="_5-10-4-pspnet-pyramid-scene-parsing-network" tabindex="-1">5.10.4. PSPNet (Pyramid Scene Parsing Network) <a class="header-anchor" href="#_5-10-4-pspnet-pyramid-scene-parsing-network" aria-label="Permalink to &quot;5.10.4. PSPNet (Pyramid Scene Parsing Network)&quot;">​</a></h3><p>PSPNet sử dụng pyramid pooling module để aggregate global context information.</p><p><strong>Pyramid Pooling Module:</strong> Áp dụng pooling ở multiple scales (1×1, 2×2, 3×3, 6×6), sau đó upsample và concatenate với original features. Điều này cho model global context về toàn bộ scene.</p><p><strong>Cho Oil Spill Detection:</strong> Global context đặc biệt hữu ích cho oil spill detection:</p><ul><li>Hiểu overall sea state (wind conditions)</li><li>Recognize patterns indicating look-alikes (linear features, periodic patterns)</li><li>Distinguish isolated spill từ widespread phenomena</li></ul><h2 id="_5-11-feature-pyramid-networks" tabindex="-1">5.11. Feature Pyramid Networks <a class="header-anchor" href="#_5-11-feature-pyramid-networks" aria-label="Permalink to &quot;5.11. Feature Pyramid Networks&quot;">​</a></h2><h3 id="_5-11-1-fpn-based-segmentation" tabindex="-1">5.11.1. FPN-based Segmentation <a class="header-anchor" href="#_5-11-1-fpn-based-segmentation" aria-label="Permalink to &quot;5.11.1. FPN-based Segmentation&quot;">​</a></h3><p>Feature Pyramid Network được sử dụng không chỉ cho detection mà còn cho segmentation trong oil spill applications.</p><p><strong>Architecture:</strong></p><ul><li>Bottom-up pathway: Backbone network tạo multi-scale features</li><li>Top-down pathway: Upsample và merge với bottom-up features</li><li>Lateral connections: 1×1 convolutions cho channel adaptation</li><li>Prediction heads: Segment prediction ở mỗi pyramid level</li></ul><p><strong>Multi-scale Benefits:</strong> Oil spills có kích thước rất diverse (từ vài trăm meters đến hàng chục kilometers). FPN cho phép model detect và segment ở multiple scales effectively.</p><h3 id="_5-11-2-panet-path-aggregation-network" tabindex="-1">5.11.2. PANet (Path Aggregation Network) <a class="header-anchor" href="#_5-11-2-panet-path-aggregation-network" aria-label="Permalink to &quot;5.11.2. PANet (Path Aggregation Network)&quot;">​</a></h3><p>PANet extends FPN với additional bottom-up path để strengthen feature hierarchy.</p><p><strong>Ý tưởng:</strong> Sau top-down path của FPN, thêm một bottom-up path nữa để information flow both ways. Điều này creates stronger multi-scale feature representation.</p><p><strong>Application:</strong> PANet-based segmentation đã được áp dụng cho ocean remote sensing applications including oil spill detection, với improvements over basic FPN.</p><h2 id="_5-12-attention-based-models" tabindex="-1">5.12. Attention-based Models <a class="header-anchor" href="#_5-12-attention-based-models" aria-label="Permalink to &quot;5.12. Attention-based Models&quot;">​</a></h2><h3 id="_5-12-1-attention-u-net" tabindex="-1">5.12.1. Attention U-Net <a class="header-anchor" href="#_5-12-1-attention-u-net" aria-label="Permalink to &quot;5.12.1. Attention U-Net&quot;">​</a></h3><p>Attention U-Net thêm attention gates vào skip connections của U-Net.</p><p><strong>Attention Gate:</strong> Cho mỗi skip connection, attention gate compute attention coefficients dựa trên:</p><ul><li>Features từ encoder (cao resolution, local information)</li><li>Features từ decoder (thấp resolution, semantic information)</li></ul><p>Output là weighted combination focusing vào relevant regions. Trong oil spill context, attention helps model focus vào dark regions (potential spills) while suppressing bright regions (normal sea surface).</p><p><strong>Results:</strong> Studies show Attention U-Net consistently outperforms vanilla U-Net cho oil spill detection, với improvements particularly noticeable for complex scenes with look-alikes.</p><h3 id="_5-12-2-self-attention-va-transformers" tabindex="-1">5.12.2. Self-Attention và Transformers <a class="header-anchor" href="#_5-12-2-self-attention-va-transformers" aria-label="Permalink to &quot;5.12.2. Self-Attention và Transformers&quot;">​</a></h3><p>Self-attention mechanisms và Vision Transformers (ViT) đang được áp dụng cho oil spill detection.</p><p><strong>Self-Attention in CNNs:</strong> Thêm self-attention layers vào CNN architectures (như CBAM, SE-Net, Non-local blocks) để capture long-range dependencies. Oil spills có thể extend over large areas, và self-attention helps capture correlations across distant parts of the image.</p><p><strong>Vision Transformers:</strong> ViT-based architectures như Swin Transformer đã được áp dụng cho oil spill segmentation:</p><ul><li><strong>Swin-UNet:</strong> Combines Swin Transformer với U-Net style encoder-decoder</li><li><strong>SegFormer:</strong> Efficient transformer-based segmentation</li></ul><p><strong>Trade-offs:</strong></p><ul><li>Transformers capture global context better than CNNs</li><li>Require more training data và compute resources</li><li>Performance gains may be marginal for well-tuned CNNs on small datasets</li></ul><h3 id="_5-12-3-dual-attention-networks" tabindex="-1">5.12.3. Dual-Attention Networks <a class="header-anchor" href="#_5-12-3-dual-attention-networks" aria-label="Permalink to &quot;5.12.3. Dual-Attention Networks&quot;">​</a></h3><p>Dual-attention networks sử dụng cả position attention và channel attention để capture comprehensive contextual information.</p><p><strong>Position Attention:</strong> Capture long-range spatial dependencies - quan trọng cho understanding oil spill shape và extent.</p><p><strong>Channel Attention:</strong> Capture inter-channel relationships - hữu ích cho multi-polarization SAR data where different polarizations capture different information.</p><h2 id="_5-13-multi-scale-va-multi-resolution-approaches" tabindex="-1">5.13. Multi-scale và Multi-resolution Approaches <a class="header-anchor" href="#_5-13-multi-scale-va-multi-resolution-approaches" aria-label="Permalink to &quot;5.13. Multi-scale và Multi-resolution Approaches&quot;">​</a></h2><h3 id="_5-13-1-hrnet-high-resolution-network" tabindex="-1">5.13.1. HRNet (High-Resolution Network) <a class="header-anchor" href="#_5-13-1-hrnet-high-resolution-network" aria-label="Permalink to &quot;5.13.1. HRNet (High-Resolution Network)&quot;">​</a></h3><p>HRNet maintains high-resolution representations throughout the network thay vì downsample rồi upsample.</p><p><strong>Architecture:</strong></p><ul><li>Multiple parallel branches ở different resolutions</li><li>Repeated multi-resolution fusions</li><li>All branches contribute to final prediction</li></ul><p><strong>Benefits cho Oil Spill:</strong></p><ul><li>Preserve fine-grained boundary information</li><li>Better segmentation của thin oil slicks và complex shapes</li><li>Reduced information loss compared to encoder-decoder approaches</li></ul><h3 id="_5-13-2-cascade-architectures" tabindex="-1">5.13.2. Cascade Architectures <a class="header-anchor" href="#_5-13-2-cascade-architectures" aria-label="Permalink to &quot;5.13.2. Cascade Architectures&quot;">​</a></h3><p>Cascade approaches process image ở multiple resolutions sequentially:</p><ol><li>Coarse detection ở low resolution để find candidate regions</li><li>Refined segmentation ở high resolution cho candidate regions</li></ol><p>Approach này efficient cho large SAR scenes where oil spill coverage is typically small percentage of total area.</p><h2 id="_5-14-multi-task-va-auxiliary-learning" tabindex="-1">5.14. Multi-task và Auxiliary Learning <a class="header-anchor" href="#_5-14-multi-task-va-auxiliary-learning" aria-label="Permalink to &quot;5.14. Multi-task và Auxiliary Learning&quot;">​</a></h2><h3 id="_5-14-1-oil-spill-look-alike-classification" tabindex="-1">5.14.1. Oil Spill + Look-alike Classification <a class="header-anchor" href="#_5-14-1-oil-spill-look-alike-classification" aria-label="Permalink to &quot;5.14.1. Oil Spill + Look-alike Classification&quot;">​</a></h3><p>Multi-task learning joint training cho:</p><ul><li>Oil spill segmentation (primary task)</li><li>Look-alike classification (auxiliary task)</li></ul><p><strong>Architecture:</strong> Shared encoder với multiple heads:</p><ul><li>Segmentation head: Dense prediction của oil spill mask</li><li>Classification head: Global prediction của look-alike presence/type</li></ul><p><strong>Benefits:</strong></p><ul><li>Shared features cho related tasks improve efficiency</li><li>Classification task provides additional supervision signal</li><li>May help learn discriminative features for look-alike rejection</li></ul><h3 id="_5-14-2-segmentation-confidence-estimation" tabindex="-1">5.14.2. Segmentation + Confidence Estimation <a class="header-anchor" href="#_5-14-2-segmentation-confidence-estimation" aria-label="Permalink to &quot;5.14.2. Segmentation + Confidence Estimation&quot;">​</a></h3><p>Auxiliary task estimating uncertainty/confidence:</p><ul><li>Primary output: Segmentation mask</li><li>Auxiliary output: Per-pixel confidence scores</li></ul><p>High confidence regions can be trusted; low confidence regions may need operator review.</p><h3 id="_5-14-3-joint-ship-va-oil-spill-detection" tabindex="-1">5.14.3. Joint Ship và Oil Spill Detection <a class="header-anchor" href="#_5-14-3-joint-ship-va-oil-spill-detection" aria-label="Permalink to &quot;5.14.3. Joint Ship và Oil Spill Detection&quot;">​</a></h3><p>Joint model cho both ship và oil spill detection:</p><ul><li>Ships appear bright trong SAR (opposite of oil)</li><li>Shared features for understanding sea surface</li><li>May help identify oil spill sources</li></ul><h2 id="_5-15-approaches-cho-look-alike-discrimination" tabindex="-1">5.15. Approaches cho Look-alike Discrimination <a class="header-anchor" href="#_5-15-approaches-cho-look-alike-discrimination" aria-label="Permalink to &quot;5.15. Approaches cho Look-alike Discrimination&quot;">​</a></h2><h3 id="_5-15-1-contextual-feature-extraction" tabindex="-1">5.15.1. Contextual Feature Extraction <a class="header-anchor" href="#_5-15-1-contextual-feature-extraction" aria-label="Permalink to &quot;5.15.1. Contextual Feature Extraction&quot;">​</a></h3><p>Models designed to explicitly extract contextual features cho look-alike discrimination:</p><p><strong>Wind Information Integration:</strong></p><ul><li>Input wind speed/direction as additional channels</li><li>Model learns wind-dependent appearance variations</li><li>Low wind regions less likely to be oil spill</li></ul><p><strong>Temporal Context:</strong></p><ul><li>Optical flow hoặc difference images từ multiple acquisitions</li><li>Oil spills persist và drift; meteorological look-alikes dissipate</li></ul><p><strong>Geographic Context:</strong></p><ul><li>Distance to coastline, shipping lanes, platforms</li><li>Historical spill locations</li><li>Bathymetry (natural seeps at certain depths)</li></ul><h3 id="_5-15-2-two-stage-approaches" tabindex="-1">5.15.2. Two-stage Approaches <a class="header-anchor" href="#_5-15-2-two-stage-approaches" aria-label="Permalink to &quot;5.15.2. Two-stage Approaches&quot;">​</a></h3><p>Stage 1 - Detection: Find all dark regions (potential spills và look-alikes) Stage 2 - Classification: Classify each detected region as oil or look-alike</p><p><strong>Stage 1 Models:</strong> Simple threshold-based detection hoặc trained detector focusing on recall (không miss actual spills).</p><p><strong>Stage 2 Models:</strong> CNN classifier với features extracted từ detected regions:</p><ul><li>Shape features (elongation, complexity, fractal dimension)</li><li>Intensity features (contrast, homogeneity)</li><li>Texture features (GLCM, wavelets)</li><li>Contextual features (proximity to ships, wind conditions)</li></ul><h3 id="_5-15-3-ensemble-approaches" tabindex="-1">5.15.3. Ensemble Approaches <a class="header-anchor" href="#_5-15-3-ensemble-approaches" aria-label="Permalink to &quot;5.15.3. Ensemble Approaches&quot;">​</a></h3><p>Combine multiple models with different characteristics:</p><ul><li>Different architectures (U-Net, DeepLab, SegFormer)</li><li>Different input (VV, VH, VV+VH)</li><li>Different training strategies (different augmentations, loss functions)</li></ul><p>Ensemble output: Vote hoặc average of individual model predictions. Typically reduces false positives while maintaining detection rate.</p><h2 id="_5-16-loss-functions-cho-oil-spill-detection" tabindex="-1">5.16. Loss Functions cho Oil Spill Detection <a class="header-anchor" href="#_5-16-loss-functions-cho-oil-spill-detection" aria-label="Permalink to &quot;5.16. Loss Functions cho Oil Spill Detection&quot;">​</a></h2><h3 id="_5-16-1-binary-cross-entropy-bce" tabindex="-1">5.16.1. Binary Cross-Entropy (BCE) <a class="header-anchor" href="#_5-16-1-binary-cross-entropy-bce" aria-label="Permalink to &quot;5.16.1. Binary Cross-Entropy (BCE)&quot;">​</a></h3><p>Standard pixel-wise loss cho binary segmentation: BCE = -[y×log(p) + (1-y)×log(1-p)]</p><p>với y là ground truth (0 hoặc 1) và p là predicted probability.</p><p><strong>Vấn đề cho Oil Spill:</strong> Class imbalance (mostly background pixels) makes BCE suboptimal - model có thể achieve low loss by predicting all background.</p><h3 id="_5-16-2-weighted-cross-entropy" tabindex="-1">5.16.2. Weighted Cross-Entropy <a class="header-anchor" href="#_5-16-2-weighted-cross-entropy" aria-label="Permalink to &quot;5.16.2. Weighted Cross-Entropy&quot;">​</a></h3><p>Address class imbalance bằng weighting: WCE = -[w₁×y×log(p) + w₀×(1-y)×log(1-p)]</p><p>với w₁ &gt;&gt; w₀ để increase importance của positive (oil) class.</p><p>Weight ratio có thể được set based on class proportions hoặc tuned as hyperparameter.</p><h3 id="_5-16-3-focal-loss" tabindex="-1">5.16.3. Focal Loss <a class="header-anchor" href="#_5-16-3-focal-loss" aria-label="Permalink to &quot;5.16.3. Focal Loss&quot;">​</a></h3><p>Focal Loss reduces weight của easy examples, focusing training on hard examples: FL = -α×(1-p)^γ × log(p) cho positive class FL = -(1-α)×p^γ × log(1-p) cho negative class</p><p>γ (focusing parameter, typically 2) controls how much to down-weight easy examples.</p><p>Focal Loss đặc biệt hiệu quả cho oil spill detection với severe class imbalance.</p><h3 id="_5-16-4-dice-loss" tabindex="-1">5.16.4. Dice Loss <a class="header-anchor" href="#_5-16-4-dice-loss" aria-label="Permalink to &quot;5.16.4. Dice Loss&quot;">​</a></h3><p>Directly optimize Dice coefficient (F1 score): Dice Loss = 1 - (2×|P∩G| + smooth) / (|P| + |G| + smooth)</p><p>với P là predicted mask, G là ground truth mask, smooth là small constant để avoid division by zero.</p><p><strong>Ưu điểm:</strong></p><ul><li>Không affected by class imbalance (optimizes overlap directly)</li><li>Better cho segmentation metrics</li></ul><p><strong>Nhược điểm:</strong></p><ul><li>Gradient magnitude giảm khi prediction improves</li><li>May need combination với BCE cho stable training</li></ul><h3 id="_5-16-5-iou-loss-jaccard-loss" tabindex="-1">5.16.5. IoU Loss (Jaccard Loss) <a class="header-anchor" href="#_5-16-5-iou-loss-jaccard-loss" aria-label="Permalink to &quot;5.16.5. IoU Loss (Jaccard Loss)&quot;">​</a></h3><p>Similar concept to Dice, directly optimize IoU: IoU Loss = 1 - |P∩G| / |P∪G|</p><h3 id="_5-16-6-combined-loss-functions" tabindex="-1">5.16.6. Combined Loss Functions <a class="header-anchor" href="#_5-16-6-combined-loss-functions" aria-label="Permalink to &quot;5.16.6. Combined Loss Functions&quot;">​</a></h3><p>Common practice là combine multiple losses: L_total = λ₁×BCE + λ₂×Dice + λ₃×Focal</p><p>với λ weights tuned cho optimal performance. Combined losses provide benefits of each:</p><ul><li>BCE cho stable gradients</li><li>Dice cho overlap optimization</li><li>Focal cho handling class imbalance</li></ul><h3 id="_5-16-7-boundary-aware-losses" tabindex="-1">5.16.7. Boundary-aware Losses <a class="header-anchor" href="#_5-16-7-boundary-aware-losses" aria-label="Permalink to &quot;5.16.7. Boundary-aware Losses&quot;">​</a></h3><p>Special losses focusing on boundary accuracy:</p><ul><li><strong>Boundary Loss:</strong> Weight higher cho pixels near boundaries</li><li><strong>Hausdorff Distance Loss:</strong> Minimize maximum boundary deviation</li><li><strong>Active Contour Loss:</strong> Model contour explicitly</li></ul><p>Accurate boundaries quan trọng cho oil spill extent estimation.</p><h2 id="_5-17-polarimetric-sar-features" tabindex="-1">5.17. Polarimetric SAR Features <a class="header-anchor" href="#_5-17-polarimetric-sar-features" aria-label="Permalink to &quot;5.17. Polarimetric SAR Features&quot;">​</a></h2><h3 id="_5-17-1-dual-pol-va-quad-pol-data" tabindex="-1">5.17.1. Dual-Pol và Quad-Pol Data <a class="header-anchor" href="#_5-17-1-dual-pol-va-quad-pol-data" aria-label="Permalink to &quot;5.17.1. Dual-Pol và Quad-Pol Data&quot;">​</a></h3><p>Sentinel-1 provides dual-polarization (VV + VH) data. Some SAR satellites provide quad-polarization (HH, HV, VH, VV).</p><p><strong>Using Multiple Polarizations:</strong> Different polarizations capture different scattering mechanisms:</p><ul><li>VV: Vertical-Vertical, sensitive to surface roughness</li><li>VH: Vertical-Horizontal, sensitive to volume scattering</li><li>HH: Horizontal-Horizontal, similar to VV but different geometry</li><li>HV: Horizontal-Vertical, similar to VH</li></ul><p>Oil spill affects polarizations differently, providing additional discrimination power.</p><h3 id="_5-17-2-polarimetric-features-cho-deep-learning" tabindex="-1">5.17.2. Polarimetric Features cho Deep Learning <a class="header-anchor" href="#_5-17-2-polarimetric-features-cho-deep-learning" aria-label="Permalink to &quot;5.17.2. Polarimetric Features cho Deep Learning&quot;">​</a></h3><p><strong>Multi-channel Input:</strong> Stack polarizations as multiple channels:</p><ul><li>2-channel input: VV, VH</li><li>4-channel input: HH, HV, VH, VV</li><li>With derived features: VV, VH, VV/VH ratio, etc.</li></ul><p><strong>Polarimetric Decomposition:</strong> Compute polarimetric decomposition features (Entropy, Alpha, Anisotropy for dual-pol; Pauli, Freeman-Durden for quad-pol) và use as additional input channels.</p><p><strong>Learning Polarimetric Features:</strong> Let network learn optimal combination của polarimetric information through training, rather than hand-crafting features.</p><h3 id="_5-17-3-pseudo-color-composite" tabindex="-1">5.17.3. Pseudo-color Composite <a class="header-anchor" href="#_5-17-3-pseudo-color-composite" aria-label="Permalink to &quot;5.17.3. Pseudo-color Composite&quot;">​</a></h3><p>Common practice để visualize và possibly use as input:</p><ul><li>R: VV</li><li>G: VH</li><li>B: VV/VH ratio</li></ul><p>Network có thể process RGB-like input using standard pre-trained backbones.</p><h2 id="_5-18-so-sanh-va-lua-chon-model" tabindex="-1">5.18. So sánh và Lựa chọn Model <a class="header-anchor" href="#_5-18-so-sanh-va-lua-chon-model" aria-label="Permalink to &quot;5.18. So sánh và Lựa chọn Model&quot;">​</a></h2><h3 id="_5-18-1-bang-so-sanh-performance" tabindex="-1">5.18.1. Bảng So sánh Performance <a class="header-anchor" href="#_5-18-1-bang-so-sanh-performance" aria-label="Permalink to &quot;5.18.1. Bảng So sánh Performance&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Model</th><th>Typical IoU</th><th>Speed</th><th>Memory</th><th>Notes</th></tr></thead><tbody><tr><td>U-Net</td><td>70-75%</td><td>Fast</td><td>Medium</td><td>Simple, effective baseline</td></tr><tr><td>Attention U-Net</td><td>75-80%</td><td>Medium</td><td>Medium</td><td>Better focus on relevant regions</td></tr><tr><td>DeepLabV3+</td><td>75-82%</td><td>Medium</td><td>High</td><td>Strong multi-scale capabilities</td></tr><tr><td>HRNet</td><td>78-85%</td><td>Slow</td><td>High</td><td>Best boundary preservation</td></tr><tr><td>Swin-UNet</td><td>80-85%</td><td>Slow</td><td>Very High</td><td>Best global context, needs data</td></tr></tbody></table><p><em>Note: Performance varies significantly với dataset, preprocessing, and training configuration.</em></p><h3 id="_5-18-2-recommendations-theo-use-case" tabindex="-1">5.18.2. Recommendations theo Use Case <a class="header-anchor" href="#_5-18-2-recommendations-theo-use-case" aria-label="Permalink to &quot;5.18.2. Recommendations theo Use Case&quot;">​</a></h3><p><strong>Real-time Monitoring:</strong></p><ul><li>U-Net hoặc lightweight variants (EfficientNet encoder)</li><li>Trade some accuracy for speed</li><li>Single-scale inference</li></ul><p><strong>High Accuracy Research:</strong></p><ul><li>HRNet hoặc ensemble của multiple architectures</li><li>Multi-scale inference với TTA</li><li>Careful post-processing</li></ul><p><strong>Limited Training Data:</strong></p><ul><li>U-Net với strong augmentation</li><li>Pre-trained encoder (từ natural images hoặc remote sensing)</li><li>Avoid large models prone to overfitting</li></ul><p><strong>Multi-class (Oil + Look-alikes):</strong></p><ul><li>DeepLabV3+ hoặc similar với sufficient capacity</li><li>Consider two-stage approach</li><li>Carefully balanced loss functions</li></ul><h3 id="_5-18-3-implementation-considerations" tabindex="-1">5.18.3. Implementation Considerations <a class="header-anchor" href="#_5-18-3-implementation-considerations" aria-label="Permalink to &quot;5.18.3. Implementation Considerations&quot;">​</a></h3><p><strong>Frameworks:</strong></p><ul><li>PyTorch: Flexible, research-oriented</li><li>TensorFlow/Keras: Good deployment options</li><li>Segmentation Models (Python library): Pre-built architectures</li></ul><p><strong>Pre-trained Weights:</strong></p><ul><li>ImageNet pre-training helps even cho single-channel SAR</li><li>Remote sensing pre-training (từ TorchGeo hoặc similar) may be better</li><li>Self-supervised pre-training on unlabeled SAR data is emerging approach</li></ul><p><strong>Training Practices:</strong></p><ul><li>Use combined loss (BCE + Dice typically)</li><li>Strong augmentation (rotation, flip, scale, noise)</li><li>Learning rate scheduling (cosine, step decay)</li><li>Early stopping based on validation IoU</li></ul>',169)])])}const g=i(n,[["render",l]]);export{u as __pageData,g as default};
