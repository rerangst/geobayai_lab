import{_ as c,C as l,c as g,o as h,a2 as i,b as r,w as n,a as e,G as o,a3 as d}from"./chunks/framework.nRfFlDZQ.js";const C=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"chuong-04-xview-challenges/muc-03-xview3-maritime/02-giai-nhat.md","filePath":"chuong-04-xview-challenges/muc-03-xview3-maritime/02-giai-nhat.md","lastUpdated":1766302189000}'),u={name:"chuong-04-xview-challenges/muc-03-xview3-maritime/02-giai-nhat.md"};function s(p,t,E,A,b,m){const a=l("Mermaid");return h(),g("div",null,[t[4]||(t[4]=i('<p>#4.3.2 Giải Pháp Hạng Nhất xView3: Kiến Trúc CircleNet</p><h2 id="loi-dan" tabindex="-1">Lời Dẫn <a class="header-anchor" href="#loi-dan" aria-label="Permalink to &quot;Lời Dẫn&quot;">​</a></h2><p>Cuộc thi xView3: Dark Vessels Detection Challenge đánh dấu một bước chuyển mình quan trọng trong chuỗi xView khi chuyển từ ảnh quang học sang ảnh radar khẩu độ tổng hợp (SAR). Với dataset SAR phát hiện tàu lớn nhất thế giới và mục tiêu chống đánh bắt cá bất hợp pháp (IUU fishing), cuộc thi thu hút sự tham gia của gần 2,000 đội từ khắp toàn cầu. Giải pháp CircleNet của Eugene Khvedchenya - một Kaggle Grandmaster - đã giành chiến thắng với điểm số vượt trội gấp ba lần baseline, mở ra những hướng tiếp cận mới cho bài toán phát hiện đối tượng nhỏ trong ảnh radar.</p><table tabindex="0"><thead><tr><th>Thuộc tính</th><th>Giá trị</th></tr></thead><tbody><tr><td><strong>Xếp hạng</strong></td><td>1/1,900+ đội</td></tr><tr><td><strong>Tác giả</strong></td><td>Eugene Khvedchenya (BloodAxe)</td></tr><tr><td><strong>Điểm holdout</strong></td><td>0.617 (gấp 3× baseline)</td></tr><tr><td><strong>Giải thưởng</strong></td><td>$150,000</td></tr><tr><td><strong>Đóng góp chính</strong></td><td>CircleNet, Stride-2 output, Entropy regularization</td></tr></tbody></table><hr><h2 id="_1-boi-canh-va-phan-tich-bai-toan" tabindex="-1">1. Bối Cảnh và Phân Tích Bài Toán <a class="header-anchor" href="#_1-boi-canh-va-phan-tich-bai-toan" aria-label="Permalink to &quot;1. Bối Cảnh và Phân Tích Bài Toán&quot;">​</a></h2><h3 id="_1-1-đac-thu-cua-du-lieu-sar" tabindex="-1">1.1 Đặc Thù của Dữ Liệu SAR <a class="header-anchor" href="#_1-1-đac-thu-cua-du-lieu-sar" aria-label="Permalink to &quot;1.1 Đặc Thù của Dữ Liệu SAR&quot;">​</a></h3><p>Khác biệt căn bản với xView1 và xView2 - vốn sử dụng ảnh quang học - xView3 làm việc với ảnh SAR (Synthetic Aperture Radar). Sự khác biệt này tạo ra những thách thức kỹ thuật hoàn toàn mới:</p><p><strong>Dải động cực lớn</strong>: Giá trị pixel trong ảnh SAR có thể dao động từ -50dB đến +20dB, với nhiều giá trị ngoại lai (outliers) gây khó khăn cho việc chuẩn hóa dữ liệu.</p><p><strong>Nhiễu speckle đặc trưng</strong>: Ảnh SAR có loại nhiễu multiplicative đặc thù, khác biệt hoàn toàn với nhiễu Gaussian trong ảnh quang học.</p><p><strong>Kích thước đối tượng nhỏ</strong>: Các tàu thuyền trong ảnh SAR chỉ chiếm 10-100 pixels, đòi hỏi phương pháp phát hiện có độ phân giải cao.</p><h3 id="_1-2-thach-thuc-ve-nhan-du-lieu" tabindex="-1">1.2 Thách Thức về Nhãn Dữ Liệu <a class="header-anchor" href="#_1-2-thach-thuc-ve-nhan-du-lieu" aria-label="Permalink to &quot;1.2 Thách Thức về Nhãn Dữ Liệu&quot;">​</a></h3><p>Một trong những thách thức lớn nhất của xView3 là chất lượng nhãn. Phần lớn nhãn được tạo ra bằng cách đối chiếu với dữ liệu AIS (Automatic Identification System), nhưng:</p><ul><li>Tàu &quot;tối&quot; (dark vessels) cố tình tắt AIS nên không được gán nhãn</li><li>Nhiều tàu nhỏ không có thiết bị AIS</li><li>Một số nhãn được đánh dấu là &quot;unknown&quot; thay vì có giá trị xác định</li></ul>',14)),(h(),r(d,null,{default:n(()=>[o(a,{id:"mermaid-105",class:"mermaid",graph:"flowchart%20TB%0A%20%20%20%20subgraph%20LABELS%5B%22Ph%C3%A2n%20B%E1%BB%91%20Nh%C3%A3n%20xView3%22%5D%0A%20%20%20%20%20%20%20%20KNOWN%5B%22Nh%C3%A3n%20%C4%91%C3%A3%20bi%E1%BA%BFt%3Cbr%2F%3E%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%3Cbr%2F%3E%E2%80%A2%20C%C3%B3%20AIS%20t%C6%B0%C6%A1ng%20%E1%BB%A9ng%3Cbr%2F%3E%E2%80%A2%20Ph%C3%A2n%20lo%E1%BA%A1i%20r%C3%B5%20r%C3%A0ng%3Cbr%2F%3E%E2%80%A2%20~60%25%20d%E1%BB%AF%20li%E1%BB%87u%22%5D%0A%0A%20%20%20%20%20%20%20%20UNKNOWN%5B%22Nh%C3%A3n%20kh%C3%B4ng%20r%C3%B5%3Cbr%2F%3E%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%3Cbr%2F%3E%E2%80%A2%20Kh%C3%B4ng%20c%C3%B3%20AIS%3Cbr%2F%3E%E2%80%A2%20Kh%C3%B4ng%20th%E1%BB%83%20x%C3%A1c%20minh%3Cbr%2F%3E%E2%80%A2%20~40%25%20d%E1%BB%AF%20li%E1%BB%87u%22%5D%0A%0A%20%20%20%20%20%20%20%20DARK%5B%22T%C3%A0u%20t%E1%BB%91i%3Cbr%2F%3E%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%3Cbr%2F%3E%E2%80%A2%20C%E1%BB%91%20t%C3%ACnh%20t%E1%BA%AFt%20AIS%3Cbr%2F%3E%E2%80%A2%20M%E1%BB%A5c%20ti%C3%AAu%20ch%C3%ADnh%3Cbr%2F%3E%E2%80%A2%20Kh%C3%B4ng%20c%C3%B3%20ground%20truth%22%5D%0A%20%20%20%20end%0A"})]),fallback:n(()=>[...t[0]||(t[0]=[e(" Loading... ",-1)])]),_:1})),t[5]||(t[5]=i('<h3 id="_1-3-insight-quan-trong-tau-nhu-điem" tabindex="-1">1.3 Insight Quan Trọng: Tàu Như Điểm <a class="header-anchor" href="#_1-3-insight-quan-trong-tau-nhu-điem" aria-label="Permalink to &quot;1.3 Insight Quan Trọng: Tàu Như Điểm&quot;">​</a></h3><p>Nhóm tác giả nhận ra rằng với kích thước tàu nhỏ (10-100 pixels), phương pháp phát hiện dựa trên bounding box truyền thống không phải lựa chọn tối ưu. Thay vào đó, coi mỗi tàu như một <strong>điểm trung tâm</strong> trên heatmap mang lại nhiều ưu điểm:</p><ul><li>Không cần ước lượng kích thước bounding box</li><li>Phù hợp với đặc điểm đối tượng nhỏ và đẳng hướng</li><li>Cho phép sử dụng heatmap regression thay vì anchor-based detection</li></ul><hr><h2 id="_2-kien-truc-circlenet" tabindex="-1">2. Kiến Trúc CircleNet <a class="header-anchor" href="#_2-kien-truc-circlenet" aria-label="Permalink to &quot;2. Kiến Trúc CircleNet&quot;">​</a></h2><h3 id="_2-1-y-tuong-cot-loi" tabindex="-1">2.1 Ý Tưởng Cốt Lõi <a class="header-anchor" href="#_2-1-y-tuong-cot-loi" aria-label="Permalink to &quot;2.1 Ý Tưởng Cốt Lõi&quot;">​</a></h3><p>CircleNet kết hợp hai ý tưởng mạnh mẽ: phát hiện dựa trên điểm từ CenterNet và skip connections độ phân giải cao từ U-Net. Tên gọi &quot;CircleNet&quot; xuất phát từ việc biểu diễn mỗi tàu như một điểm tròn trên heatmap.</p><blockquote><p><strong>Tham khảo Chương 3</strong>: Kiến trúc EfficientNet được trình bày tại <a href="/sen_doc/chuong-03-kien-truc-model/muc-02-classification/01-classification-models.html">Mục 3.2 - Classification Models</a>, và U-Net decoder với skip connections được giới thiệu trong <a href="/sen_doc/chuong-03-kien-truc-model/muc-03-segmentation/01-segmentation-models.html">Mục 3.3 - Segmentation Models</a>.</p></blockquote>',8)),(h(),r(d,null,{default:n(()=>[o(a,{id:"mermaid-144",class:"mermaid",graph:"flowchart%20TB%0A%20%20%20%20subgraph%20ARCH%5B%22Ki%E1%BA%BFn%20Tr%C3%BAc%20CircleNet%22%5D%0A%20%20%20%20%20%20%20%20subgraph%20INPUT%5B%22%C4%90%E1%BA%A7u%20V%C3%A0o%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20SAR%5B%22%E1%BA%A2nh%20SAR%3Cbr%2F%3E2048%C3%972048%3Cbr%2F%3E4%20k%C3%AAnh%22%5D%0A%20%20%20%20%20%20%20%20end%0A%0A%20%20%20%20%20%20%20%20subgraph%20ENCODER%5B%22Encoder%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20E1%5B%22EfficientNet-B4%2FB5%2FV2S%3Cbr%2F%3EPretrained%20ImageNet%3Cbr%2F%3EStride%3A%202%E2%86%924%E2%86%928%E2%86%9216%E2%86%9232%22%5D%0A%20%20%20%20%20%20%20%20end%0A%0A%20%20%20%20%20%20%20%20subgraph%20DECODER%5B%22Decoder%20U-Net%20Style%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20D1%5B%22Skip%20Connections%3Cbr%2F%3Et%E1%BA%A1i%20m%E1%BB%97i%20t%E1%BB%B7%20l%E1%BB%87%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20D2%5B%22PixelShuffle%20Upsampling%3Cbr%2F%3EStride-4%20%E2%86%92%20Stride-2%22%5D%0A%20%20%20%20%20%20%20%20end%0A%0A%20%20%20%20%20%20%20%20subgraph%20HEADS%5B%22Task%20Heads%20Ri%C3%AAng%20Bi%E1%BB%87t%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20H1%5B%22Objectness%3Cbr%2F%3EHeatmap%20ph%C3%A1t%20hi%E1%BB%87n%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20H2%5B%22Is%20Vessel%3Cbr%2F%3EPh%C3%A2n%20lo%E1%BA%A1i%20t%C3%A0u%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20H3%5B%22Is%20Fishing%3Cbr%2F%3EPh%C3%A2n%20lo%E1%BA%A1i%20%C4%91%C3%A1nh%20c%C3%A1%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20H4%5B%22Length%3Cbr%2F%3E%C6%AF%E1%BB%9Bc%20l%C6%B0%E1%BB%A3ng%20chi%E1%BB%81u%20d%C3%A0i%22%5D%0A%20%20%20%20%20%20%20%20end%0A%0A%20%20%20%20%20%20%20%20INPUT%20--%3E%20ENCODER%20--%3E%20DECODER%20--%3E%20HEADS%0A%20%20%20%20end%0A"})]),fallback:n(()=>[...t[1]||(t[1]=[e(" Loading... ",-1)])]),_:1})),t[6]||(t[6]=i('<h3 id="_2-2-đot-pha-output-stride-2" tabindex="-1">2.2 Đột Phá: Output Stride-2 <a class="header-anchor" href="#_2-2-đot-pha-output-stride-2" aria-label="Permalink to &quot;2.2 Đột Phá: Output Stride-2&quot;">​</a></h3><p>Điểm sáng tạo quan trọng nhất của CircleNet là sử dụng output stride-2 thay vì stride-16 như các mô hình thông thường. Với ảnh đầu vào 2048×2048, output stride-2 cho ra feature map 1024×1024, trong khi stride-16 chỉ cho 128×128.</p><table tabindex="0"><thead><tr><th>Output Stride</th><th>Kích thước Feature Map</th><th>Label Encoding F1</th></tr></thead><tbody><tr><td>Stride-16</td><td>128×128</td><td>0.9672</td></tr><tr><td>Stride-8</td><td>256×256</td><td>0.9934</td></tr><tr><td>Stride-4</td><td>512×512</td><td>0.9991</td></tr><tr><td><strong>Stride-2</strong></td><td>1024×1024</td><td><strong>0.9999</strong></td></tr></tbody></table><p>Sự cải thiện 3.3% trong label encoding accuracy từ stride-16 đến stride-2 có vẻ nhỏ nhưng có ý nghĩa quyết định: với tàu chỉ 10 pixels, việc định vị sai 8 pixels (stride-16) có thể khiến hoàn toàn bỏ lỡ đối tượng.</p><h3 id="_2-3-xu-ly-đau-vao-đa-kenh" tabindex="-1">2.3 Xử Lý Đầu Vào Đa Kênh <a class="header-anchor" href="#_2-3-xu-ly-đau-vao-đa-kenh" aria-label="Permalink to &quot;2.3 Xử Lý Đầu Vào Đa Kênh&quot;">​</a></h3><p>Thay vì chỉ sử dụng ảnh SAR thuần túy, giải pháp kết hợp bốn kênh đầu vào:</p><table tabindex="0"><thead><tr><th>Kênh</th><th>Mô tả</th><th>Vai trò</th></tr></thead><tbody><tr><td><strong>VH Polarization</strong></td><td>Vertical-Horizontal</td><td>Phát hiện cấu trúc kim loại</td></tr><tr><td><strong>VV Polarization</strong></td><td>Vertical-Vertical</td><td>Bổ sung thông tin tán xạ</td></tr><tr><td><strong>Bathymetry</strong></td><td>Độ sâu đáy biển</td><td>Loại bỏ false positive từ đáy nông</td></tr><tr><td><strong>Wind Speed</strong></td><td>Tốc độ gió</td><td>Hiệu chỉnh nhiễu sóng biển</td></tr></tbody></table><hr><h2 id="_3-xu-ly-cac-thach-thuc-ky-thuat" tabindex="-1">3. Xử Lý Các Thách Thức Kỹ Thuật <a class="header-anchor" href="#_3-xu-ly-cac-thach-thuc-ky-thuat" aria-label="Permalink to &quot;3. Xử Lý Các Thách Thức Kỹ Thuật&quot;">​</a></h2><h3 id="_3-1-chuan-hoa-sar-bang-sigmoid" tabindex="-1">3.1 Chuẩn Hóa SAR Bằng Sigmoid <a class="header-anchor" href="#_3-1-chuan-hoa-sar-bang-sigmoid" aria-label="Permalink to &quot;3.1 Chuẩn Hóa SAR Bằng Sigmoid&quot;">​</a></h3><p>Dải động cực lớn của ảnh SAR (-50dB đến +20dB) đòi hỏi phương pháp chuẩn hóa đặc biệt. Thay vì linear scaling truyền thống, CircleNet sử dụng Sigmoid normalization:</p>',11)),(h(),r(d,null,{default:n(()=>[o(a,{id:"mermaid-292",class:"mermaid",graph:"flowchart%20LR%0A%20%20%20%20subgraph%20NORM%5B%22Chu%E1%BA%A9n%20H%C3%B3a%20Sigmoid%22%5D%0A%20%20%20%20%20%20%20%20RAW%5B%22Gi%C3%A1%20tr%E1%BB%8B%20SAR%20g%E1%BB%91c%3Cbr%2F%3E-50dB%20%C4%91%E1%BA%BFn%20%2B20dB%22%5D%0A%20%20%20%20%20%20%20%20SHIFT%5B%22D%E1%BB%8Bch%20chuy%E1%BB%83n%3Cbr%2F%3Ex%20%2B%2040%22%5D%0A%20%20%20%20%20%20%20%20SCALE%5B%22Chia%20t%E1%BB%B7%20l%E1%BB%87%3Cbr%2F%3Ex%20%2F%2015%22%5D%0A%20%20%20%20%20%20%20%20SIG%5B%22Sigmoid%3Cbr%2F%3E%CF%83(x)%22%5D%0A%20%20%20%20%20%20%20%20OUT%5B%22Gi%C3%A1%20tr%E1%BB%8B%20chu%E1%BA%A9n%20h%C3%B3a%3Cbr%2F%3E0%20%C4%91%E1%BA%BFn%201%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20RAW%20--%3E%20SHIFT%20--%3E%20SCALE%20--%3E%20SIG%20--%3E%20OUT%0A"})]),fallback:n(()=>[...t[2]||(t[2]=[e(" Loading... ",-1)])]),_:1})),t[7]||(t[7]=i('<p>Ưu điểm của Sigmoid normalization:</p><ul><li>Nén dải động mượt mà</li><li>Robust với outliers (giá trị cực trị không gây vấn đề)</li><li>Tự động tập trung vào vùng tín hiệu quan trọng</li></ul><h3 id="_3-2-xu-ly-nhan-nhieu" tabindex="-1">3.2 Xử Lý Nhãn Nhiễu <a class="header-anchor" href="#_3-2-xu-ly-nhan-nhieu" aria-label="Permalink to &quot;3.2 Xử Lý Nhãn Nhiễu&quot;">​</a></h3><p>Vấn đề nhãn không đầy đủ được giải quyết thông qua hai kỹ thuật:</p><p><strong>Label Smoothing (5%)</strong>: Thay vì dùng nhãn cứng 0/1, sử dụng 0.025/0.975 để giảm overconfidence và tăng khả năng tổng quát hóa.</p><p><strong>Shannon Entropy Regularization</strong>: Với các nhãn &quot;unknown&quot;, thêm một thành phần loss khuyến khích mô hình đưa ra dự đoán xác định (gần 0 hoặc gần 1) thay vì không chắc chắn (gần 0.5). Điều này cho phép mô hình tự học từ dữ liệu không có nhãn.</p><h3 id="_3-3-thiet-ke-multi-head-output" tabindex="-1">3.3 Thiết Kế Multi-Head Output <a class="header-anchor" href="#_3-3-thiet-ke-multi-head-output" aria-label="Permalink to &quot;3.3 Thiết Kế Multi-Head Output&quot;">​</a></h3><p>CircleNet sử dụng bốn heads riêng biệt, mỗi head tối ưu cho một nhiệm vụ:</p>',8)),(h(),r(d,null,{default:n(()=>[o(a,{id:"mermaid-331",class:"mermaid",graph:"flowchart%20TB%0A%20%20%20%20subgraph%20HEADS%5B%22B%E1%BB%91n%20Task%20Heads%22%5D%0A%20%20%20%20%20%20%20%20direction%20LR%0A%0A%20%20%20%20%20%20%20%20subgraph%20H1%5B%22Objectness%20Head%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20H1_DESC%5B%22Ph%C3%A1t%20hi%E1%BB%87n%20t%C3%A0u%3Cbr%2F%3E%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%3Cbr%2F%3EOutput%3A%20Heatmap%3Cbr%2F%3ELoss%3A%20Focal%20Loss%3Cbr%2F%3EM%E1%BB%A5c%20ti%C3%AAu%3A%20%C4%90%E1%BB%8Bnh%20v%E1%BB%8B%22%5D%0A%20%20%20%20%20%20%20%20end%0A%0A%20%20%20%20%20%20%20%20subgraph%20H2%5B%22Vessel%20Head%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20H2_DESC%5B%22Ph%C3%A2n%20lo%E1%BA%A1i%20t%C3%A0u%3Cbr%2F%3E%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%3Cbr%2F%3EOutput%3A%20X%C3%A1c%20su%E1%BA%A5t%3Cbr%2F%3ELoss%3A%20BCE%3Cbr%2F%3EM%E1%BB%A5c%20ti%C3%AAu%3A%20T%C3%A0u%20vs%20kh%C3%B4ng%20t%C3%A0u%22%5D%0A%20%20%20%20%20%20%20%20end%0A%0A%20%20%20%20%20%20%20%20subgraph%20H3%5B%22Fishing%20Head%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20H3_DESC%5B%22Ph%C3%A2n%20lo%E1%BA%A1i%20%C4%91%C3%A1nh%20c%C3%A1%3Cbr%2F%3E%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%3Cbr%2F%3EOutput%3A%20X%C3%A1c%20su%E1%BA%A5t%3Cbr%2F%3ELoss%3A%20BCE%3Cbr%2F%3EM%E1%BB%A5c%20ti%C3%AAu%3A%20Fishing%20vs%20kh%C3%A1c%22%5D%0A%20%20%20%20%20%20%20%20end%0A%0A%20%20%20%20%20%20%20%20subgraph%20H4%5B%22Length%20Head%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20H4_DESC%5B%22%C6%AF%E1%BB%9Bc%20l%C6%B0%E1%BB%A3ng%20chi%E1%BB%81u%20d%C3%A0i%3Cbr%2F%3E%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%3Cbr%2F%3EOutput%3A%20Gi%C3%A1%20tr%E1%BB%8B%3Cbr%2F%3ELoss%3A%20L1%20Loss%3Cbr%2F%3EM%E1%BB%A5c%20ti%C3%AAu%3A%20K%C3%ADch%20th%C6%B0%E1%BB%9Bc%20t%C3%A0u%22%5D%0A%20%20%20%20%20%20%20%20end%0A%20%20%20%20end%0A"})]),fallback:n(()=>[...t[3]||(t[3]=[e(" Loading... ",-1)])]),_:1})),t[8]||(t[8]=i('<p>Việc tách riêng các heads cho phép tối ưu từng nhiệm vụ một cách độc lập, đồng thời chia sẻ biểu diễn đặc trưng chung từ encoder-decoder.</p><hr><h2 id="_4-chien-luoc-ensemble" tabindex="-1">4. Chiến Lược Ensemble <a class="header-anchor" href="#_4-chien-luoc-ensemble" aria-label="Permalink to &quot;4. Chiến Lược Ensemble&quot;">​</a></h2><h3 id="_4-1-đa-dang-backbone" tabindex="-1">4.1 Đa Dạng Backbone <a class="header-anchor" href="#_4-1-đa-dang-backbone" aria-label="Permalink to &quot;4.1 Đa Dạng Backbone&quot;">​</a></h3><p>Giải pháp cuối cùng sử dụng ensemble của 12 mô hình, kết hợp ba loại backbone khác nhau với bốn fold cross-validation:</p><table tabindex="0"><thead><tr><th>Backbone</th><th>Đặc điểm</th><th>Số mô hình</th><th>CV Score</th></tr></thead><tbody><tr><td>EfficientNet-B4</td><td>Nhẹ, nhanh</td><td>4 folds</td><td>0.51-0.52</td></tr><tr><td>EfficientNet-B5</td><td>Cân bằng</td><td>4 folds</td><td>0.53-0.55</td></tr><tr><td>EfficientNet-V2S</td><td>Mạnh nhất</td><td>4 folds</td><td>0.55-0.62</td></tr><tr><td><strong>Ensemble</strong></td><td>Kết hợp</td><td><strong>12 total</strong></td><td><strong>0.617</strong></td></tr></tbody></table><h3 id="_4-2-phuong-phap-ket-hop" tabindex="-1">4.2 Phương Pháp Kết Hợp <a class="header-anchor" href="#_4-2-phuong-phap-ket-hop" aria-label="Permalink to &quot;4.2 Phương Pháp Kết Hợp&quot;">​</a></h3><p>Dự đoán từ 12 mô hình được kết hợp thông qua:</p><ul><li>Trung bình heatmap objectness</li><li>Voting có trọng số cho classification</li><li>Trung bình có trọng số cho length estimation</li></ul><p>Test-Time Augmentation với horizontal flip được áp dụng, mang lại cải thiện 0.5-1% điểm số.</p><hr><h2 id="_5-ket-qua-va-phan-tich" tabindex="-1">5. Kết Quả và Phân Tích <a class="header-anchor" href="#_5-ket-qua-va-phan-tich" aria-label="Permalink to &quot;5. Kết Quả và Phân Tích&quot;">​</a></h2><h3 id="_5-1-đong-gop-tung-thanh-phan" tabindex="-1">5.1 Đóng Góp Từng Thành Phần <a class="header-anchor" href="#_5-1-đong-gop-tung-thanh-phan" aria-label="Permalink to &quot;5.1 Đóng Góp Từng Thành Phần&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Thành phần</th><th>Thay đổi điểm</th></tr></thead><tbody><tr><td>Baseline (stride-16)</td><td>-</td></tr><tr><td>+ Stride-2 output</td><td>+0.04</td></tr><tr><td>+ Label smoothing</td><td>+0.01</td></tr><tr><td>+ Entropy regularization</td><td>+0.01</td></tr><tr><td>+ Sigmoid normalization</td><td>+0.01</td></tr><tr><td>+ 12-model ensemble</td><td>+0.06</td></tr><tr><td><strong>Tổng cải thiện</strong></td><td><strong>+0.13</strong></td></tr></tbody></table><p>Có thể thấy Stride-2 output đóng góp lớn nhất (+0.04), tiếp theo là ensemble (+0.06). Các kỹ thuật xử lý nhãn và chuẩn hóa mỗi cái đóng góp +0.01 nhưng khi kết hợp tạo ra hiệu quả cộng hưởng.</p><h3 id="_5-2-phan-tich-cac-loai-loi" tabindex="-1">5.2 Phân Tích Các Loại Lỗi <a class="header-anchor" href="#_5-2-phan-tich-cac-loai-loi" aria-label="Permalink to &quot;5.2 Phân Tích Các Loại Lỗi&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Loại lỗi</th><th>Tỷ lệ</th><th>Nguyên nhân</th></tr></thead><tbody><tr><td><strong>False Negatives</strong></td><td>40%</td><td>Tàu nhỏ, dark vessels, gần bờ</td></tr><tr><td><strong>False Positives</strong></td><td>30%</td><td>Cơ sở hạ tầng cố định, sóng biển</td></tr><tr><td><strong>Classification errors</strong></td><td>20%</td><td>Khó phân biệt fishing vs non-fishing</td></tr><tr><td><strong>Edge effects</strong></td><td>10%</td><td>Artifacts từ việc chia tile</td></tr></tbody></table><p>False negatives chiếm tỷ lệ cao nhất, đặc biệt với các tàu &quot;tối&quot; - chính xác là mục tiêu quan trọng nhất của cuộc thi. Điều này cho thấy vẫn còn nhiều dư địa cải thiện cho các nghiên cứu tương lai.</p><hr><h2 id="_6-y-nghia-va-bai-hoc" tabindex="-1">6. Ý Nghĩa và Bài Học <a class="header-anchor" href="#_6-y-nghia-va-bai-hoc" aria-label="Permalink to &quot;6. Ý Nghĩa và Bài Học&quot;">​</a></h2><h3 id="_6-1-đong-gop-cho-linh-vuc" tabindex="-1">6.1 Đóng Góp Cho Lĩnh Vực <a class="header-anchor" href="#_6-1-đong-gop-cho-linh-vuc" aria-label="Permalink to &quot;6.1 Đóng Góp Cho Lĩnh Vực&quot;">​</a></h3><p>Giải pháp CircleNet mang lại nhiều đóng góp quan trọng:</p><p><strong>Về phương pháp luận</strong>: Chứng minh hiệu quả của phát hiện dựa trên điểm cho đối tượng nhỏ trong ảnh SAR, mở ra hướng tiếp cận mới cho các bài toán tương tự.</p><p><strong>Về kỹ thuật</strong>: Các kỹ thuật như Sigmoid normalization và Entropy regularization có thể áp dụng rộng rãi cho các bài toán khác với dữ liệu SAR hoặc nhãn không đầy đủ.</p><p><strong>Về ứng dụng</strong>: Mô hình đã được Global Fishing Watch tích hợp để giám sát hoạt động đánh bắt cá trên toàn cầu, góp phần vào nỗ lực chống IUU fishing.</p><h3 id="_6-2-bai-hoc-rut-ra" tabindex="-1">6.2 Bài Học Rút Ra <a class="header-anchor" href="#_6-2-bai-hoc-rut-ra" aria-label="Permalink to &quot;6.2 Bài Học Rút Ra&quot;">​</a></h3><ol><li><p><strong>Độ phân giải output quan trọng</strong>: Với đối tượng nhỏ, stride-2 vượt trội stride-16</p></li><li><p><strong>Xử lý đặc thù dữ liệu</strong>: SAR cần chuẩn hóa khác biệt so với ảnh quang học</p></li><li><p><strong>Làm việc với nhãn nhiễu</strong>: Entropy regularization cho phép học từ dữ liệu không có nhãn</p></li><li><p><strong>Ensemble vẫn hiệu quả</strong>: 12 mô hình đa dạng tạo ra cải thiện đáng kể</p></li></ol><hr><h2 id="_7-yeu-cau-tai-tao" tabindex="-1">7. Yêu Cầu Tái Tạo <a class="header-anchor" href="#_7-yeu-cau-tai-tao" aria-label="Permalink to &quot;7. Yêu Cầu Tái Tạo&quot;">​</a></h2><h3 id="_7-1-phan-cung" tabindex="-1">7.1 Phần Cứng <a class="header-anchor" href="#_7-1-phan-cung" aria-label="Permalink to &quot;7.1 Phần Cứng&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Tài nguyên</th><th>Thông số</th></tr></thead><tbody><tr><td><strong>GPU</strong></td><td>4× RTX 3090 (24GB VRAM mỗi card)</td></tr><tr><td><strong>RAM</strong></td><td>128GB</td></tr><tr><td><strong>Storage</strong></td><td>500GB SSD</td></tr><tr><td><strong>Thời gian huấn luyện</strong></td><td>~25 giờ (4 GPUs)</td></tr></tbody></table><h3 id="_7-2-phan-mem" tabindex="-1">7.2 Phần Mềm <a class="header-anchor" href="#_7-2-phan-mem" aria-label="Permalink to &quot;7.2 Phần Mềm&quot;">​</a></h3><p>Giải pháp sử dụng PyTorch với các thư viện hỗ trợ:</p><ul><li>pytorch-toolbelt (của cùng tác giả)</li><li>segmentation-models-pytorch</li><li>albumentations cho augmentation</li></ul><hr><h2 id="tai-lieu-tham-khao" tabindex="-1">Tài Liệu Tham Khảo <a class="header-anchor" href="#tai-lieu-tham-khao" aria-label="Permalink to &quot;Tài Liệu Tham Khảo&quot;">​</a></h2><ol><li><p>Zhou, X., Wang, D., &amp; Krähenbühl, P. (2019). Objects as Points. arXiv:1904.07850.</p></li><li><p>Tan, M., &amp; Le, Q. (2019). EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. ICML.</p></li><li><p>Ronneberger, O., Fischer, P., &amp; Brox, T. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation. MICCAI.</p></li><li><p>Paolo, F. S., et al. (2022). xView3-SAR: Detecting Dark Fishing Activity Using Synthetic Aperture Radar Imagery. NeurIPS 2022 Datasets and Benchmarks Track.</p></li><li><p>Khvedchenya, E. (2022). xView3 First Place Solution. GitHub Repository.</p></li></ol><hr><p><em>Phần tiếp theo sẽ trình bày giải pháp hạng nhì của cuộc thi, với những đóng góp về Multi-Scale Feature Fusion và Attention Mechanisms.</em></p>',39))])}const k=c(u,[["render",s]]);export{C as __pageData,k as default};
