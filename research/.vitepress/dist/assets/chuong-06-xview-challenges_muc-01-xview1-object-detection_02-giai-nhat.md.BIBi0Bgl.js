import{_ as d,C as g,c as l,o as h,a2 as a,b as e,w as n,a as r,G as o,a3 as c}from"./chunks/framework.nRfFlDZQ.js";const C=JSON.parse('{"title":"6.1.2 Giải Pháp Hạng Nhất xView1: Reduced Focal Loss","description":"","frontmatter":{},"headers":[],"relativePath":"chuong-06-xview-challenges/muc-01-xview1-object-detection/02-giai-nhat.md","filePath":"chuong-06-xview-challenges/muc-01-xview1-object-detection/02-giai-nhat.md","lastUpdated":1766163869000}'),s={name:"chuong-06-xview-challenges/muc-01-xview1-object-detection/02-giai-nhat.md"};function u(B,t,m,p,A,b){const i=g("Mermaid");return h(),l("div",null,[t[4]||(t[4]=a('<h1 id="_6-1-2-giai-phap-hang-nhat-xview1-reduced-focal-loss" tabindex="-1">6.1.2 Giải Pháp Hạng Nhất xView1: Reduced Focal Loss <a class="header-anchor" href="#_6-1-2-giai-phap-hang-nhat-xview1-reduced-focal-loss" aria-label="Permalink to &quot;6.1.2 Giải Pháp Hạng Nhất xView1: Reduced Focal Loss&quot;">​</a></h1><h2 id="tong-quan-giai-phap" tabindex="-1">Tổng Quan Giải Pháp <a class="header-anchor" href="#tong-quan-giai-phap" aria-label="Permalink to &quot;Tổng Quan Giải Pháp&quot;">​</a></h2><p>Giải pháp đạt hạng nhất trong cuộc thi xView1 Detection Challenge 2018 được phát triển bởi Nikolay Sergievskiy và Alexander Ponamarev, hai nhà nghiên cứu độc lập đến từ Nga. Với điểm mAP 31.74 trên public leaderboard và 29.32 trên private leaderboard, giải pháp này vượt trội hơn 111% so với baseline do ban tổ chức cung cấp, đánh dấu một bước tiến đáng kể trong lĩnh vực phát hiện đối tượng từ ảnh viễn thám.</p><table tabindex="0"><thead><tr><th>Thuộc tính</th><th>Giá trị</th></tr></thead><tbody><tr><td><strong>Xếp hạng</strong></td><td>1/2,300+ bài nộp</td></tr><tr><td><strong>Tác giả</strong></td><td>Nikolay Sergievskiy, Alexander Ponamarev</td></tr><tr><td><strong>Điểm mAP</strong></td><td>31.74 (public) / 29.32 (private)</td></tr><tr><td><strong>Đóng góp chính</strong></td><td>Reduced Focal Loss</td></tr><tr><td><strong>Bài báo</strong></td><td>arXiv:1903.01347</td></tr></tbody></table><hr><h2 id="_1-boi-canh-va-van-đe-can-giai-quyet" tabindex="-1">1. Bối Cảnh và Vấn Đề Cần Giải Quyết <a class="header-anchor" href="#_1-boi-canh-va-van-đe-can-giai-quyet" aria-label="Permalink to &quot;1. Bối Cảnh và Vấn Đề Cần Giải Quyết&quot;">​</a></h2><h3 id="_1-1-thach-thuc-mat-can-bang-lop-cuc-đo" tabindex="-1">1.1 Thách Thức Mất Cân Bằng Lớp Cực Độ <a class="header-anchor" href="#_1-1-thach-thuc-mat-can-bang-lop-cuc-đo" aria-label="Permalink to &quot;1.1 Thách Thức Mất Cân Bằng Lớp Cực Độ&quot;">​</a></h3><p>Bộ dữ liệu xView1 chứa hơn một triệu đối tượng được gán nhãn, nhưng sự phân bố giữa các lớp cực kỳ không đồng đều. Hai lớp phổ biến nhất - xe ô tô nhỏ và công trình - chiếm tới 60% tổng số mẫu, trong khi các lớp hiếm như đầu máy tàu hỏa chỉ có vài trăm mẫu. Tỷ lệ chênh lệch giữa lớp lớn nhất và nhỏ nhất lên tới 3000:1.</p><p>Sự mất cân bằng này tạo ra một thách thức nghiêm trọng cho việc huấn luyện mô hình: các gradient từ lớp phổ biến thống trị quá trình học, khiến mô hình hầu như không học được gì về các lớp hiếm. Khi metric đánh giá là trung bình AP của tất cả các lớp với trọng số bằng nhau, hiệu suất kém trên các lớp hiếm sẽ kéo điểm tổng thể xuống đáng kể.</p><h3 id="_1-2-nghich-ly-focal-loss-trong-mang-đe-xuat-vung" tabindex="-1">1.2 Nghịch Lý Focal Loss Trong Mạng Đề Xuất Vùng <a class="header-anchor" href="#_1-2-nghich-ly-focal-loss-trong-mang-đe-xuat-vung" aria-label="Permalink to &quot;1.2 Nghịch Lý Focal Loss Trong Mạng Đề Xuất Vùng&quot;">​</a></h3><p>Focal Loss, được Lin và cộng sự đề xuất năm 2017, là một giải pháp phổ biến cho vấn đề mất cân bằng lớp. Ý tưởng cốt lõi của Focal Loss là giảm trọng số của các mẫu dễ phân loại để mô hình tập trung vào các mẫu khó.</p><p>Tuy nhiên, nhóm tác giả phát hiện một nghịch lý thú vị: khi áp dụng Focal Loss cho Mạng Đề Xuất Vùng (Region Proposal Network - RPN) trong kiến trúc Faster R-CNN, thay vì cải thiện, hiệu suất lại giảm đáng kể.</p>',12)),(h(),e(c,null,{default:n(()=>[o(i,{id:"mermaid-85",class:"mermaid",graph:"flowchart%20TB%0A%20%20%20%20subgraph%20PROBLEM%5B%22Ngh%E1%BB%8Bch%20L%C3%BD%20Focal%20Loss%20trong%20RPN%22%5D%0A%20%20%20%20%20%20%20%20direction%20TB%0A%20%20%20%20%20%20%20%20FL%5B%22Focal%20Loss%20gi%E1%BA%A3m%20tr%E1%BB%8Dng%20s%E1%BB%91%3Cbr%2F%3Ec%C3%A1c%20m%E1%BA%ABu%20d%E1%BB%85%20ph%C3%A2n%20lo%E1%BA%A1i%22%5D%0A%0A%20%20%20%20%20%20%20%20EFFECT%5B%22M%E1%BA%ABu%20%C3%A2m%20%E1%BB%9F%20v%C3%B9ng%20bi%C3%AAn%20%C4%91%E1%BB%91i%20t%C6%B0%E1%BB%A3ng%3Cbr%2F%3Eb%E1%BB%8B%20coi%20l%C3%A0%20'd%E1%BB%85'%20v%C3%A0%20b%E1%BB%8B%20gi%E1%BA%A3m%20tr%E1%BB%8Dng%20s%E1%BB%91%22%5D%0A%0A%20%20%20%20%20%20%20%20RESULT%5B%22RPN%20tr%C3%A1nh%20v%C3%B9ng%20bi%C3%AAn%3Cbr%2F%3E%E2%86%92%20Proposals%20kh%C3%B4ng%20bao%20ph%E1%BB%A7%20%C4%91%E1%BA%A7y%20%C4%91%E1%BB%A7%3Cbr%2F%3E%E2%86%92%20Recall%20gi%E1%BA%A3m%20t%E1%BB%AB%2095%25%20xu%E1%BB%91ng%2085%25%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20FL%20--%3E%20EFFECT%20--%3E%20RESULT%0A"})]),fallback:n(()=>[...t[0]||(t[0]=[r(" Loading... ",-1)])]),_:1})),t[5]||(t[5]=a('<p>Nguyên nhân của hiện tượng này nằm ở vai trò đặc biệt của RPN trong kiến trúc hai giai đoạn. RPN có nhiệm vụ tạo ra các vùng đề xuất chất lượng cao để gửi cho bộ phân loại ở giai đoạn sau. Khi Focal Loss giảm trọng số các mẫu âm dễ phân loại, nó vô tình cũng giảm trọng số các mẫu âm quan trọng ở vùng biên của đối tượng - chính xác là những vùng mà RPN cần học để tạo proposals chính xác.</p><hr><h2 id="_2-đoi-moi-ky-thuat-reduced-focal-loss" tabindex="-1">2. Đổi Mới Kỹ Thuật: Reduced Focal Loss <a class="header-anchor" href="#_2-đoi-moi-ky-thuat-reduced-focal-loss" aria-label="Permalink to &quot;2. Đổi Mới Kỹ Thuật: Reduced Focal Loss&quot;">​</a></h2><h3 id="_2-1-y-tuong-cot-loi" tabindex="-1">2.1 Ý Tưởng Cốt Lõi <a class="header-anchor" href="#_2-1-y-tuong-cot-loi" aria-label="Permalink to &quot;2.1 Ý Tưởng Cốt Lõi&quot;">​</a></h3><p>Để giải quyết nghịch lý trên, Sergievskiy và Ponamarev đề xuất Reduced Focal Loss - một biến thể của Focal Loss với cơ chế trọng số thích ứng dựa trên ngưỡng xác suất.</p><p>Ý tưởng chính là chia không gian xác suất thành hai vùng:</p><ul><li><strong>Dưới ngưỡng</strong> (mặc định 0.5): Sử dụng cross-entropy tiêu chuẩn với trọng số đầy đủ</li><li><strong>Trên ngưỡng</strong>: Áp dụng trọng số focal đã được điều chỉnh</li></ul>',7)),(h(),e(c,null,{default:n(()=>[o(i,{id:"mermaid-114",class:"mermaid",graph:"flowchart%20LR%0A%20%20%20%20subgraph%20RFL%5B%22Reduced%20Focal%20Loss%22%5D%0A%20%20%20%20%20%20%20%20direction%20TB%0A%0A%20%20%20%20%20%20%20%20subgraph%20BELOW%5B%22p_t%20nh%E1%BB%8F%20h%C6%A1n%20threshold%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20B_DESC%5B%22M%E1%BA%ABu%20kh%C3%B3%3Cbr%2F%3E%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%3Cbr%2F%3EGradient%20%C4%91%E1%BA%A7y%20%C4%91%E1%BB%A7%3Cbr%2F%3E%C4%90%E1%BA%A3m%20b%E1%BA%A3o%20RPN%20h%E1%BB%8Dc%3Cbr%2F%3Eph%C3%A1t%20hi%E1%BB%87n%20v%C3%B9ng%20bi%C3%AAn%22%5D%0A%20%20%20%20%20%20%20%20end%0A%0A%20%20%20%20%20%20%20%20subgraph%20ABOVE%5B%22p_t%20l%E1%BB%9Bn%20h%C6%A1n%20ho%E1%BA%B7c%20b%E1%BA%B1ng%20threshold%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20A_DESC%5B%22M%E1%BA%ABu%20d%E1%BB%85%3Cbr%2F%3E%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%3Cbr%2F%3EGradient%20gi%E1%BA%A3m%3Cbr%2F%3EX%E1%BB%AD%20l%C3%BD%20m%E1%BA%A5t%20c%C3%A2n%20b%E1%BA%B1ng%3Cbr%2F%3Enh%C6%B0%20Focal%20Loss%22%5D%0A%20%20%20%20%20%20%20%20end%0A%20%20%20%20end%0A"})]),fallback:n(()=>[...t[1]||(t[1]=[r(" Loading... ",-1)])]),_:1})),t[6]||(t[6]=a('<h3 id="_2-2-so-sanh-cac-ham-mat-mat" tabindex="-1">2.2 So Sánh Các Hàm Mất Mát <a class="header-anchor" href="#_2-2-so-sanh-cac-ham-mat-mat" aria-label="Permalink to &quot;2.2 So Sánh Các Hàm Mất Mát&quot;">​</a></h3><p>Bảng so sánh đặc tính của ba hàm mất mát:</p><table tabindex="0"><thead><tr><th>Hàm mất mát</th><th>Đặc điểm</th><th>Ưu điểm</th><th>Nhược điểm</th></tr></thead><tbody><tr><td><strong>Cross-Entropy</strong></td><td>Gradient đều cho mọi mẫu</td><td>Học đầy đủ mọi vùng</td><td>Không xử lý mất cân bằng</td></tr><tr><td><strong>Focal Loss</strong></td><td>Giảm gradient mẫu dễ</td><td>Tập trung mẫu khó</td><td>Có thể bỏ qua mẫu quan trọng ở biên</td></tr><tr><td><strong>Reduced Focal Loss</strong></td><td>Ngưỡng phân vùng</td><td>Kết hợp ưu điểm cả hai</td><td>Thêm hyperparameter (threshold)</td></tr></tbody></table><h3 id="_2-3-ket-qua-thuc-nghiem" tabindex="-1">2.3 Kết Quả Thực Nghiệm <a class="header-anchor" href="#_2-3-ket-qua-thuc-nghiem" aria-label="Permalink to &quot;2.3 Kết Quả Thực Nghiệm&quot;">​</a></h3><p>Bảng so sánh hiệu suất của các hàm mất mát trên xView1:</p><table tabindex="0"><thead><tr><th>Hàm mất mát</th><th>Recall RPN @1000</th><th>mAP cuối</th></tr></thead><tbody><tr><td>Cross-Entropy tiêu chuẩn</td><td>94.2%</td><td>24.1</td></tr><tr><td>Focal Loss (γ=2)</td><td>86.5%</td><td>22.8</td></tr><tr><td><strong>Reduced Focal Loss</strong></td><td><strong>93.8%</strong></td><td><strong>28.5</strong></td></tr></tbody></table><p>Reduced Focal Loss gần như khôi phục lại recall của RPN (93.8% so với 94.2%) trong khi vẫn đạt được lợi ích của việc xử lý mất cân bằng lớp, dẫn đến cải thiện +4.4 mAP so với baseline.</p><hr><h2 id="_3-kien-truc-mo-hinh" tabindex="-1">3. Kiến Trúc Mô Hình <a class="header-anchor" href="#_3-kien-truc-mo-hinh" aria-label="Permalink to &quot;3. Kiến Trúc Mô Hình&quot;">​</a></h2><h3 id="_3-1-tong-quan-kien-truc" tabindex="-1">3.1 Tổng Quan Kiến Trúc <a class="header-anchor" href="#_3-1-tong-quan-kien-truc" aria-label="Permalink to &quot;3.1 Tổng Quan Kiến Trúc&quot;">​</a></h3><p>Giải pháp sử dụng kiến trúc Faster R-CNN với Feature Pyramid Network (FPN), một lựa chọn phổ biến cho các bài toán phát hiện đối tượng đa tỷ lệ.</p>',11)),(h(),e(c,null,{default:n(()=>[o(i,{id:"mermaid-252",class:"mermaid",graph:"flowchart%20TB%0A%20%20%20%20subgraph%20INPUT%5B%22%C4%90%E1%BA%A7u%20v%C3%A0o%22%5D%0A%20%20%20%20%20%20%20%20IMG%5B%22%E1%BA%A2nh%20v%E1%BB%87%20tinh%3Cbr%2F%3E700%C3%97700%20pixels%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20BACKBONE%5B%22X%C6%B0%C6%A1ng%20s%E1%BB%91ng%3A%20ResNet-50%2F101%22%5D%0A%20%20%20%20%20%20%20%20C2%5B%22Stage%202%3Cbr%2F%3E256%20k%C3%AAnh%3Cbr%2F%3E1%2F4%20k%C3%ADch%20th%C6%B0%E1%BB%9Bc%22%5D%0A%20%20%20%20%20%20%20%20C3%5B%22Stage%203%3Cbr%2F%3E512%20k%C3%AAnh%3Cbr%2F%3E1%2F8%20k%C3%ADch%20th%C6%B0%E1%BB%9Bc%22%5D%0A%20%20%20%20%20%20%20%20C4%5B%22Stage%204%3Cbr%2F%3E1024%20k%C3%AAnh%3Cbr%2F%3E1%2F16%20k%C3%ADch%20th%C6%B0%E1%BB%9Bc%22%5D%0A%20%20%20%20%20%20%20%20C5%5B%22Stage%205%3Cbr%2F%3E2048%20k%C3%AAnh%3Cbr%2F%3E1%2F32%20k%C3%ADch%20th%C6%B0%E1%BB%9Bc%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20FPN%5B%22M%E1%BA%A1ng%20Kim%20T%E1%BB%B1%20Th%C3%A1p%20%C4%90%E1%BA%B7c%20Tr%C6%B0ng%22%5D%0A%20%20%20%20%20%20%20%20P2%5B%22P2%3A%20256%20k%C3%AAnh%3Cbr%2F%3E%C4%90%E1%BB%91i%20t%C6%B0%E1%BB%A3ng%20nh%E1%BB%8F%22%5D%0A%20%20%20%20%20%20%20%20P3%5B%22P3%3A%20256%20k%C3%AAnh%22%5D%0A%20%20%20%20%20%20%20%20P4%5B%22P4%3A%20256%20k%C3%AAnh%22%5D%0A%20%20%20%20%20%20%20%20P5%5B%22P5%3A%20256%20k%C3%AAnh%3Cbr%2F%3E%C4%90%E1%BB%91i%20t%C6%B0%E1%BB%A3ng%20l%E1%BB%9Bn%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20RPN%5B%22M%E1%BA%A1ng%20%C4%90%E1%BB%81%20Xu%E1%BA%A5t%20V%C3%B9ng%22%5D%0A%20%20%20%20%20%20%20%20ANCHORS%5B%229%20anchors%2Fv%E1%BB%8B%20tr%C3%AD%3Cbr%2F%3E3%20t%E1%BB%B7%20l%E1%BB%87%20%C3%97%203%20k%C3%ADch%20th%C6%B0%E1%BB%9Bc%22%5D%0A%20%20%20%20%20%20%20%20PROPOSALS%5B%22Top-1000%20proposals%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20HEAD%5B%22%C4%90%E1%BA%A7u%20Ph%C3%A2n%20Lo%E1%BA%A1i%22%5D%0A%20%20%20%20%20%20%20%20ROIALIGN%5B%22RoI%20Align%22%5D%0A%20%20%20%20%20%20%20%20FC%5B%222%20l%E1%BB%9Bp%20FC%201024%22%5D%0A%20%20%20%20%20%20%20%20OUTPUT%5B%22Ph%C3%A2n%20lo%E1%BA%A1i%3A%2061%20l%E1%BB%9Bp%3Cbr%2F%3EH%E1%BB%93i%20quy%3A%20244%20t%E1%BB%8Da%20%C4%91%E1%BB%99%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20IMG%20--%3E%20BACKBONE%0A%20%20%20%20C2%20--%3E%20P2%0A%20%20%20%20C3%20--%3E%20P3%0A%20%20%20%20C4%20--%3E%20P4%0A%20%20%20%20C5%20--%3E%20P5%0A%0A%20%20%20%20FPN%20--%3E%20RPN%20--%3E%20HEAD%0A"})]),fallback:n(()=>[...t[2]||(t[2]=[r(" Loading... ",-1)])]),_:1})),t[7]||(t[7]=a('<h3 id="_3-2-chien-luoc-xu-ly-anh-lon" tabindex="-1">3.2 Chiến Lược Xử Lý Ảnh Lớn <a class="header-anchor" href="#_3-2-chien-luoc-xu-ly-anh-lon" aria-label="Permalink to &quot;3.2 Chiến Lược Xử Lý Ảnh Lớn&quot;">​</a></h3><p>Ảnh xView1 có kích thước rất lớn (trung bình 3,000 × 3,000 pixels), vượt quá khả năng xử lý trực tiếp của GPU. Giải pháp sử dụng chiến lược chia nhỏ (tiling) với các tham số được tối ưu cẩn thận:</p><table tabindex="0"><thead><tr><th>Tham số</th><th>Giá trị</th><th>Ý nghĩa</th></tr></thead><tbody><tr><td>Kích thước tile</td><td>700 × 700</td><td>Cân bằng giữa ngữ cảnh và bộ nhớ</td></tr><tr><td>Độ chồng lấp</td><td>80 pixels</td><td>Tránh cắt ngang đối tượng</td></tr><tr><td>Tổng số crops</td><td>~63,000</td><td>Sau khi xoay và augmentation</td></tr></tbody></table><h3 id="_3-3-chien-luoc-ensemble" tabindex="-1">3.3 Chiến Lược Ensemble <a class="header-anchor" href="#_3-3-chien-luoc-ensemble" aria-label="Permalink to &quot;3.3 Chiến Lược Ensemble&quot;">​</a></h3><p>Giải pháp cuối cùng sử dụng ensemble của 7 mô hình với các cấu hình khác nhau:</p><table tabindex="0"><thead><tr><th>Mô hình</th><th>Backbone</th><th>Kích thước crop</th><th>mAP đơn</th></tr></thead><tbody><tr><td>M1</td><td>ResNet-50</td><td>700×700</td><td>28.5</td></tr><tr><td>M2</td><td>ResNet-50</td><td>800×800</td><td>29.1</td></tr><tr><td>M3</td><td>ResNet-101</td><td>700×700</td><td>29.8</td></tr><tr><td>M4</td><td>ResNeXt-101</td><td>700×700</td><td>30.2</td></tr><tr><td>M5</td><td>ResNet-50</td><td>600×600</td><td>27.8</td></tr><tr><td>M6</td><td>ResNet-101</td><td>800×800</td><td>30.0</td></tr><tr><td>M7</td><td>ResNeXt-101</td><td>800×800</td><td>30.5</td></tr><tr><td><strong>Ensemble</strong></td><td>-</td><td>-</td><td><strong>31.74</strong></td></tr></tbody></table><p>Việc sử dụng ensemble đa dạng về cả backbone (ResNet-50, ResNet-101, ResNeXt-101) và kích thước đầu vào (600, 700, 800) giúp mô hình bao phủ được nhiều tỷ lệ đối tượng khác nhau và giảm thiểu overfitting.</p><hr><h2 id="_4-cac-ky-thuat-bo-sung" tabindex="-1">4. Các Kỹ Thuật Bổ Sung <a class="header-anchor" href="#_4-cac-ky-thuat-bo-sung" aria-label="Permalink to &quot;4. Các Kỹ Thuật Bổ Sung&quot;">​</a></h2><h3 id="_4-1-lay-mau-can-bang-lop" tabindex="-1">4.1 Lấy Mẫu Cân Bằng Lớp <a class="header-anchor" href="#_4-1-lay-mau-can-bang-lop" aria-label="Permalink to &quot;4.1 Lấy Mẫu Cân Bằng Lớp&quot;">​</a></h3><p>Ngoài Reduced Focal Loss, giải pháp còn áp dụng kỹ thuật undersampling cho các lớp phổ biến:</p><ul><li><strong>Lớp mục tiêu</strong>: Xe ô tô nhỏ, Công trình</li><li><strong>Xác suất loại bỏ</strong>: 50%</li><li><strong>Hiệu quả</strong>: Cải thiện mAP cho lớp hiếm từ ~5% lên ~18%</li></ul><h3 id="_4-2-augmentation-đa-dang" tabindex="-1">4.2 Augmentation Đa Dạng <a class="header-anchor" href="#_4-2-augmentation-đa-dang" aria-label="Permalink to &quot;4.2 Augmentation Đa Dạng&quot;">​</a></h3><p>Chiến lược augmentation được thiết kế phù hợp với đặc thù ảnh viễn thám:</p>',14)),(h(),e(c,null,{default:n(()=>[o(i,{id:"mermaid-483",class:"mermaid",graph:"mindmap%0A%20%20root((Augmentation))%0A%20%20%20%20Kh%C3%B4ng%20gian%0A%20%20%20%20%20%20Xoay%2090%C2%B0%2F180%C2%B0%2F270%C2%B0%0A%20%20%20%20%20%20L%E1%BA%ADt%20ngang%0A%20%20%20%20%20%20L%E1%BA%ADt%20d%E1%BB%8Dc%0A%20%20%20%20Quang%20h%E1%BB%8Dc%0A%20%20%20%20%20%20%C4%90i%E1%BB%81u%20ch%E1%BB%89nh%20%C4%91%E1%BB%99%20s%C3%A1ng%20%C2%B120%25%0A%20%20%20%20%20%20%C4%90i%E1%BB%81u%20ch%E1%BB%89nh%20t%C6%B0%C6%A1ng%20ph%E1%BA%A3n%20%C2%B120%25%0A%20%20%20%20%20%20%C4%90i%E1%BB%81u%20ch%E1%BB%89nh%20%C4%91%E1%BB%99%20b%C3%A3o%20h%C3%B2a%20%C2%B120%25%0A%20%20%20%20T%E1%BB%B7%20l%E1%BB%87%0A%20%20%20%20%20%20Scale%20jittering%20%C2%B130%25%0A%20%20%20%20%20%20Multi-scale%20training%0A"})]),fallback:n(()=>[...t[3]||(t[3]=[r(" Loading... ",-1)])]),_:1})),t[8]||(t[8]=a('<h3 id="_4-3-quy-trinh-huan-luyen-hai-giai-đoan" tabindex="-1">4.3 Quy Trình Huấn Luyện Hai Giai Đoạn <a class="header-anchor" href="#_4-3-quy-trinh-huan-luyen-hai-giai-đoan" aria-label="Permalink to &quot;4.3 Quy Trình Huấn Luyện Hai Giai Đoạn&quot;">​</a></h3><p><strong>Giai đoạn 1</strong> (200K iterations): Huấn luyện cơ bản với learning rate 0.005</p><p><strong>Giai đoạn 2</strong> (100K iterations): Tinh chỉnh với learning rate giảm 10 lần và bật undersampling</p><hr><h2 id="_5-phan-tich-ket-qua" tabindex="-1">5. Phân Tích Kết Quả <a class="header-anchor" href="#_5-phan-tich-ket-qua" aria-label="Permalink to &quot;5. Phân Tích Kết Quả&quot;">​</a></h2><h3 id="_5-1-đong-gop-cua-tung-thanh-phan" tabindex="-1">5.1 Đóng Góp Của Từng Thành Phần <a class="header-anchor" href="#_5-1-đong-gop-cua-tung-thanh-phan" aria-label="Permalink to &quot;5.1 Đóng Góp Của Từng Thành Phần&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Cấu hình</th><th>mAP</th><th>Thay đổi</th></tr></thead><tbody><tr><td>Baseline (Cross-Entropy)</td><td>24.1</td><td>-</td></tr><tr><td>+ Focal Loss (γ=2)</td><td>22.8</td><td>-1.3</td></tr><tr><td>+ Reduced Focal Loss</td><td>28.5</td><td>+4.4</td></tr><tr><td>+ Undersampling</td><td>29.8</td><td>+1.3</td></tr><tr><td>+ Ensemble (7 mô hình)</td><td>31.74</td><td>+1.94</td></tr></tbody></table><p>Phát hiện quan trọng: Focal Loss tiêu chuẩn thực sự <em>làm giảm</em> hiệu suất (-1.3 mAP), trong khi Reduced Focal Loss đem lại cải thiện đáng kể (+4.4 mAP).</p><h3 id="_5-2-hieu-suat-theo-danh-muc-đoi-tuong" tabindex="-1">5.2 Hiệu Suất Theo Danh Mục Đối Tượng <a class="header-anchor" href="#_5-2-hieu-suat-theo-danh-muc-đoi-tuong" aria-label="Permalink to &quot;5.2 Hiệu Suất Theo Danh Mục Đối Tượng&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Danh mục</th><th>mAP</th><th>Nhận xét</th></tr></thead><tbody><tr><td>Máy bay</td><td>~45</td><td>Hình dạng rõ ràng, tương phản cao</td></tr><tr><td>Tàu thuyền</td><td>~40</td><td>Tương phản tốt với nền nước</td></tr><tr><td>Xe lớn</td><td>~30</td><td>Đa dạng về hình dạng</td></tr><tr><td>Xe nhỏ</td><td>~25</td><td>Thách thức về kích thước</td></tr><tr><td>Công trình</td><td>~28</td><td>Đa dạng kiến trúc</td></tr><tr><td>Đầu máy tàu</td><td>~12</td><td>Lớp rất hiếm</td></tr></tbody></table><p>Có thể thấy các đối tượng có hình dạng đặc trưng và tương phản cao (máy bay, tàu thuyền) đạt hiệu suất cao nhất, trong khi các lớp hiếm vẫn còn khó khăn dù đã được cải thiện đáng kể.</p><hr><h2 id="_6-y-nghia-va-tac-đong" tabindex="-1">6. Ý Nghĩa và Tác Động <a class="header-anchor" href="#_6-y-nghia-va-tac-đong" aria-label="Permalink to &quot;6. Ý Nghĩa và Tác Động&quot;">​</a></h2><h3 id="_6-1-đong-gop-cho-cong-đong-nghien-cuu" tabindex="-1">6.1 Đóng Góp Cho Cộng Đồng Nghiên Cứu <a class="header-anchor" href="#_6-1-đong-gop-cho-cong-đong-nghien-cuu" aria-label="Permalink to &quot;6.1 Đóng Góp Cho Cộng Đồng Nghiên Cứu&quot;">​</a></h3><p>Reduced Focal Loss đã trở thành một kỹ thuật được tham khảo rộng rãi trong cộng đồng nghiên cứu phát hiện đối tượng. Ý tưởng về việc duy trì gradient đầy đủ cho các mẫu khó trong khi vẫn xử lý mất cân bằng lớp đã mở ra hướng nghiên cứu mới về thiết kế hàm mất mát thích ứng.</p><h3 id="_6-2-bai-hoc-rut-ra" tabindex="-1">6.2 Bài Học Rút Ra <a class="header-anchor" href="#_6-2-bai-hoc-rut-ra" aria-label="Permalink to &quot;6.2 Bài Học Rút Ra&quot;">​</a></h3><ol><li><p><strong>Không áp dụng máy móc</strong>: Focal Loss hiệu quả cho detector một giai đoạn nhưng có thể gây hại cho detector hai giai đoạn</p></li><li><p><strong>Hiểu vai trò của mỗi thành phần</strong>: RPN và classifier head có mục tiêu khác nhau, cần hàm mất mát phù hợp</p></li><li><p><strong>Kết hợp nhiều kỹ thuật</strong>: Reduced Focal Loss + undersampling + ensemble tạo hiệu quả cộng hưởng</p></li><li><p><strong>Đa dạng ensemble</strong>: Sử dụng nhiều backbone và kích thước khác nhau giúp bao phủ đa tỷ lệ</p></li></ol><hr><h2 id="tai-lieu-tham-khao" tabindex="-1">Tài Liệu Tham Khảo <a class="header-anchor" href="#tai-lieu-tham-khao" aria-label="Permalink to &quot;Tài Liệu Tham Khảo&quot;">​</a></h2><ol><li><p>Sergievskiy, N., &amp; Ponamarev, A. (2019). Reduced Focal Loss: 1st Place Solution to xView object detection in Satellite Imagery. arXiv:1903.01347.</p></li><li><p>Lin, T. Y., Goyal, P., Girshick, R., He, K., &amp; Dollár, P. (2017). Focal Loss for Dense Object Detection. IEEE ICCV.</p></li><li><p>Lin, T. Y., Dollár, P., Girshick, R., He, K., Hariharan, B., &amp; Belongie, S. (2017). Feature Pyramid Networks for Object Detection. IEEE CVPR.</p></li></ol><hr><p><em>Mục tiếp theo sẽ trình bày giải pháp hạng nhì của cuộc thi, với những đóng góp về Domain Adversarial Training và Feature Enhancement.</em></p>',22))])}const k=d(s,[["render",u]]);export{C as __pageData,k as default};
