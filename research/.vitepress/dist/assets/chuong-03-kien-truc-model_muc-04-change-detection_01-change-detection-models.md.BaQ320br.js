import{_ as Q,C as T,c as s,o,a2 as a,b as l,j as t,w as i,a as n,G as d,a3 as h}from"./chunks/framework.nRfFlDZQ.js";const _=JSON.parse('{"title":"Mục 3.4: Change Detection Models cho Phát Hiện Thay Đổi","description":"","frontmatter":{},"headers":[],"relativePath":"chuong-03-kien-truc-model/muc-04-change-detection/01-change-detection-models.md","filePath":"chuong-03-kien-truc-model/muc-04-change-detection/01-change-detection-models.md","lastUpdated":1766302189000}'),c={name:"chuong-03-kien-truc-model/muc-04-change-detection/01-change-detection-models.md"},m={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},g={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.439ex"},xmlns:"http://www.w3.org/2000/svg",width:"23.194ex",height:"2.034ex",role:"img",focusable:"false",viewBox:"0 -705 10251.9 899","aria-hidden":"true"},p={tabindex:"0"},u={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},f={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.912ex"},xmlns:"http://www.w3.org/2000/svg",width:"5.101ex",height:"2.896ex",role:"img",focusable:"false",viewBox:"0 -877 2254.4 1279.9","aria-hidden":"true"},b={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},k={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.912ex"},xmlns:"http://www.w3.org/2000/svg",width:"10.831ex",height:"2.896ex",role:"img",focusable:"false",viewBox:"0 -877 4787.3 1279.9","aria-hidden":"true"};function A(C,e,D,x,S,y){const r=T("Mermaid");return o(),s("div",null,[e[21]||(e[21]=a('<h1 id="muc-3-4-change-detection-models-cho-phat-hien-thay-đoi" tabindex="-1">Mục 3.4: Change Detection Models cho Phát Hiện Thay Đổi <a class="header-anchor" href="#muc-3-4-change-detection-models-cho-phat-hien-thay-đoi" aria-label="Permalink to &quot;Mục 3.4: Change Detection Models cho Phát Hiện Thay Đổi&quot;">​</a></h1><h2 id="_3-4-1-gioi-thieu" tabindex="-1">3.4.1. Giới Thiệu <a class="header-anchor" href="#_3-4-1-gioi-thieu" aria-label="Permalink to &quot;3.4.1. Giới Thiệu&quot;">​</a></h2><p>Sau khi nghiên cứu classification (<strong>Mục 3.2</strong>) và segmentation (<strong>Mục 3.3</strong>) cho ảnh đơn lẻ, phần này chuyển sang một ứng dụng đặc trưng của viễn thám: Change Detection - xác định và phân tích những thay đổi trên bề mặt Trái Đất qua thời gian. Khác với classification và segmentation chỉ phân tích ảnh đơn lẻ, change detection đòi hỏi so sánh ảnh từ nhiều thời điểm (bi-temporal hoặc multi-temporal) để xác định vùng nào đã thay đổi và trong một số trường hợp, thay đổi như thế nào.</p><p>Các ứng dụng của change detection trải rộng từ giám sát mở rộng đô thị, theo dõi phá rừng, đánh giá thiệt hại sau thiên tai, đến giám sát biến động nông nghiệp và xói mòn bờ biển. Điểm chung của các ứng dụng này là nhu cầu phát hiện nhanh và chính xác những biến đổi có ý nghĩa trong môi trường, trong khi loại bỏ những thay đổi giả do sự khác biệt về điều kiện chụp ảnh (góc mặt trời, khí quyển, mùa).</p><p>TorchGeo hỗ trợ change detection thông qua các benchmark datasets như OSCD, LEVIR-CD và xView2, cùng khả năng tích hợp với các kiến trúc deep learning chuyên biệt. Chương này trình bày ba kiến trúc change detection tiêu biểu: FC-Siam, BIT-Transformer và STANet.</p><h2 id="_5-4-2-phan-loai-bai-toan-change-detection" tabindex="-1">5.4.2. Phân Loại Bài Toán Change Detection <a class="header-anchor" href="#_5-4-2-phan-loai-bai-toan-change-detection" aria-label="Permalink to &quot;5.4.2. Phân Loại Bài Toán Change Detection&quot;">​</a></h2><p>Trước khi đi vào chi tiết các kiến trúc, cần phân biệt các formulations khác nhau của bài toán change detection:</p><table tabindex="0"><thead><tr><th>Formulation</th><th>Output</th><th>Độ phức tạp</th><th>Ứng dụng</th></tr></thead><tbody><tr><td>Binary CD</td><td>Change/No-change mask</td><td>Thấp</td><td>General monitoring</td></tr><tr><td>Semantic CD</td><td>Multi-class change type</td><td>Trung bình</td><td>Urban planning</td></tr><tr><td>From-to CD</td><td>Transition matrix</td><td>Cao</td><td>Land use analysis</td></tr><tr><td>Multi-temporal CD</td><td>Change trajectory</td><td>Cao</td><td>Continuous monitoring</td></tr></tbody></table><p><strong>Bảng 5.17:</strong> Các formulations của bài toán change detection</p><p><strong>Binary Change Detection</strong> là formulation phổ biến nhất, xác định đơn giản pixel nào đã thay đổi. <strong>Semantic Change Detection</strong> phân loại thêm loại thay đổi (xây dựng mới, phá hủy, mất rừng...). <strong>From-to Change Detection</strong> xác định transition cụ thể (rừng → đô thị). <strong>Multi-temporal CD</strong> mở rộng sang chuỗi thời gian nhiều thời điểm.</p><h2 id="_5-4-3-fc-siam-fully-convolutional-siamese-networks" tabindex="-1">5.4.3. FC-Siam: Fully Convolutional Siamese Networks <a class="header-anchor" href="#_5-4-3-fc-siam-fully-convolutional-siamese-networks" aria-label="Permalink to &quot;5.4.3. FC-Siam: Fully Convolutional Siamese Networks&quot;">​</a></h2><h3 id="_5-4-3-1-kien-truc-siamese-cho-so-sanh-thoi-gian" tabindex="-1">5.4.3.1. Kiến Trúc Siamese cho So Sánh Thời Gian <a class="header-anchor" href="#_5-4-3-1-kien-truc-siamese-cho-so-sanh-thoi-gian" aria-label="Permalink to &quot;5.4.3.1. Kiến Trúc Siamese cho So Sánh Thời Gian&quot;">​</a></h3><p>FC-Siam [Daudt et al., 2018] đề xuất kiến trúc fully convolutional end-to-end cho change detection, không yêu cầu pre-training. Ý tưởng cốt lõi là sử dụng <strong>Siamese encoder</strong> - hai nhánh encoder chia sẻ trọng số (shared weights) xử lý song song ảnh từ hai thời điểm, sau đó so sánh features để tạo change map.</p>',13)),(o(),l(h,null,{default:i(()=>[d(r,{id:"mermaid-112",class:"mermaid",graph:"graph%20TD%0A%20%20%20%20subgraph%20%22Siamese%20Encoder%22%0A%20%20%20%20%20%20%20%20I1%5B%22Image%20t1%22%5D%20--%3E%20E1%5B%22Encoder%3Cbr%2F%3E(shared)%22%5D%0A%20%20%20%20%20%20%20%20I2%5B%22Image%20t2%22%5D%20--%3E%20E2%5B%22Encoder%3Cbr%2F%3E(shared)%22%5D%0A%20%20%20%20%20%20%20%20E1%20--%3E%20F1%5B%22Features%20t1%22%5D%0A%20%20%20%20%20%20%20%20E2%20--%3E%20F2%5B%22Features%20t2%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20%22Comparison%20Module%22%0A%20%20%20%20%20%20%20%20F1%20--%3E%20C%5B%22Compare%3A%3Cbr%2F%3EConcat%20%2F%20Diff%22%5D%0A%20%20%20%20%20%20%20%20F2%20--%3E%20C%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20%22Decoder%22%0A%20%20%20%20%20%20%20%20C%20--%3E%20D%5B%22Decoder%22%5D%0A%20%20%20%20%20%20%20%20D%20--%3E%20O%5B%22Change%20Map%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20style%20I1%20fill%3A%23e3f2fd%0A%20%20%20%20style%20I2%20fill%3A%23e3f2fd%0A%20%20%20%20style%20O%20fill%3A%23c8e6c9%0A"})]),fallback:i(()=>[...e[0]||(e[0]=[n(" Loading... ",-1)])]),_:1})),e[22]||(e[22]=a('<p><strong>Hình 5.16:</strong> Kiến trúc chung của Siamese change detection</p><p>Ba variants được đề xuất với chiến lược comparison khác nhau:</p><ul><li><strong>FC-EF (Early Fusion):</strong> Concatenate hai ảnh đầu vào thành 6-channel input, xử lý bởi single encoder-decoder</li><li><strong>FC-Siam-conc (Concatenation):</strong> Siamese encoder + concatenate skip connections tại decoder</li><li><strong>FC-Siam-diff (Difference):</strong> Siamese encoder + absolute difference của skip connections</li></ul><h3 id="_5-4-3-2-skip-connection-strategies" tabindex="-1">5.4.3.2. Skip Connection Strategies <a class="header-anchor" href="#_5-4-3-2-skip-connection-strategies" aria-label="Permalink to &quot;5.4.3.2. Skip Connection Strategies&quot;">​</a></h3><p>Điểm khác biệt chính giữa FC-Siam-conc và FC-Siam-diff nằm ở cách xử lý skip connections từ encoder:</p>',5)),(o(),l(h,null,{default:i(()=>[d(r,{id:"mermaid-142",class:"mermaid",graph:"graph%20LR%0A%20%20%20%20subgraph%20%22FC-Siam-conc%22%0A%20%20%20%20%20%20%20%20A1%5B%22Skip%20t1%22%5D%20--%3E%20C1%5B%22Concat%22%5D%0A%20%20%20%20%20%20%20%20A2%5B%22Skip%20t2%22%5D%20--%3E%20C1%0A%20%20%20%20%20%20%20%20C1%20--%3E%20D1%5B%22Decoder%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20%22FC-Siam-diff%22%0A%20%20%20%20%20%20%20%20B1%5B%22Skip%20t1%22%5D%20--%3E%20Diff%5B%22%7Ct1%20-%20t2%7C%22%5D%0A%20%20%20%20%20%20%20%20B2%5B%22Skip%20t2%22%5D%20--%3E%20Diff%0A%20%20%20%20%20%20%20%20Diff%20--%3E%20D2%5B%22Decoder%22%5D%0A%20%20%20%20end%0A"})]),fallback:i(()=>[...e[1]||(e[1]=[n(" Loading... ",-1)])]),_:1})),e[23]||(e[23]=a('<p><strong>Hình 5.17:</strong> So sánh skip connection strategies trong FC-Siam variants</p><p>FC-Siam-diff thể hiện performance tốt hơn trên hầu hết benchmarks do <strong>explicit difference</strong> giúp model focus trực tiếp vào vùng có thay đổi.</p><h3 id="_5-4-3-3-benchmark-performance" tabindex="-1">5.4.3.3. Benchmark Performance <a class="header-anchor" href="#_5-4-3-3-benchmark-performance" aria-label="Permalink to &quot;5.4.3.3. Benchmark Performance&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Dataset</th><th>Best Variant</th><th>F1 Score</th><th>Speed</th></tr></thead><tbody><tr><td>OSCD (13 bands)</td><td>FC-Siam-diff</td><td>48.86%</td><td>&lt;0.1s/image</td></tr><tr><td>OSCD (RGB)</td><td>FC-Siam-diff</td><td>57.92%</td><td>&lt;0.1s/image</td></tr><tr><td>Air Change Szada</td><td>FC-Siam-diff</td><td>52.66%</td><td>-</td></tr><tr><td>Air Change Tiszadob</td><td>FC-EF</td><td>93.40%</td><td>-</td></tr></tbody></table><p><strong>Bảng 5.18:</strong> Benchmark performance của FC-Siam variants</p><p>Điểm mạnh của FC-Siam là <strong>tốc độ inference nhanh</strong> (500× so với patch-based methods) và <strong>đơn giản</strong>, nhưng accuracy còn hạn chế so với các phương pháp attention-based hiện đại.</p><h2 id="_5-4-4-bit-transformer-binary-change-detection-transformer" tabindex="-1">5.4.4. BIT-Transformer: Binary Change Detection Transformer <a class="header-anchor" href="#_5-4-4-bit-transformer-binary-change-detection-transformer" aria-label="Permalink to &quot;5.4.4. BIT-Transformer: Binary Change Detection Transformer&quot;">​</a></h2><h3 id="_5-4-4-1-token-based-context-modeling" tabindex="-1">5.4.4.1. Token-based Context Modeling <a class="header-anchor" href="#_5-4-4-1-token-based-context-modeling" aria-label="Permalink to &quot;5.4.4.1. Token-based Context Modeling&quot;">​</a></h3><p>BIT-Transformer [Chen et al., 2021] mang kiến trúc Transformer vào change detection, đạt SOTA performance với <strong>3× ít FLOPs/parameters</strong> so với convolutional baselines. Đổi mới chính là chuyển từ dense pixel-level processing sang compact <strong>token-based representation</strong>.</p><h3 id="_5-4-4-2-quy-trinh-xu-ly" tabindex="-1">5.4.4.2. Quy Trình Xử Lý <a class="header-anchor" href="#_5-4-4-2-quy-trinh-xu-ly" aria-label="Permalink to &quot;5.4.4.2. Quy Trình Xử Lý&quot;">​</a></h3><p>BIT-Transformer hoạt động theo 5 bước:</p>',11)),(o(),l(h,null,{default:i(()=>[d(r,{id:"mermaid-249",class:"mermaid",graph:"graph%20TD%0A%20%20%20%20subgraph%20%221.%20Feature%20Extraction%22%0A%20%20%20%20%20%20%20%20I1%5B%22Input%20t1%22%5D%20--%3E%20B1%5B%22CNN%20Backbone%3Cbr%2F%3E(ResNet)%22%5D%0A%20%20%20%20%20%20%20%20I2%5B%22Input%20t2%22%5D%20--%3E%20B2%5B%22CNN%20Backbone%3Cbr%2F%3E(shared)%22%5D%0A%20%20%20%20%20%20%20%20B1%20--%3E%20X1%5B%22Features%20X%E2%82%81%22%5D%0A%20%20%20%20%20%20%20%20B2%20--%3E%20X2%5B%22Features%20X%E2%82%82%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20%222.%20Semantic%20Tokenizer%22%0A%20%20%20%20%20%20%20%20X1%20--%3E%20T1%5B%22Tokens%20T%E2%82%81%22%5D%0A%20%20%20%20%20%20%20%20X2%20--%3E%20T2%5B%22Tokens%20T%E2%82%82%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20%223.%20Transformer%20Encoder%22%0A%20%20%20%20%20%20%20%20T1%20--%3E%20TE%5B%22MSA%20%2B%20MLP%22%5D%0A%20%20%20%20%20%20%20%20T2%20--%3E%20TE%0A%20%20%20%20%20%20%20%20TE%20--%3E%20TN%5B%22Context%20Tokens%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20%224.%20Transformer%20Decoder%22%0A%20%20%20%20%20%20%20%20TN%20--%3E%20TD%5B%22Cross-Attention%22%5D%0A%20%20%20%20%20%20%20%20X1%20--%3E%20TD%0A%20%20%20%20%20%20%20%20X2%20--%3E%20TD%0A%20%20%20%20%20%20%20%20TD%20--%3E%20XN%5B%22Refined%20Features%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20subgraph%20%225.%20Prediction%22%0A%20%20%20%20%20%20%20%20XN%20--%3E%20FDI%5B%22Feature%20Diff%22%5D%0A%20%20%20%20%20%20%20%20FDI%20--%3E%20P%5B%22Change%20Map%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20style%20I1%20fill%3A%23e3f2fd%0A%20%20%20%20style%20I2%20fill%3A%23e3f2fd%0A%20%20%20%20style%20P%20fill%3A%23c8e6c9%0A"})]),fallback:i(()=>[...e[2]||(e[2]=[n(" Loading... ",-1)])]),_:1})),e[24]||(e[24]=a('<p><strong>Hình 5.19:</strong> Pipeline xử lý của BIT-Transformer</p><p><strong>Semantic Tokenizer</strong> pool dense features thành compact tokens thông qua learned spatial attention maps. <strong>Transformer Encoder</strong> model long-range context trong token-space. <strong>Transformer Decoder</strong> project tokens trở lại pixel-space qua cross-attention.</p><h3 id="_5-4-4-3-benchmark-va-efficiency" tabindex="-1">5.4.4.3. Benchmark và Efficiency <a class="header-anchor" href="#_5-4-4-3-benchmark-va-efficiency" aria-label="Permalink to &quot;5.4.4.3. Benchmark và Efficiency&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Dataset</th><th>BIT F1</th><th>Previous SOTA</th><th>Improvement</th></tr></thead><tbody><tr><td>LEVIR-CD</td><td>89.31%</td><td>87.26% (STANet)</td><td>+2.05pp</td></tr><tr><td>WHU-CD</td><td>83.98%</td><td>82.32% (STANet)</td><td>+1.66pp</td></tr><tr><td>DSIFN-CD</td><td>69.26%</td><td>64.56% (STANet)</td><td>+4.70pp</td></tr></tbody></table><p><strong>Bảng 5.19:</strong> BIT-Transformer vs previous SOTA trên change detection benchmarks</p><p>Đặc biệt, BIT đạt hiệu suất cao hơn với <strong>3× ít FLOPs</strong> so với fully convolutional baselines, chứng minh effectiveness của token-based approach.</p><h2 id="_5-4-5-stanet-spatial-temporal-attention-network" tabindex="-1">5.4.5. STANet: Spatial-Temporal Attention Network <a class="header-anchor" href="#_5-4-5-stanet-spatial-temporal-attention-network" aria-label="Permalink to &quot;5.4.5. STANet: Spatial-Temporal Attention Network&quot;">​</a></h2><h3 id="_5-4-5-1-cd-self-attention-mechanism" tabindex="-1">5.4.5.1. CD Self-Attention Mechanism <a class="header-anchor" href="#_5-4-5-1-cd-self-attention-mechanism" aria-label="Permalink to &quot;5.4.5.1. CD Self-Attention Mechanism&quot;">​</a></h3><p>STANet [Chen &amp; Shi, 2020] đề xuất <strong>CD self-attention</strong> - cơ chế attention explicitly modeling spatial-temporal relationships giữa hai ảnh. Điểm mạnh là <strong>robustness</strong> với illumination variations và misregistration errors thường gặp trong dữ liệu viễn thám.</p><h3 id="_5-4-5-2-attention-module-variants" tabindex="-1">5.4.5.2. Attention Module Variants <a class="header-anchor" href="#_5-4-5-2-attention-module-variants" aria-label="Permalink to &quot;5.4.5.2. Attention Module Variants&quot;">​</a></h3><p>STANet đề xuất hai variants của attention module:</p><p><strong>Basic Attention Module (BAM):</strong></p><ul><li>Global spatial-temporal self-attention</li><li>Tính weighted sum across tất cả spatio-temporal positions</li><li>Captures long-range dependencies</li></ul><p><strong>Pyramid Attention Module (PAM):</strong></p><ul><li>Multi-scale BAM trong pyramid structure</li><li>Xử lý objects ở nhiều scales khác nhau</li><li>Performance cao hơn BAM (+1.6%)</li></ul>',15)),(o(),l(h,null,{default:i(()=>[d(r,{id:"mermaid-382",class:"mermaid",graph:"graph%20TD%0A%20%20%20%20subgraph%20%22PAM%20-%20Pyramid%20Attention%22%0A%20%20%20%20%20%20%20%20F%5B%22Backbone%20Features%22%5D%20--%3E%20P1%5B%22Scale%201%20BAM%22%5D%0A%20%20%20%20%20%20%20%20F%20--%3E%20P2%5B%22Scale%201%2F2%20BAM%22%5D%0A%20%20%20%20%20%20%20%20F%20--%3E%20P3%5B%22Scale%201%2F4%20BAM%22%5D%0A%20%20%20%20%20%20%20%20P1%20--%3E%20M%5B%22Merge%22%5D%0A%20%20%20%20%20%20%20%20P2%20--%3E%20M%0A%20%20%20%20%20%20%20%20P3%20--%3E%20M%0A%20%20%20%20%20%20%20%20M%20--%3E%20O%5B%22Output%22%5D%0A%20%20%20%20end%0A%0A%20%20%20%20style%20F%20fill%3A%23e3f2fd%0A%20%20%20%20style%20O%20fill%3A%23c8e6c9%0A"})]),fallback:i(()=>[...e[3]||(e[3]=[n(" Loading... ",-1)])]),_:1})),e[25]||(e[25]=a('<p><strong>Hình 5.21:</strong> Pyramid Attention Module với multi-scale processing</p><h3 id="_5-4-5-3-đong-gop-dataset-levir-cd" tabindex="-1">5.4.5.3. Đóng Góp Dataset: LEVIR-CD <a class="header-anchor" href="#_5-4-5-3-đong-gop-dataset-levir-cd" aria-label="Permalink to &quot;5.4.5.3. Đóng Góp Dataset: LEVIR-CD&quot;">​</a></h3><p>Một đóng góp quan trọng của STANet là việc công bố <strong>LEVIR-CD dataset</strong> - benchmark lớn nhất cho building change detection:</p><table tabindex="0"><thead><tr><th>Attribute</th><th>Value</th></tr></thead><tbody><tr><td>Số pairs</td><td>637</td></tr><tr><td>Resolution</td><td>0.5m</td></tr><tr><td>Size</td><td>1024×1024 pixels</td></tr><tr><td>Time span</td><td>5-14 năm</td></tr><tr><td>Focus</td><td>Building changes</td></tr></tbody></table><p><strong>Bảng 5.20:</strong> LEVIR-CD dataset characteristics</p><h3 id="_5-4-5-4-benchmark-performance" tabindex="-1">5.4.5.4. Benchmark Performance <a class="header-anchor" href="#_5-4-5-4-benchmark-performance" aria-label="Permalink to &quot;5.4.5.4. Benchmark Performance&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Method</th><th>F1 Score</th><th>Improvement</th></tr></thead><tbody><tr><td>STANet-Base</td><td>~86%</td><td>Baseline</td></tr><tr><td>STANet-BAM</td><td>~87.8%</td><td>+1.8pp</td></tr><tr><td>STANet-PAM</td><td>~89.4%</td><td>+3.4pp overall</td></tr></tbody></table><p><strong>Bảng 5.21:</strong> Comparison of STANet variants trên LEVIR-CD</p><h2 id="_5-4-6-so-sanh-tong-hop" tabindex="-1">5.4.6. So Sánh Tổng Hợp <a class="header-anchor" href="#_5-4-6-so-sanh-tong-hop" aria-label="Permalink to &quot;5.4.6. So Sánh Tổng Hợp&quot;">​</a></h2><p>Bảng 5.22 so sánh ba kiến trúc change detection chính:</p><table tabindex="0"><thead><tr><th>Aspect</th><th>FC-Siam</th><th>BIT-Transformer</th><th>STANet</th></tr></thead><tbody><tr><td><strong>Core Design</strong></td><td>Siamese CNN</td><td>Transformer tokens</td><td>Siamese + Attention</td></tr><tr><td><strong>Feature Fusion</strong></td><td>Skip diff/concat</td><td>Token-space context</td><td>Spatial-temporal attn</td></tr><tr><td><strong>Scale Handling</strong></td><td>Single resolution</td><td>Implicit (tokens)</td><td>Multi-scale (PAM)</td></tr><tr><td><strong>Efficiency</strong></td><td>Fastest (baseline)</td><td>3× fewer FLOPs</td><td>Moderate</td></tr><tr><td><strong>Best F1 (LEVIR)</strong></td><td>~75%</td><td>89.31%</td><td>89.4%</td></tr><tr><td><strong>Robustness</strong></td><td>Basic</td><td>High</td><td>High (illumination)</td></tr></tbody></table><p><strong>Bảng 5.22:</strong> So sánh kiến trúc change detection</p><h3 id="khuyen-nghi-thuc-tien" tabindex="-1">Khuyến Nghị Thực Tiễn <a class="header-anchor" href="#khuyen-nghi-thuc-tien" aria-label="Permalink to &quot;Khuyến Nghị Thực Tiễn&quot;">​</a></h3><ol><li><strong>Speed priority:</strong> FC-Siam-diff cho rapid screening</li><li><strong>Accuracy + Efficiency:</strong> BIT-Transformer (3× efficiency với SOTA accuracy)</li><li><strong>Illumination variations:</strong> STANet-PAM với robustness cao</li><li><strong>Limited compute:</strong> FC-EF đơn giản nhất</li></ol><h2 id="_5-4-7-change-detection-datasets-trong-torchgeo" tabindex="-1">5.4.7. Change Detection Datasets trong TorchGeo <a class="header-anchor" href="#_5-4-7-change-detection-datasets-trong-torchgeo" aria-label="Permalink to &quot;5.4.7. Change Detection Datasets trong TorchGeo&quot;">​</a></h2><p>TorchGeo tích hợp các benchmark datasets phổ biến:</p><table tabindex="0"><thead><tr><th>Dataset</th><th>Source</th><th>Pairs</th><th>Resolution</th><th>Focus</th></tr></thead><tbody><tr><td>OSCD</td><td>Sentinel-2</td><td>24</td><td>10m</td><td>Urban change</td></tr><tr><td>LEVIR-CD</td><td>Google Earth</td><td>637</td><td>0.5m</td><td>Building change</td></tr><tr><td>WHU-CD</td><td>Aerial</td><td>1 (large)</td><td>0.075m</td><td>Building change</td></tr><tr><td>xView2</td><td>WorldView</td><td>8,399</td><td>&lt;1m</td><td>Damage assessment</td></tr></tbody></table><p><strong>Bảng 5.23:</strong> Change detection datasets trong TorchGeo</p><p><strong>OSCD (Onera Satellite Change Detection):</strong> 24 pairs ảnh Sentinel-2 13 bands, urban areas worldwide, binary change labels.</p><p><strong>LEVIR-CD:</strong> 637 pairs high-resolution (0.5m), focus building construction/demolition, 10-year time span.</p><p><strong>xView2:</strong> Damage assessment sau disasters, 4 damage levels (intact → destroyed), multiple disaster events.</p><h2 id="_5-4-8-training-best-practices" tabindex="-1">5.4.8. Training Best Practices <a class="header-anchor" href="#_5-4-8-training-best-practices" aria-label="Permalink to &quot;5.4.8. Training Best Practices&quot;">​</a></h2><h3 id="_5-4-8-1-paired-augmentation" tabindex="-1">5.4.8.1. Paired Augmentation <a class="header-anchor" href="#_5-4-8-1-paired-augmentation" aria-label="Permalink to &quot;5.4.8.1. Paired Augmentation&quot;">​</a></h3><p>Điểm đặc biệt của change detection là cần <strong>paired augmentation</strong> - apply cùng geometric transform cho cả hai ảnh để duy trì spatial alignment:</p><p><strong>Geometric (same for both):</strong></p><ul><li>Random flip (H/V)</li><li>Random rotation (90°, 180°, 270°)</li><li>Random crop</li></ul><p><strong>Photometric (can differ):</strong></p><ul><li>Brightness/contrast adjustment</li><li>Color jittering</li><li>Mimics different acquisition conditions</li></ul><h3 id="_5-4-8-2-class-imbalance" tabindex="-1">5.4.8.2. Class Imbalance <a class="header-anchor" href="#_5-4-8-2-class-imbalance" aria-label="Permalink to &quot;5.4.8.2. Class Imbalance&quot;">​</a></h3><p>Change detection có <strong>extreme class imbalance</strong> - thường &lt;5% pixels thay đổi. Các giải pháp:</p>',30)),t("ul",null,[e[8]||(e[8]=t("li",null,[t("strong",null,"Focal Loss:"),n(" Focus vào hard examples")],-1)),e[9]||(e[9]=t("li",null,[t("strong",null,"Dice/IoU Loss:"),n(" Optimize overlap metric")],-1)),e[10]||(e[10]=t("li",null,[t("strong",null,"Patch selection:"),n(" Bias sampling toward patches có change")],-1)),t("li",null,[e[6]||(e[6]=t("strong",null,"Combined loss:",-1)),e[7]||(e[7]=n()),t("mjx-container",m,[(o(),s("svg",g,[...e[4]||(e[4]=[a('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="4C" d="M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(967.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2023.6,0)"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(2885.8,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(3386,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(4145,0)"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(4905,0)"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(5891.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(6891.4,0)"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(7679.7,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(8179.9,0)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(9007.9,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(9352.9,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(9785.9,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z" style="stroke-width:3;"></path></g></g></g>',1)])])),e[5]||(e[5]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mrow",{"data-mjx-texclass":"ORD"},[t("mi",{"data-mjx-variant":"-tex-calligraphic",mathvariant:"script"},"L")]),t("mo",null,"="),t("mi",null,"α"),t("mo",null,"⋅"),t("mi",null,"B"),t("mi",null,"C"),t("mi",null,"E"),t("mo",null,"+"),t("mi",null,"β"),t("mo",null,"⋅"),t("mi",null,"D"),t("mi",null,"i"),t("mi",null,"c"),t("mi",null,"e")])],-1))])])]),e[26]||(e[26]=t("h3",{id:"_5-4-8-3-evaluation-metrics",tabindex:"-1"},[n("5.4.8.3. Evaluation Metrics "),t("a",{class:"header-anchor",href:"#_5-4-8-3-evaluation-metrics","aria-label":'Permalink to "5.4.8.3. Evaluation Metrics"'},"​")],-1)),t("table",p,[e[20]||(e[20]=t("thead",null,[t("tr",null,[t("th",null,"Metric"),t("th",null,"Formula"),t("th",null,"Ưu điểm")])],-1)),t("tbody",null,[t("tr",null,[e[13]||(e[13]=t("td",null,"F1 Score",-1)),t("td",null,[t("mjx-container",u,[(o(),s("svg",f,[...e[11]||(e[11]=[a('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(220,394) scale(0.707)"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(500,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1529,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1807,0)"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mrow" transform="translate(318.3,-345) scale(0.707)"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(751,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1529,0)"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z" style="stroke-width:3;"></path></g></g><rect width="2014.4" height="60" x="120" y="220"></rect></g></g></g>',1)])])),e[12]||(e[12]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mfrac",null,[t("mrow",null,[t("mn",null,"2"),t("mo",null,"⋅"),t("mi",null,"P"),t("mo",null,"⋅"),t("mi",null,"R")]),t("mrow",null,[t("mi",null,"P"),t("mo",null,"+"),t("mi",null,"R")])])])],-1))])]),e[14]||(e[14]=t("td",null,"Balance precision/recall",-1))]),t("tr",null,[e[17]||(e[17]=t("td",null,"IoU",-1)),t("td",null,[t("mjx-container",b,[(o(),s("svg",k,[...e[15]||(e[15]=[a('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(1879.2,394) scale(0.707)"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(704,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mrow" transform="translate(220,-345) scale(0.707)"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(704,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1455,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2233,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2982,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3733,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(4511,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(5260,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z" style="stroke-width:3;"></path></g></g><rect width="4547.3" height="60" x="120" y="220"></rect></g></g></g>',1)])])),e[16]||(e[16]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mfrac",null,[t("mrow",null,[t("mi",null,"T"),t("mi",null,"P")]),t("mrow",null,[t("mi",null,"T"),t("mi",null,"P"),t("mo",null,"+"),t("mi",null,"F"),t("mi",null,"P"),t("mo",null,"+"),t("mi",null,"F"),t("mi",null,"N")])])])],-1))])]),e[18]||(e[18]=t("td",null,"Overlap-based",-1))]),e[19]||(e[19]=t("tr",null,[t("td",null,"Kappa"),t("td",null,"Cohen's Kappa"),t("td",null,"Accounts for chance")],-1))])]),e[27]||(e[27]=a('<p><strong>Bảng 5.24:</strong> Metrics cho change detection evaluation</p><h2 id="_3-4-9-ket-luan-muc" tabindex="-1">3.4.9. Kết Luận Mục <a class="header-anchor" href="#_3-4-9-ket-luan-muc" aria-label="Permalink to &quot;3.4.9. Kết Luận Mục&quot;">​</a></h2><p>Change detection là bài toán đặc trưng của viễn thám với nhiều thách thức riêng: class imbalance nghiêm trọng (&lt;5% pixels thay đổi), biến đổi điều kiện chụp ảnh, và yêu cầu so sánh thời gian hiệu quả. Các kiến trúc hiện đại như <strong>BIT-Transformer</strong> và <strong>STANet</strong> đã đạt hiệu suất ấn tượng (&gt;89% F1 trên LEVIR-CD) thông qua attention mechanisms cho phép model học so sánh features một cách hiệu quả.</p><p><strong>FC-Siam</strong> vẫn là baseline đáng tin cậy cho ứng dụng cần tốc độ (500× nhanh hơn patch-based methods). <strong>BIT-Transformer</strong> cung cấp balance tốt với 3× fewer FLOPs nhưng SOTA accuracy nhờ token-based representation. <strong>STANet</strong> mạnh về robustness với illumination variations và misregistration errors.</p><p>Các kiến trúc change detection này tận dụng backbone encoders (ResNet, ViT) đã học từ <strong>Mục 3.2</strong>, và áp dụng skip connection strategies từ segmentation architectures (<strong>Mục 3.3</strong>). <strong>Mục 3.5</strong> tiếp theo sẽ tổng hợp về pre-trained weights và self-supervised learning - yếu tố then chốt giúp cải thiện performance của tất cả các kiến trúc đã trình bày.</p><hr><h2 id="tai-lieu-tham-khao" tabindex="-1">Tài Liệu Tham Khảo <a class="header-anchor" href="#tai-lieu-tham-khao" aria-label="Permalink to &quot;Tài Liệu Tham Khảo&quot;">​</a></h2><p>[1] Daudt, R. C., Le Saux, B., &amp; Boulch, A. (2018). &quot;Fully Convolutional Siamese Networks for Change Detection.&quot; ICIP. arXiv:1810.08462.</p><p>[2] Chen, H., Qi, Z., &amp; Shi, Z. (2021). &quot;Remote Sensing Image Change Detection with Transformers.&quot; IEEE TGRS. arXiv:2103.00208.</p><p>[3] Chen, H., &amp; Shi, Z. (2020). &quot;A Spatial-Temporal Attention-Based Method and a New Dataset for Remote Sensing Image Change Detection.&quot; Remote Sensing. arXiv:2007.03078.</p><p>[4] Chen, H., Qi, Z., &amp; Shi, Z. (2020). &quot;LEVIR-CD: A Large-Scale Remote Sensing Image Change Detection Dataset.&quot; arXiv:2012.03588.</p>',11))])}const v=Q(c,[["render",A]]);export{_ as __pageData,v as default};
