<!DOCTYPE html>
<html lang="vi-VN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>xView2/xBD Dataset Image Sources &amp; Documentation | Deep Learning trong Viễn thám</title>
    <meta name="description" content="Nghiên cứu ứng dụng CNN và Deep Learning trong phân tích ảnh viễn thám">
    <meta name="generator" content="VitePress v1.6.4">
    <link rel="preload stylesheet" href="/sen_doc/assets/style.W3JISx3E.css" as="style">
    <link rel="preload stylesheet" href="/sen_doc/vp-icons.css" as="style">
    
    <script type="module" src="/sen_doc/assets/app.CWSbRAFv.js"></script>
    <link rel="preload" href="/sen_doc/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/framework.nRfFlDZQ.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/theme.Ch0spFQA.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/katex.Cu_Erd72.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/dagre-6UL2VRFP.BQ5r6kFc.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/cose-bilkent-S5V4N54A.Cg2D0hX4.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/c4Diagram-YG6GDRKO.Ch1Z5DYy.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/flowDiagram-NV44I4VS.B-M56PNY.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/erDiagram-Q2GNP2WA.ChNEjQqf.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/gitGraphDiagram-NY62KEGX.CYjbWr1H.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/ganttDiagram-JELNMOA3.BuFF-7gm.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/infoDiagram-WHAUD3N6.DXhWiX-4.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/pieDiagram-ADFJNKIX.CEooP7iW.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/quadrantDiagram-AYHSOK5B.BxpFNOre.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/xychartDiagram-PRI3JC2R.D7l7DTkm.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/requirementDiagram-UZGBJVZJ.CnZWdBnS.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/sequenceDiagram-WL72ISMW.Dq5DiI5R.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/classDiagram-2ON5EDUG.C-uTH9t6.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/classDiagram-v2-WZHVMYZB.C-uTH9t6.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/stateDiagram-FKZM4ZOC.DA69JNoS.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/stateDiagram-v2-4FDKWEC3.CvG5pOcG.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/journeyDiagram-XKPGCS4Q.B6_zk-Uc.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/timeline-definition-IT6M3QCI.Bq-srREc.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/mindmap-definition-VGOIOE7T.C1lO0ZZX.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/kanban-definition-3W4ZIXB7.D1R1ZtJ4.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/sankeyDiagram-TZEHDZUN.3FvNQ0V-.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/diagram-S2PKOQOG.CN4gAtio.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/diagram-QEK2KX5R.BgEYpliI.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/blockDiagram-VD42YOAC.CblIZ9TF.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/architectureDiagram-VXUJARFQ.D58rp7Xd.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/diagram-PSM6KHXK.55LfW1Pd.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/virtual_mermaid-config.CQTEIV6y.js">
    <link rel="modulepreload" href="/sen_doc/assets/assets_images_xview2_image-sources.md.DuMc8EPf.lean.js">
    <meta name="theme-color" content="#3eaf7c">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5d98c3a5><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0b0ada53></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0b0ada53>Skip to content</a><!--]--><!----><header class="VPNav" data-v-5d98c3a5 data-v-ae24b3ad><div class="VPNavBar" data-v-ae24b3ad data-v-6aa21345><div class="wrapper" data-v-6aa21345><div class="container" data-v-6aa21345><div class="title" data-v-6aa21345><div class="VPNavBarTitle has-sidebar" data-v-6aa21345 data-v-1168a8e4><a class="title" href="/sen_doc/" data-v-1168a8e4><!--[--><!--]--><!----><span data-v-1168a8e4>Deep Learning trong Viễn thám</span><!--[--><!--]--></a></div></div><div class="content" data-v-6aa21345><div class="content-body" data-v-6aa21345><!--[--><!--]--><div class="VPNavBarSearch search" data-v-6aa21345><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-6aa21345 data-v-dc692963><span id="main-nav-aria-label" class="visually-hidden" data-v-dc692963> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/sen_doc/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Trang chủ</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/sen_doc/chuong-01-gioi-thieu/muc-01-tong-quan/01-gioi-thieu-cnn-deep-learning.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Giới thiệu</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/sen_doc/chuong-05-torchgeo/muc-01-tong-quan/01-tong-quan.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>TorchGeo</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/01-dataset.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>xView</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-6aa21345 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-6aa21345 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/tchatb/sen_doc" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-6aa21345 data-v-bb2aa2f0 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-cf11d7a2><span class="vpi-more-horizontal icon" data-v-cf11d7a2></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><!----><!--[--><!--[--><!----><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>Giao diện</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/tchatb/sen_doc" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-6aa21345 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-6aa21345><div class="divider-line" data-v-6aa21345></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-5d98c3a5 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-8a42e2b4><button data-v-8a42e2b4>Về đầu trang</button><!----></div></div></div><aside class="VPSidebar" data-v-5d98c3a5 data-v-319d5ca6><div class="curtain" data-v-319d5ca6></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-319d5ca6><span class="visually-hidden" id="sidebar-aria-label" data-v-319d5ca6> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 1: Giới thiệu</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-01-gioi-thieu/muc-01-tong-quan/01-gioi-thieu-cnn-deep-learning.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>1.1. Tổng quan CNN & Deep Learning</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 2: Cơ sở lý thuyết</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-01-kien-truc-cnn/01-kien-truc-co-ban.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.1.1. Kiến trúc CNN cơ bản</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-01-kien-truc-cnn/02-backbone-networks.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.1.2. Backbone Networks</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/01-phan-loai-anh.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.2.1. Phân loại ảnh</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/02-phat-hien-doi-tuong.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.2.2. Phát hiện đối tượng</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/03-phan-doan-ngu-nghia.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.2.3. Phân đoạn ngữ nghĩa</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/04-instance-segmentation.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.2.4. Instance Segmentation</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible collapsed" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 3: Phát hiện tàu biển</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-03-phat-hien-tau-bien/muc-01-dac-diem-bai-toan/01-dac-diem.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>3.1. Đặc điểm bài toán</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-03-phat-hien-tau-bien/muc-02-mo-hinh/01-cac-mo-hinh.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>3.2. Các mô hình</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-03-phat-hien-tau-bien/muc-03-quy-trinh/01-pipeline.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>3.3. Quy trình pipeline</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-03-phat-hien-tau-bien/muc-04-bo-du-lieu/01-datasets.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>3.4. Bộ dữ liệu</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible collapsed" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 4: Phát hiện dầu loang</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-phat-hien-dau-loang/muc-01-dac-diem-bai-toan/01-dac-diem.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>4.1. Đặc điểm bài toán</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-phat-hien-dau-loang/muc-02-mo-hinh/01-cac-mo-hinh.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>4.2. Các mô hình</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-phat-hien-dau-loang/muc-03-quy-trinh/01-pipeline.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>4.3. Quy trình pipeline</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-phat-hien-dau-loang/muc-04-bo-du-lieu/01-datasets.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>4.4. Bộ dữ liệu</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible collapsed" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 5: TorchGeo</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-torchgeo/muc-01-tong-quan/01-tong-quan.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.1. Tổng quan</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-torchgeo/muc-02-classification/01-classification-models.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.2. Classification Models</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-torchgeo/muc-03-segmentation/01-segmentation-models.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.3. Segmentation Models</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-torchgeo/muc-04-change-detection/01-change-detection-models.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.4. Change Detection</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-torchgeo/muc-05-pretrained-weights/01-pretrained-weights.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.5. Pre-trained Weights</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 6: xView Challenges</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><section class="VPSidebarItem level-1 collapsible collapsed" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h3 class="text" data-v-b3fd67f8>6.1. xView1 - Object Detection</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/01-dataset.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/02-giai-nhat.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhất</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/03-giai-nhi.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhì</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/04-giai-ba.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải ba</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/05-giai-tu.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải tư</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-01-xview1-object-detection/06-giai-nam.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải năm</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible collapsed" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h3 class="text" data-v-b3fd67f8>6.2. xView2 - Building Damage</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-02-xview2-building-damage/01-dataset.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Dataset (xBD)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-02-xview2-building-damage/02-giai-nhat.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhất</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-02-xview2-building-damage/03-giai-nhi.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhì</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-02-xview2-building-damage/04-giai-ba.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải ba</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-02-xview2-building-damage/05-giai-tu.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải tư</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-02-xview2-building-damage/06-giai-nam.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải năm</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible collapsed" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h3 class="text" data-v-b3fd67f8>6.3. xView3 - Maritime (SAR)</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-03-xview3-maritime/01-dataset.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-03-xview3-maritime/02-giai-nhat.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhất</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-03-xview3-maritime/03-giai-nhi.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhì</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-03-xview3-maritime/04-giai-ba.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải ba</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-03-xview3-maritime/05-giai-tu.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải tư</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-xview-challenges/muc-03-xview3-maritime/06-giai-nam.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải năm</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 7: Kết luận</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-07-ket-luan/muc-01-tong-ket/01-ket-luan.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>7.1. Tổng kết</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5d98c3a5 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-a5bbad30><div class="content" data-v-a5bbad30><div class="outline-marker" data-v-a5bbad30></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a5bbad30>Mục lục trang</div><ul class="VPDocOutlineItem root" data-v-a5bbad30 data-v-b933a997><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _sen_doc_assets_images_xview2_image-sources" data-v-39a288b8><div><h1 id="xview2-xbd-dataset-image-sources-documentation" tabindex="-1">xView2/xBD Dataset Image Sources &amp; Documentation <a class="header-anchor" href="#xview2-xbd-dataset-image-sources-documentation" aria-label="Permalink to &quot;xView2/xBD Dataset Image Sources &amp; Documentation&quot;">​</a></h1><p>Research conducted: 2025-12-19</p><h2 id="overview" tabindex="-1">Overview <a class="header-anchor" href="#overview" aria-label="Permalink to &quot;Overview&quot;">​</a></h2><p>The xView2 Challenge dataset (xBD - xView Building Damage) contains satellite imagery before and after natural disasters with building damage classification. This document catalogs image sources, visualization resources, and download locations.</p><hr><h2 id="primary-research-papers-figures" tabindex="-1">Primary Research Papers &amp; Figures <a class="header-anchor" href="#primary-research-papers-figures" aria-label="Permalink to &quot;Primary Research Papers &amp; Figures&quot;">​</a></h2><h3 id="_1-cvpr-2019-paper-creating-xbd-a-dataset-for-assessing-building-damage-from-satellite-imagery" tabindex="-1">1. CVPR 2019 Paper: &quot;Creating xBD: A Dataset for Assessing Building Damage from Satellite Imagery&quot; <a class="header-anchor" href="#_1-cvpr-2019-paper-creating-xbd-a-dataset-for-assessing-building-damage-from-satellite-imagery" aria-label="Permalink to &quot;1. CVPR 2019 Paper: &quot;Creating xBD: A Dataset for Assessing Building Damage from Satellite Imagery&quot;&quot;">​</a></h3><p><strong>Paper Details</strong></p><ul><li>Authors: Ritwik Gupta, Bryce Goodman, Nirav Patel, Ricky Hosfelt, Sandra Sajeev, Eric Heim, Jigar Doshi, Keane Lucas, Howie Choset, Matthew Gaston</li><li>Published: CVPR 2019 Workshops (cv4gc)</li><li>Date: November 21, 2019</li></ul><p><strong>Available Formats</strong></p><table tabindex="0"><thead><tr><th>Format</th><th>URL</th><th>License</th></tr></thead><tbody><tr><td>PDF (Direct)</td><td><a href="https://arxiv.org/pdf/1911.09296" target="_blank" rel="noreferrer">https://arxiv.org/pdf/1911.09296</a></td><td>arXiv Open Access</td></tr><tr><td>PDF (CVF)</td><td><a href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/cv4gc/Gupta_Creating_xBD_A_Dataset_for_Assessing_Building_Damage_from_Satellite_CVPRW_2019_paper.pdf" target="_blank" rel="noreferrer">https://openaccess.thecvf.com/content_CVPRW_2019/papers/cv4gc/Gupta_Creating_xBD_A_Dataset_for_Assessing_Building_Damage_from_Satellite_CVPRW_2019_paper.pdf</a></td><td>Open Access</td></tr><tr><td>HTML (ar5iv)</td><td><a href="https://ar5iv.labs.arxiv.org/html/1911.09296" target="_blank" rel="noreferrer">https://ar5iv.labs.arxiv.org/html/1911.09296</a></td><td>Open Access</td></tr><tr><td>HTML (CVF)</td><td><a href="https://openaccess.thecvf.com/content_CVPRW_2019/html/cv4gc/Gupta_Creating_xBD_A_Dataset_for_Assessing_Building_Damage_from_Satellite_CVPRW_2019_paper.html" target="_blank" rel="noreferrer">https://openaccess.thecvf.com/content_CVPRW_2019/html/cv4gc/Gupta_Creating_xBD_A_Dataset_for_Assessing_Building_Damage_from_Satellite_CVPRW_2019_paper.html</a></td><td>Open Access</td></tr></tbody></table><p><strong>Paper Contains</strong></p><ul><li>Figure 1: Example disaster events (Hurricane Harvey, Palu Tsunami, Mexico City Earthquake, Santa Rosa Fire)</li><li>Figure 2: Pre- and post-disaster satellite imagery pairs (4 events)</li><li>Figure 3: Geographic distribution map - disaster types and locations worldwide</li><li>Figure 4: Joint Damage Scale classification descriptions (0-3 scale)</li><li>Figure 5: Building polygon annotations on pre-disaster imagery</li><li>Figure 6: Area coverage distribution across disasters</li><li>Figure 7: Positive vs. negative imagery counts by disaster</li><li>Figure 8: Building polygon density per disaster event</li><li>Figure 9: Damage classification label distribution (heavily imbalanced - 8x more &quot;no damage&quot;)</li><li>Figure 10: Baseline classification model architecture diagram</li></ul><p><strong>Image Accessibility</strong>: Figures embedded in PDF/HTML. Use ar5iv HTML version for responsive viewing.</p><hr><h2 id="official-dataset-source" tabindex="-1">Official Dataset Source <a class="header-anchor" href="#official-dataset-source" aria-label="Permalink to &quot;Official Dataset Source&quot;">​</a></h2><h3 id="xview2-challenge-website" tabindex="-1">xView2 Challenge Website <a class="header-anchor" href="#xview2-challenge-website" aria-label="Permalink to &quot;xView2 Challenge Website&quot;">​</a></h3><p><strong>Main URL</strong>: <a href="https://xview2.org/" target="_blank" rel="noreferrer">https://xview2.org/</a></p><p><strong>Dataset Page</strong>: <a href="https://xview2.org/dataset" target="_blank" rel="noreferrer">https://xview2.org/dataset</a></p><p><strong>Status</strong>: Official repository (requires JavaScript, registration for download)</p><p><strong>Dataset Contents</strong></p><ul><li>22,068 satellite images at 1024×1024 resolution</li><li>11,034 pre/post-disaster image pairs</li><li>850,736 annotated building polygons</li><li>Coverage: 45,362 km² across 15 countries</li><li>19 natural disasters, 6 disaster types</li><li>Ground sampling distance (GSD): &lt;0.8 meters</li><li>Source: Maxar/DigitalGlobe Open Data Program</li></ul><p><strong>Download Requirements</strong></p><ul><li>Registration required</li><li>~10 GB compressed, ~11 GB uncompressed</li><li>Two training tiers: Tier 1 (2,799 pairs) + Tier 3 (5,600 pairs) = 8,399 total</li><li>Test set: 933 image pairs</li></ul><p><strong>Disaster Types Included</strong></p><table tabindex="0"><thead><tr><th>Disaster Type</th><th>Count</th><th>Examples</th></tr></thead><tbody><tr><td>Earthquake/Tsunami</td><td>4</td><td>Palu Tsunami, Mexico Earthquake, Lombok Earthquake, Sulawesi Tsunami</td></tr><tr><td>Wildfire</td><td>3</td><td>Santa Rosa Fire, Socal Fire, Pinery Bushfire</td></tr><tr><td>Flooding</td><td>2</td><td>Midwest Flooding, Nepal Flooding, India Monsoon</td></tr><tr><td>Volcanic Eruption</td><td>1</td><td>Guatemala Volcano, Lower Puna Eruption</td></tr><tr><td>Wind/Hurricane</td><td>5</td><td>Hurricane Harvey, Hurricane Florence, Hurricane Michael, Hurricane Matthew, Joplin Tornado</td></tr><tr><td>Landslide/Other</td><td>4</td><td>Additional events</td></tr></tbody></table><hr><h2 id="satellite-image-metadata" tabindex="-1">Satellite Image Metadata <a class="header-anchor" href="#satellite-image-metadata" aria-label="Permalink to &quot;Satellite Image Metadata&quot;">​</a></h2><p><strong>Imagery Source</strong>: Maxar/DigitalGlobe Open Data Program</p><ul><li>URL: <a href="https://www.digitalglobe.com/ecosystem/open-data" target="_blank" rel="noreferrer">https://www.digitalglobe.com/ecosystem/open-data</a></li><li>License: Various (check individual event availability)</li><li>Sensors: Multiple high-resolution optical satellites</li><li>Resolution: ~0.3-0.8 meters GSD</li></ul><p><strong>Image Specifications</strong></p><ul><li>Format: PNG, RGB (3-channel)</li><li>Resolution: 1024×1024 pixels</li><li>Color Depth: 24-bit RGB</li><li>Off-nadir angles: Variable (realistic satellite acquisition)</li><li>Sun elevation angles: Variable</li></ul><p><strong>Annotation Format</strong></p><ul><li>Building polygons in WKT notation</li><li>Damage labels: 0 (no damage), 1 (minor), 2 (major), 3 (destroyed)</li><li>Additional labels: fire, water, smoke, lava (environmental factors)</li><li>Georeferencing metadata included</li></ul><hr><h2 id="damage-classification-scale" tabindex="-1">Damage Classification Scale <a class="header-anchor" href="#damage-classification-scale" aria-label="Permalink to &quot;Damage Classification Scale&quot;">​</a></h2><h3 id="joint-damage-scale-4-level-ordinal-system" tabindex="-1">Joint Damage Scale (4-Level Ordinal System) <a class="header-anchor" href="#joint-damage-scale-4-level-ordinal-system" aria-label="Permalink to &quot;Joint Damage Scale (4-Level Ordinal System)&quot;">​</a></h3><p><strong>Color Scheme</strong> (standard visualization)</p><table tabindex="0"><thead><tr><th>Level</th><th>Value</th><th>Color</th><th>Description</th></tr></thead><tbody><tr><td>No Damage</td><td>0</td><td>Green</td><td>Undisturbed, no structural damage, no burn marks</td></tr><tr><td>Minor Damage</td><td>1</td><td>Blue</td><td>Partial burns, water surrounding, roof elements missing, visible cracks</td></tr><tr><td>Major Damage</td><td>2</td><td>Orange</td><td>Partial wall/roof collapse, significant damage encroaching</td></tr><tr><td>Destroyed</td><td>3</td><td>Red</td><td>Complete collapse, structure uninhabitable</td></tr></tbody></table><p><strong>Label Distribution in xBD</strong></p><ul><li>No Damage: 313,033 polygons (84%)</li><li>Minor Damage: 36,860 polygons (5%)</li><li>Major Damage: 29,904 polygons (4%)</li><li>Destroyed: 31,560 polygons (4%)</li><li>Unclassified: 14,011 polygons (3%)</li><li><strong>Imbalance Challenge</strong>: 8x more &quot;no damage&quot; than other categories</li></ul><hr><h2 id="alternative-access-points-mirrors" tabindex="-1">Alternative Access Points &amp; Mirrors <a class="header-anchor" href="#alternative-access-points-mirrors" aria-label="Permalink to &quot;Alternative Access Points &amp; Mirrors&quot;">​</a></h2><h3 id="_1-hugging-face" tabindex="-1">1. Hugging Face <a class="header-anchor" href="#_1-hugging-face" aria-label="Permalink to &quot;1. Hugging Face&quot;">​</a></h3><p><strong>URL</strong>: <a href="https://huggingface.co/datasets/danielz01/xView2" target="_blank" rel="noreferrer">https://huggingface.co/datasets/danielz01/xView2</a></p><ul><li>Creator: Chenhui Zhang (@danielz01)</li><li>Access: Requires login + accept terms and conditions</li><li>Status: ~104 monthly downloads</li><li>Format: Parquet</li><li>Size: 1K-10K entries</li></ul><h3 id="_2-roboflow-universe" tabindex="-1">2. Roboflow Universe <a class="header-anchor" href="#_2-roboflow-universe" aria-label="Permalink to &quot;2. Roboflow Universe&quot;">​</a></h3><p><strong>URL</strong>: <a href="https://universe.roboflow.com/ozu/xview2" target="_blank" rel="noreferrer">https://universe.roboflow.com/ozu/xview2</a></p><ul><li>Status: Public preview available</li><li>Sample Size: 520 open-source images</li><li>Classes: undamaged, minor-damage, major-damage, destroyed</li><li>License: CC BY 4.0</li><li>Includes: Pre-trained XView2 model + API</li></ul><h3 id="_3-kaggle" tabindex="-1">3. Kaggle <a class="header-anchor" href="#_3-kaggle" aria-label="Permalink to &quot;3. Kaggle&quot;">​</a></h3><ul><li>Searchable via Kaggle dataset exploration</li><li>May contain community kernels and subsets</li><li>Useful for quick experimentation</li></ul><h3 id="_4-torchgeo-library" tabindex="-1">4. TorchGeo Library <a class="header-anchor" href="#_4-torchgeo-library" aria-label="Permalink to &quot;4. TorchGeo Library&quot;">​</a></h3><p><strong>URL</strong>: <a href="https://torchgeo.readthedocs.io/" target="_blank" rel="noreferrer">https://torchgeo.readthedocs.io/</a></p><ul><li>Python library for geospatial deep learning</li><li>Includes xView2 dataset loader</li><li>Challenge training set: ~7.8 GB</li><li>Challenge test set: ~2.6 GB</li></ul><h3 id="_5-earth-observation-database" tabindex="-1">5. Earth Observation Database <a class="header-anchor" href="#_5-earth-observation-database" aria-label="Permalink to &quot;5. Earth Observation Database&quot;">​</a></h3><p><strong>URL</strong>: <a href="https://eod-grss-ieee.com/dataset-detail/MHpyVXNmV0dxaEtWWVBaNzlpckJPUT09" target="_blank" rel="noreferrer">https://eod-grss-ieee.com/dataset-detail/MHpyVXNmV0dxaEtWWVBaNzlpckJPUT09</a></p><ul><li>Metadata and index: xBD (xView2)</li></ul><hr><h2 id="baseline-reference-implementations" tabindex="-1">Baseline &amp; Reference Implementations <a class="header-anchor" href="#baseline-reference-implementations" aria-label="Permalink to &quot;Baseline &amp; Reference Implementations&quot;">​</a></h2><h3 id="official-baseline-repository" tabindex="-1">Official Baseline Repository <a class="header-anchor" href="#official-baseline-repository" aria-label="Permalink to &quot;Official Baseline Repository&quot;">​</a></h3><p><strong>GitHub</strong>: <a href="https://github.com/DIUx-xView/xView2_baseline" target="_blank" rel="noreferrer">https://github.com/DIUx-xView/xView2_baseline</a></p><ul><li>Language: Python 3.6+</li><li>Architecture: U-Net for localization, ResNet50 for classification</li><li>Authors: CMU SEI</li><li>Includes: Data preparation, training, inference scripts</li><li>License: Check repository</li></ul><p><strong>Output Specification</strong></p><ul><li>Grayscale PNG format</li><li>Pixel values: 0-4 (no building, no damage, minor, major, destroyed)</li></ul><h3 id="top-challenge-solutions" tabindex="-1">Top Challenge Solutions <a class="header-anchor" href="#top-challenge-solutions" aria-label="Permalink to &quot;Top Challenge Solutions&quot;">​</a></h3><ul><li><p><strong>1st Place</strong>: <a href="https://github.com/DIUx-xView/xView2_first_place" target="_blank" rel="noreferrer">https://github.com/DIUx-xView/xView2_first_place</a></p><ul><li>Siamese Neural Networks</li><li>Full image (1024×1024) inference with 4 TTA</li></ul></li><li><p><strong>2nd Place</strong>: <a href="https://github.com/ethanweber/xview2" target="_blank" rel="noreferrer">https://github.com/ethanweber/xview2</a></p><ul><li>Detectron2-based (Facebook)</li><li>Multi-temporal fusion</li></ul></li><li><p><strong>Visualization Tool</strong>: ethanweber/xview2 includes notebook for visualizing predictions</p></li></ul><h3 id="toolkit-utilities" tabindex="-1">Toolkit &amp; Utilities <a class="header-anchor" href="#toolkit-utilities" aria-label="Permalink to &quot;Toolkit &amp; Utilities&quot;">​</a></h3><ul><li><strong>xview2-toolkit</strong>: <a href="https://github.com/ashnair1/xview2-toolkit" target="_blank" rel="noreferrer">https://github.com/ashnair1/xview2-toolkit</a><ul><li>Annotation visualization</li><li>MS-COCO format conversion</li><li>Segmentation map generation</li></ul></li></ul><hr><h2 id="related-papers-research" tabindex="-1">Related Papers &amp; Research <a class="header-anchor" href="#related-papers-research" aria-label="Permalink to &quot;Related Papers &amp; Research&quot;">​</a></h2><h3 id="extended-works" tabindex="-1">Extended Works <a class="header-anchor" href="#extended-works" aria-label="Permalink to &quot;Extended Works&quot;">​</a></h3><ol><li><p><strong>[2212.13876] xFBD: Focused Building Damage Dataset and Analysis</strong></p><ul><li>URL: <a href="https://arxiv.org/pdf/2212.13876" target="_blank" rel="noreferrer">https://arxiv.org/pdf/2212.13876</a></li><li>Focused subset with different methodology</li></ul></li><li><p><strong>[2405.04800v1] DeepDamageNet</strong></p><ul><li>URL: <a href="https://arxiv.org/html/2405.04800v1" target="_blank" rel="noreferrer">https://arxiv.org/html/2405.04800v1</a></li><li>Two-step model for multi-disaster assessment</li></ul></li><li><p><strong>Building Damage Assessment Papers</strong></p><ul><li>ScienceDirect: <a href="https://www.sciencedirect.com/science/article/abs/pii/S0034425721003564" target="_blank" rel="noreferrer">https://www.sciencedirect.com/science/article/abs/pii/S0034425721003564</a></li><li>Taylor &amp; Francis: <a href="https://www.tandfonline.com/doi/full/10.1080/17538947.2024.2302577" target="_blank" rel="noreferrer">https://www.tandfonline.com/doi/full/10.1080/17538947.2024.2302577</a></li></ul></li></ol><h3 id="benchmark-collections" tabindex="-1">Benchmark Collections <a class="header-anchor" href="#benchmark-collections" aria-label="Permalink to &quot;Benchmark Collections&quot;">​</a></h3><ul><li><strong>Satellite Image Deep Learning Datasets</strong>: <a href="https://github.com/satellite-image-deep-learning/datasets" target="_blank" rel="noreferrer">https://github.com/satellite-image-deep-learning/datasets</a></li><li><strong>NAD Benchmarks</strong>: <a href="https://roc-hci.github.io/NADBenchmarks/" target="_blank" rel="noreferrer">https://roc-hci.github.io/NADBenchmarks/</a></li></ul><hr><h2 id="dataset-statistics-insights" tabindex="-1">Dataset Statistics &amp; Insights <a class="header-anchor" href="#dataset-statistics-insights" aria-label="Permalink to &quot;Dataset Statistics &amp; Insights&quot;">​</a></h2><h3 id="coverage-by-disaster" tabindex="-1">Coverage by Disaster <a class="header-anchor" href="#coverage-by-disaster" aria-label="Permalink to &quot;Coverage by Disaster&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Event</th><th>Region</th><th>Type</th><th>Coverage</th><th>Building Count</th></tr></thead><tbody><tr><td>Hurricane Harvey</td><td>Houston, TX</td><td>Wind</td><td>~8000 km²</td><td>100,000+</td></tr><tr><td>Palu Tsunami</td><td>Indonesia</td><td>Tsunami</td><td>&lt;1000 km²</td><td>100,000+</td></tr><tr><td>Mexico Earthquake</td><td>Mexico City</td><td>Earthquake</td><td>&lt;1000 km²</td><td>100,000+</td></tr><tr><td>Pinery Bushfire</td><td>Australia</td><td>Fire</td><td>~8000 km²</td><td>Large</td></tr></tbody></table><h3 id="model-performance-baseline" tabindex="-1">Model Performance Baseline <a class="header-anchor" href="#model-performance-baseline" aria-label="Permalink to &quot;Model Performance Baseline&quot;">​</a></h3><ul><li>Localization F1 (U-Net): 0.80</li><li>Localization IoU: 0.66</li><li>Classification F1 (ResNet50): Varies by damage class</li><li>Combined F1 (weighted): ~0.71 (IBM approach)</li></ul><h3 id="challenge-application" tabindex="-1">Challenge Application <a class="header-anchor" href="#challenge-application" aria-label="Permalink to &quot;Challenge Application&quot;">​</a></h3><ul><li>Real-world use: California wildfire damage assessment</li><li>Processing time: 10-20 minutes per large area (vs 1-2 days manual)</li><li>Deployed by: California National Guard</li></ul><hr><h2 id="image-download-instructions" tabindex="-1">Image Download Instructions <a class="header-anchor" href="#image-download-instructions" aria-label="Permalink to &quot;Image Download Instructions&quot;">​</a></h2><h3 id="method-1-official-xview2-portal" tabindex="-1">Method 1: Official xView2 Portal <a class="header-anchor" href="#method-1-official-xview2-portal" aria-label="Permalink to &quot;Method 1: Official xView2 Portal&quot;">​</a></h3><ol><li>Navigate to <a href="https://xview2.org/dataset" target="_blank" rel="noreferrer">https://xview2.org/dataset</a></li><li>Create account and login</li><li>Accept challenge terms</li><li>Download data (10 GB compressed)</li><li>Extract to working directory</li></ol><h3 id="method-2-maxar-open-data-stac" tabindex="-1">Method 2: Maxar Open Data STAC <a class="header-anchor" href="#method-2-maxar-open-data-stac" aria-label="Permalink to &quot;Method 2: Maxar Open Data STAC&quot;">​</a></h3><ol><li>Access STAC catalog: <a href="https://maxar-opendata.s3.amazonaws.com/events/catalog.json" target="_blank" rel="noreferrer">https://maxar-opendata.s3.amazonaws.com/events/catalog.json</a></li><li>Use GIS tools or STAC client to fetch individual events</li><li>Filter by disaster event</li><li>Download GeoTIFF or COG format</li></ol><h3 id="method-3-roboflow-quick-start" tabindex="-1">Method 3: Roboflow (Quick Start) <a class="header-anchor" href="#method-3-roboflow-quick-start" aria-label="Permalink to &quot;Method 3: Roboflow (Quick Start)&quot;">​</a></h3><ol><li>Visit <a href="https://universe.roboflow.com/ozu/xview2" target="_blank" rel="noreferrer">https://universe.roboflow.com/ozu/xview2</a></li><li>Browse 520 sample images</li><li>Download with API key for programmatic access</li></ol><h3 id="method-4-torchgeo-python" tabindex="-1">Method 4: TorchGeo (Python) <a class="header-anchor" href="#method-4-torchgeo-python" aria-label="Permalink to &quot;Method 4: TorchGeo (Python)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torchgeo.datasets </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> XView2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">dataset </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> XView2(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">root</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;path/to/data&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">download</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h3 id="method-5-hugging-face-python" tabindex="-1">Method 5: Hugging Face (Python) <a class="header-anchor" href="#method-5-hugging-face-python" aria-label="Permalink to &quot;Method 5: Hugging Face (Python)&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> datasets </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> load_dataset</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ds </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> load_dataset(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;danielz01/xView2&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Requires login/acceptance</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><hr><h2 id="image-licensing-attribution" tabindex="-1">Image Licensing &amp; Attribution <a class="header-anchor" href="#image-licensing-attribution" aria-label="Permalink to &quot;Image Licensing &amp; Attribution&quot;">​</a></h2><h3 id="satellite-imagery" tabindex="-1">Satellite Imagery <a class="header-anchor" href="#satellite-imagery" aria-label="Permalink to &quot;Satellite Imagery&quot;">​</a></h3><ul><li><strong>Source</strong>: Maxar/DigitalGlobe Open Data Program</li><li><strong>License</strong>: Varies per event (typically public domain for crisis events)</li><li><strong>Attribution</strong>: DigitalGlobe/Maxar required</li><li><strong>Terms</strong>: Check specific event in Open Data Program catalog</li></ul><h3 id="dataset-annotations" tabindex="-1">Dataset Annotations <a class="header-anchor" href="#dataset-annotations" aria-label="Permalink to &quot;Dataset Annotations&quot;">​</a></h3><ul><li><strong>License</strong>: Creative Commons (varies by version)</li><li><strong>Citation</strong>: Gupta, R., et al. (2019). &quot;Creating xBD: A Dataset for Assessing Building Damage from Satellite Imagery&quot;</li><li><strong>Challenge Data</strong>: xView2 Challenge terms apply</li></ul><h3 id="research-use" tabindex="-1">Research Use <a class="header-anchor" href="#research-use" aria-label="Permalink to &quot;Research Use&quot;">​</a></h3><ul><li><strong>Academic</strong>: Permitted with attribution</li><li><strong>Commercial</strong>: Check licensing terms before deployment</li><li><strong>Redistribution</strong>: Allowed under CC BY 4.0 (Roboflow subset)</li></ul><hr><h2 id="format-specifications" tabindex="-1">Format Specifications <a class="header-anchor" href="#format-specifications" aria-label="Permalink to &quot;Format Specifications&quot;">​</a></h2><h3 id="pre-disaster-post-disaster-images" tabindex="-1">Pre-Disaster &amp; Post-Disaster Images <a class="header-anchor" href="#pre-disaster-post-disaster-images" aria-label="Permalink to &quot;Pre-Disaster &amp; Post-Disaster Images&quot;">​</a></h3><ul><li><strong>Container</strong>: PNG or GeoTIFF</li><li><strong>Bands</strong>: RGB (3 channels)</li><li><strong>Resolution</strong>: 1024×1024 pixels</li><li><strong>Bit Depth</strong>: 8-bit per channel</li><li><strong>Color Space</strong>: sRGB</li></ul><h3 id="ground-truth-annotations" tabindex="-1">Ground Truth Annotations <a class="header-anchor" href="#ground-truth-annotations" aria-label="Permalink to &quot;Ground Truth Annotations&quot;">​</a></h3><ul><li><strong>Format</strong>: JSON (polygon vertices) + CSV (damage labels)</li><li><strong>Polygon Notation</strong>: WKT (Well-Known Text)</li><li><strong>Damage Values</strong>: 0-3 (ordinal scale)</li><li><strong>Metadata</strong>: Georeferencing, sensor info, timestamp</li></ul><h3 id="output-format-predictions" tabindex="-1">Output Format (Predictions) <a class="header-anchor" href="#output-format-predictions" aria-label="Permalink to &quot;Output Format (Predictions)&quot;">​</a></h3><ul><li><strong>Container</strong>: PNG (grayscale)</li><li><strong>Values</strong>: 0-4 (pixel-wise damage classification)</li><li><strong>Resolution</strong>: 1024×1024 pixels</li></ul><hr><h2 id="key-statistics-summary" tabindex="-1">Key Statistics Summary <a class="header-anchor" href="#key-statistics-summary" aria-label="Permalink to &quot;Key Statistics Summary&quot;">​</a></h2><table tabindex="0"><thead><tr><th>Metric</th><th>Value</th></tr></thead><tbody><tr><td>Total Images</td><td>22,068</td></tr><tr><td>Image Pairs</td><td>11,034</td></tr><tr><td>Building Polygons</td><td>850,736</td></tr><tr><td>Geographic Coverage</td><td>45,362 km²</td></tr><tr><td>Countries</td><td>15+</td></tr><tr><td>Disaster Events</td><td>19</td></tr><tr><td>Disaster Types</td><td>6</td></tr><tr><td>GSD (Resolution)</td><td>&lt;0.8 meters</td></tr><tr><td>Image Size</td><td>1024×1024 pixels</td></tr><tr><td>Color Format</td><td>RGB (24-bit)</td></tr><tr><td>Damage Classes</td><td>4 levels (0-3)</td></tr><tr><td>Download Size</td><td>~10 GB (compressed), ~11 GB (uncompressed)</td></tr><tr><td>Training Pairs</td><td>8,399 (Tier1 + Tier3)</td></tr><tr><td>Test Pairs</td><td>933</td></tr></tbody></table><hr><h2 id="recommended-citation" tabindex="-1">Recommended Citation <a class="header-anchor" href="#recommended-citation" aria-label="Permalink to &quot;Recommended Citation&quot;">​</a></h2><div class="language-bibtex vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">bibtex</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">@inproceedings</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">gupta2019xbd</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  title</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Creating xBD: A Dataset for Assessing Building Damage from Satellite Imagery</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  author</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Gupta, Ritwik and Goodman, Bryce and Patel, Nirav and Hosfelt, Ricky and Sajeev, Sandra and Heim, Eric and Doshi, Jigar and Lucas, Keane and Choset, Howie and Gaston, Matthew</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  booktitle</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  pages</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">18--26</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  year</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">2019</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">}</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><hr><h2 id="important-notes" tabindex="-1">Important Notes <a class="header-anchor" href="#important-notes" aria-label="Permalink to &quot;Important Notes&quot;">​</a></h2><h3 id="data-imbalance" tabindex="-1">Data Imbalance <a class="header-anchor" href="#data-imbalance" aria-label="Permalink to &quot;Data Imbalance&quot;">​</a></h3><ul><li>&quot;No damage&quot; class heavily overrepresented (84% of labels)</li><li>Imbalance factor: ~8x more &quot;no damage&quot; than other classes</li><li>Poses challenge for class-balanced training</li></ul><h3 id="visual-similarity-challenge" tabindex="-1">Visual Similarity Challenge <a class="header-anchor" href="#visual-similarity-challenge" aria-label="Permalink to &quot;Visual Similarity Challenge&quot;">​</a></h3><ul><li>Minor vs. major damage can have subtle visual differences</li><li>Models often confuse adjacent damage classes</li><li>Joint Damage Scale designed as practical trade-off</li></ul><h3 id="real-world-application" tabindex="-1">Real-World Application <a class="header-anchor" href="#real-world-application" aria-label="Permalink to &quot;Real-World Application&quot;">​</a></h3><ul><li>Successfully used by California National Guard for wildfire assessment</li><li>Demonstrated 10-20 minute assessment vs. 1-2 days manual analysis</li><li>High-impact humanitarian/disaster response tool</li></ul><h3 id="access-limitations" tabindex="-1">Access Limitations <a class="header-anchor" href="#access-limitations" aria-label="Permalink to &quot;Access Limitations&quot;">​</a></h3><ul><li>Full dataset requires registration at xView2.org</li><li>Some mirrors/subsets publicly available (Roboflow, HuggingFace)</li><li>Roboflow subset (520 images) under CC BY 4.0 license</li></ul><hr><h2 id="unresolved-questions" tabindex="-1">Unresolved Questions <a class="header-anchor" href="#unresolved-questions" aria-label="Permalink to &quot;Unresolved Questions&quot;">​</a></h2><ol><li><strong>Exact GSD by Event</strong>: Paper states &quot;&lt;0.8 meters&quot; GSD but specific resolution per disaster varies</li><li><strong>Sensor Specifications</strong>: Which satellites exactly? (Likely DigitalGlobe WorldView series, specifics not documented)</li><li><strong>Temporal Gap</strong>: Exact time between pre- and post-disaster capture not always specified</li><li><strong>Quality Assurance</strong>: Annotation inter-rater agreement / QA metrics not provided in CVPR paper</li><li><strong>Update Frequency</strong>: Whether new disasters have been added to dataset post-2019</li><li><strong>Raw Image URLs</strong>: Specific CDN/S3 paths for individual images not publicly listed (must download via portal)</li></ol><hr><h2 id="last-updated" tabindex="-1">Last Updated <a class="header-anchor" href="#last-updated" aria-label="Permalink to &quot;Last Updated&quot;">​</a></h2><p>Research Date: 2025-12-19</p><p>All URLs verified as active at time of documentation. Note that websites and data availability may change.</p></div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-e257564d><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><!----></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/sen_doc/chuong-01-gioi-thieu/muc-01-tong-quan/01-gioi-thieu-cnn-deep-learning.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Trang sau</span><span class="title" data-v-e257564d>1.1. Tổng quan CNN & Deep Learning</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5d98c3a5 data-v-e315a0ad><div class="container" data-v-e315a0ad><p class="message" data-v-e315a0ad>Nghiên cứu Ứng dụng Deep Learning trong Viễn thám</p><p class="copyright" data-v-e315a0ad>2024</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"assets_images_xview1_image-sources.md\":\"ckCsuNuZ\",\"assets_images_xview1_readme.md\":\"Dh-ZirnL\",\"assets_images_xview2_download-guide.md\":\"CoBf_73u\",\"assets_images_xview2_image-reference-catalog.md\":\"BygTyrM0\",\"assets_images_xview2_image-sources.md\":\"DuMc8EPf\",\"assets_images_xview2_readme.md\":\"BxXava9o\",\"assets_images_xview3_image-sources.md\":\"BniOX9bd\",\"chuong-01-gioi-thieu_muc-01-tong-quan_01-gioi-thieu-cnn-deep-learning.md\":\"Bd-Fbg20\",\"chuong-02-co-so-ly-thuyet_muc-01-kien-truc-cnn_01-kien-truc-co-ban.md\":\"JTkuWTE-\",\"chuong-02-co-so-ly-thuyet_muc-01-kien-truc-cnn_02-backbone-networks.md\":\"BlX0yEKA\",\"chuong-02-co-so-ly-thuyet_muc-02-phuong-phap-xu-ly-anh_01-phan-loai-anh.md\":\"DETt3o-M\",\"chuong-02-co-so-ly-thuyet_muc-02-phuong-phap-xu-ly-anh_02-phat-hien-doi-tuong.md\":\"GmKUOhbb\",\"chuong-02-co-so-ly-thuyet_muc-02-phuong-phap-xu-ly-anh_03-phan-doan-ngu-nghia.md\":\"CcH_kyR9\",\"chuong-02-co-so-ly-thuyet_muc-02-phuong-phap-xu-ly-anh_04-instance-segmentation.md\":\"TtJykzVA\",\"chuong-03-phat-hien-tau-bien_muc-01-dac-diem-bai-toan_01-dac-diem.md\":\"C0Yxv2n_\",\"chuong-03-phat-hien-tau-bien_muc-02-mo-hinh_01-cac-mo-hinh.md\":\"DGRPnXI5\",\"chuong-03-phat-hien-tau-bien_muc-03-quy-trinh_01-pipeline.md\":\"CyQavZag\",\"chuong-03-phat-hien-tau-bien_muc-04-bo-du-lieu_01-datasets.md\":\"B-r7bzJa\",\"chuong-04-phat-hien-dau-loang_muc-01-dac-diem-bai-toan_01-dac-diem.md\":\"DoL0XU6F\",\"chuong-04-phat-hien-dau-loang_muc-02-mo-hinh_01-cac-mo-hinh.md\":\"BDt_W34a\",\"chuong-04-phat-hien-dau-loang_muc-03-quy-trinh_01-pipeline.md\":\"CFhAxDR2\",\"chuong-04-phat-hien-dau-loang_muc-04-bo-du-lieu_01-datasets.md\":\"B0YdiGB0\",\"chuong-05-torchgeo_muc-01-tong-quan_01-tong-quan.md\":\"BoDJs4WI\",\"chuong-05-torchgeo_muc-02-classification_01-classification-models.md\":\"CzG4Fvsd\",\"chuong-05-torchgeo_muc-03-segmentation_01-segmentation-models.md\":\"BI9c1b3a\",\"chuong-05-torchgeo_muc-04-change-detection_01-change-detection-models.md\":\"AY_JAMod\",\"chuong-05-torchgeo_muc-05-pretrained-weights_01-pretrained-weights.md\":\"BuNGhnCB\",\"chuong-06-xview-challenges_muc-01-xview1-object-detection_01-dataset.md\":\"Dm7BptPM\",\"chuong-06-xview-challenges_muc-01-xview1-object-detection_02-giai-nhat.md\":\"2wV3PEsV\",\"chuong-06-xview-challenges_muc-01-xview1-object-detection_03-giai-nhi.md\":\"BufeTIgD\",\"chuong-06-xview-challenges_muc-01-xview1-object-detection_04-giai-ba.md\":\"BB8ENdVV\",\"chuong-06-xview-challenges_muc-01-xview1-object-detection_05-giai-tu.md\":\"BeVPeWzd\",\"chuong-06-xview-challenges_muc-01-xview1-object-detection_06-giai-nam.md\":\"BODlexDn\",\"chuong-06-xview-challenges_muc-02-xview2-building-damage_01-dataset.md\":\"D4Zdh38-\",\"chuong-06-xview-challenges_muc-02-xview2-building-damage_02-giai-nhat.md\":\"DmTBWgjK\",\"chuong-06-xview-challenges_muc-02-xview2-building-damage_03-giai-nhi.md\":\"BW-aVCBj\",\"chuong-06-xview-challenges_muc-02-xview2-building-damage_04-giai-ba.md\":\"C82xwoJR\",\"chuong-06-xview-challenges_muc-02-xview2-building-damage_05-giai-tu.md\":\"_cJqRaka\",\"chuong-06-xview-challenges_muc-02-xview2-building-damage_06-giai-nam.md\":\"B4Yzptuh\",\"chuong-06-xview-challenges_muc-03-xview3-maritime_01-dataset.md\":\"DteeNegR\",\"chuong-06-xview-challenges_muc-03-xview3-maritime_02-giai-nhat.md\":\"DNNZ5ArH\",\"chuong-06-xview-challenges_muc-03-xview3-maritime_03-giai-nhi.md\":\"DXfAO9PE\",\"chuong-06-xview-challenges_muc-03-xview3-maritime_04-giai-ba.md\":\"B_Gh3WW0\",\"chuong-06-xview-challenges_muc-03-xview3-maritime_05-giai-tu.md\":\"CSu3Wob_\",\"chuong-06-xview-challenges_muc-03-xview3-maritime_06-giai-nam.md\":\"YgGqePJH\",\"chuong-07-ket-luan_muc-01-tong-ket_01-ket-luan.md\":\"CnvNs1AJ\",\"index.md\":\"I4CP-rxb\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"vi-VN\",\"dir\":\"ltr\",\"title\":\"Deep Learning trong Viễn thám\",\"description\":\"Nghiên cứu ứng dụng CNN và Deep Learning trong phân tích ảnh viễn thám\",\"base\":\"/sen_doc/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"Trang chủ\",\"link\":\"/\"},{\"text\":\"Giới thiệu\",\"link\":\"/chuong-01-gioi-thieu/muc-01-tong-quan/01-gioi-thieu-cnn-deep-learning\"},{\"text\":\"TorchGeo\",\"link\":\"/chuong-05-torchgeo/muc-01-tong-quan/01-tong-quan\"},{\"text\":\"xView\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/01-dataset\"}],\"sidebar\":[{\"text\":\"Chương 1: Giới thiệu\",\"collapsed\":false,\"items\":[{\"text\":\"1.1. Tổng quan CNN & Deep Learning\",\"link\":\"/chuong-01-gioi-thieu/muc-01-tong-quan/01-gioi-thieu-cnn-deep-learning\"}]},{\"text\":\"Chương 2: Cơ sở lý thuyết\",\"collapsed\":false,\"items\":[{\"text\":\"2.1.1. Kiến trúc CNN cơ bản\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-01-kien-truc-cnn/01-kien-truc-co-ban\"},{\"text\":\"2.1.2. Backbone Networks\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-01-kien-truc-cnn/02-backbone-networks\"},{\"text\":\"2.2.1. Phân loại ảnh\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/01-phan-loai-anh\"},{\"text\":\"2.2.2. Phát hiện đối tượng\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/02-phat-hien-doi-tuong\"},{\"text\":\"2.2.3. Phân đoạn ngữ nghĩa\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/03-phan-doan-ngu-nghia\"},{\"text\":\"2.2.4. Instance Segmentation\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/04-instance-segmentation\"}]},{\"text\":\"Chương 3: Phát hiện tàu biển\",\"collapsed\":true,\"items\":[{\"text\":\"3.1. Đặc điểm bài toán\",\"link\":\"/chuong-03-phat-hien-tau-bien/muc-01-dac-diem-bai-toan/01-dac-diem\"},{\"text\":\"3.2. Các mô hình\",\"link\":\"/chuong-03-phat-hien-tau-bien/muc-02-mo-hinh/01-cac-mo-hinh\"},{\"text\":\"3.3. Quy trình pipeline\",\"link\":\"/chuong-03-phat-hien-tau-bien/muc-03-quy-trinh/01-pipeline\"},{\"text\":\"3.4. Bộ dữ liệu\",\"link\":\"/chuong-03-phat-hien-tau-bien/muc-04-bo-du-lieu/01-datasets\"}]},{\"text\":\"Chương 4: Phát hiện dầu loang\",\"collapsed\":true,\"items\":[{\"text\":\"4.1. Đặc điểm bài toán\",\"link\":\"/chuong-04-phat-hien-dau-loang/muc-01-dac-diem-bai-toan/01-dac-diem\"},{\"text\":\"4.2. Các mô hình\",\"link\":\"/chuong-04-phat-hien-dau-loang/muc-02-mo-hinh/01-cac-mo-hinh\"},{\"text\":\"4.3. Quy trình pipeline\",\"link\":\"/chuong-04-phat-hien-dau-loang/muc-03-quy-trinh/01-pipeline\"},{\"text\":\"4.4. Bộ dữ liệu\",\"link\":\"/chuong-04-phat-hien-dau-loang/muc-04-bo-du-lieu/01-datasets\"}]},{\"text\":\"Chương 5: TorchGeo\",\"collapsed\":true,\"items\":[{\"text\":\"5.1. Tổng quan\",\"link\":\"/chuong-05-torchgeo/muc-01-tong-quan/01-tong-quan\"},{\"text\":\"5.2. Classification Models\",\"link\":\"/chuong-05-torchgeo/muc-02-classification/01-classification-models\"},{\"text\":\"5.3. Segmentation Models\",\"link\":\"/chuong-05-torchgeo/muc-03-segmentation/01-segmentation-models\"},{\"text\":\"5.4. Change Detection\",\"link\":\"/chuong-05-torchgeo/muc-04-change-detection/01-change-detection-models\"},{\"text\":\"5.5. Pre-trained Weights\",\"link\":\"/chuong-05-torchgeo/muc-05-pretrained-weights/01-pretrained-weights\"}]},{\"text\":\"Chương 6: xView Challenges\",\"collapsed\":false,\"items\":[{\"text\":\"6.1. xView1 - Object Detection\",\"collapsed\":true,\"items\":[{\"text\":\"Dataset\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/01-dataset\"},{\"text\":\"Giải nhất\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/02-giai-nhat\"},{\"text\":\"Giải nhì\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/03-giai-nhi\"},{\"text\":\"Giải ba\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/04-giai-ba\"},{\"text\":\"Giải tư\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/05-giai-tu\"},{\"text\":\"Giải năm\",\"link\":\"/chuong-06-xview-challenges/muc-01-xview1-object-detection/06-giai-nam\"}]},{\"text\":\"6.2. xView2 - Building Damage\",\"collapsed\":true,\"items\":[{\"text\":\"Dataset (xBD)\",\"link\":\"/chuong-06-xview-challenges/muc-02-xview2-building-damage/01-dataset\"},{\"text\":\"Giải nhất\",\"link\":\"/chuong-06-xview-challenges/muc-02-xview2-building-damage/02-giai-nhat\"},{\"text\":\"Giải nhì\",\"link\":\"/chuong-06-xview-challenges/muc-02-xview2-building-damage/03-giai-nhi\"},{\"text\":\"Giải ba\",\"link\":\"/chuong-06-xview-challenges/muc-02-xview2-building-damage/04-giai-ba\"},{\"text\":\"Giải tư\",\"link\":\"/chuong-06-xview-challenges/muc-02-xview2-building-damage/05-giai-tu\"},{\"text\":\"Giải năm\",\"link\":\"/chuong-06-xview-challenges/muc-02-xview2-building-damage/06-giai-nam\"}]},{\"text\":\"6.3. xView3 - Maritime (SAR)\",\"collapsed\":true,\"items\":[{\"text\":\"Dataset\",\"link\":\"/chuong-06-xview-challenges/muc-03-xview3-maritime/01-dataset\"},{\"text\":\"Giải nhất\",\"link\":\"/chuong-06-xview-challenges/muc-03-xview3-maritime/02-giai-nhat\"},{\"text\":\"Giải nhì\",\"link\":\"/chuong-06-xview-challenges/muc-03-xview3-maritime/03-giai-nhi\"},{\"text\":\"Giải ba\",\"link\":\"/chuong-06-xview-challenges/muc-03-xview3-maritime/04-giai-ba\"},{\"text\":\"Giải tư\",\"link\":\"/chuong-06-xview-challenges/muc-03-xview3-maritime/05-giai-tu\"},{\"text\":\"Giải năm\",\"link\":\"/chuong-06-xview-challenges/muc-03-xview3-maritime/06-giai-nam\"}]}]},{\"text\":\"Chương 7: Kết luận\",\"collapsed\":false,\"items\":[{\"text\":\"7.1. Tổng kết\",\"link\":\"/chuong-07-ket-luan/muc-01-tong-ket/01-ket-luan\"}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/tchatb/sen_doc\"}],\"search\":{\"provider\":\"local\"},\"outline\":{\"level\":[2,3],\"label\":\"Mục lục trang\"},\"footer\":{\"message\":\"Nghiên cứu Ứng dụng Deep Learning trong Viễn thám\",\"copyright\":\"2024\"},\"docFooter\":{\"prev\":\"Trang trước\",\"next\":\"Trang sau\"},\"lastUpdated\":{\"text\":\"Cập nhật lần cuối\"},\"returnToTopLabel\":\"Về đầu trang\",\"sidebarMenuLabel\":\"Menu\",\"darkModeSwitchLabel\":\"Giao diện\"},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>