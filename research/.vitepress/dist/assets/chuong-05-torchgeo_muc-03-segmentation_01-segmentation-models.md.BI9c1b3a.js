import{_ as a,c as t,o as n,a2 as i}from"./chunks/framework.nRfFlDZQ.js";const g=JSON.parse('{"title":"Chương 5: Segmentation Models trong TorchGeo","description":"","frontmatter":{},"headers":[],"relativePath":"chuong-05-torchgeo/muc-03-segmentation/01-segmentation-models.md","filePath":"chuong-05-torchgeo/muc-03-segmentation/01-segmentation-models.md","lastUpdated":null}'),s={name:"chuong-05-torchgeo/muc-03-segmentation/01-segmentation-models.md"};function l(r,e,o,d,p,c){return n(),t("div",null,[...e[0]||(e[0]=[i(`<h1 id="chuong-5-segmentation-models-trong-torchgeo" tabindex="-1">Chương 5: Segmentation Models trong TorchGeo <a class="header-anchor" href="#chuong-5-segmentation-models-trong-torchgeo" aria-label="Permalink to &quot;Chương 5: Segmentation Models trong TorchGeo&quot;">​</a></h1><h2 id="_6-20-tong-quan-segmentation-trong-torchgeo" tabindex="-1">6.20. Tổng quan Segmentation trong TorchGeo <a class="header-anchor" href="#_6-20-tong-quan-segmentation-trong-torchgeo" aria-label="Permalink to &quot;6.20. Tổng quan Segmentation trong TorchGeo&quot;">​</a></h2><p>Semantic segmentation là task quan trọng trong remote sensing, cho phép pixel-level classification của ảnh vệ tinh. Các ứng dụng bao gồm land cover mapping, crop field delineation, building footprint extraction, flood mapping, và nhiều tasks khác yêu cầu chi tiết về spatial extent của các features.</p><p>TorchGeo cung cấp comprehensive support cho segmentation tasks thông qua pre-trained encoders, benchmark datasets, và training utilities được thiết kế đặc biệt cho geospatial data.</p><h2 id="_6-21-segmentation-architectures" tabindex="-1">6.21. Segmentation Architectures <a class="header-anchor" href="#_6-21-segmentation-architectures" aria-label="Permalink to &quot;6.21. Segmentation Architectures&quot;">​</a></h2><h3 id="_6-21-1-u-net-trong-torchgeo" tabindex="-1">6.21.1. U-Net trong TorchGeo <a class="header-anchor" href="#_6-21-1-u-net-trong-torchgeo" aria-label="Permalink to &quot;6.21.1. U-Net trong TorchGeo&quot;">​</a></h3><p>U-Net là architecture cơ bản và phổ biến nhất cho remote sensing segmentation.</p><p><strong>Implementation:</strong> TorchGeo sử dụng U-Net implementations từ segmentation_models_pytorch library:</p><ul><li>Various encoder backbones</li><li>Skip connections preserve spatial information</li><li>Configurable depth và features</li></ul><p><strong>Encoder Options:</strong></p><ul><li>ResNet (18, 34, 50, 101, 152)</li><li>EfficientNet (B0-B7)</li><li>VGG</li><li>DenseNet</li><li>MobileNet</li></ul><p><strong>Pre-trained Encoders:</strong> Encoders có thể được initialized với:</p><ul><li>TorchGeo remote sensing weights (SSL4EO, SatMAE)</li><li>ImageNet weights</li><li>Random initialization</li></ul><p><strong>Configuration:</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>model = UNet(</span></span>
<span class="line"><span>    encoder_name=&quot;resnet50&quot;,</span></span>
<span class="line"><span>    encoder_weights=&quot;ssl4eo_moco&quot;,  # TorchGeo specific</span></span>
<span class="line"><span>    in_channels=13,  # Sentinel-2 bands</span></span>
<span class="line"><span>    classes=10,  # Number of classes</span></span>
<span class="line"><span>    activation=None,  # For training</span></span>
<span class="line"><span>)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h3 id="_6-21-2-deeplabv3" tabindex="-1">6.21.2. DeepLabV3+ <a class="header-anchor" href="#_6-21-2-deeplabv3" aria-label="Permalink to &quot;6.21.2. DeepLabV3+&quot;">​</a></h3><p>DeepLabV3+ với atrous spatial pyramid pooling cho multi-scale context.</p><p><strong>Key Components:</strong></p><ul><li>Encoder backbone (ResNet, Xception)</li><li>ASPP module với multiple dilation rates</li><li>Simple decoder với skip connection</li></ul><p><strong>Advantages cho Remote Sensing:</strong></p><ul><li>Captures objects ở multiple scales</li><li>Good boundary delineation</li><li>Efficient inference</li></ul><p><strong>TorchGeo Integration:</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>model = DeepLabV3Plus(</span></span>
<span class="line"><span>    encoder_name=&quot;resnet50&quot;,</span></span>
<span class="line"><span>    encoder_weights=&quot;ssl4eo&quot;,</span></span>
<span class="line"><span>    in_channels=13,</span></span>
<span class="line"><span>    classes=10,</span></span>
<span class="line"><span>)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><h3 id="_6-21-3-feature-pyramid-network-fpn" tabindex="-1">6.21.3. Feature Pyramid Network (FPN) <a class="header-anchor" href="#_6-21-3-feature-pyramid-network-fpn" aria-label="Permalink to &quot;6.21.3. Feature Pyramid Network (FPN)&quot;">​</a></h3><p>FPN-based segmentation cho multi-scale features.</p><p><strong>Architecture:</strong></p><ul><li>Bottom-up pathway (encoder)</li><li>Top-down pathway với lateral connections</li><li>Prediction từ merged features</li></ul><p><strong>Use Cases:</strong></p><ul><li>Multi-scale object segmentation</li><li>Objects ranging từ buildings đến large water bodies</li></ul><h3 id="_6-21-4-pspnet" tabindex="-1">6.21.4. PSPNet <a class="header-anchor" href="#_6-21-4-pspnet" aria-label="Permalink to &quot;6.21.4. PSPNet&quot;">​</a></h3><p>Pyramid Scene Parsing Network với pyramid pooling module.</p><p><strong>Key Feature:</strong></p><ul><li>Global context aggregation</li><li>Multiple pooling scales (1×1, 2×2, 3×3, 6×6)</li><li>Good cho understanding scene layout</li></ul><h3 id="_6-21-5-manet-multi-scale-attention-network" tabindex="-1">6.21.5. MANet (Multi-scale Attention Network) <a class="header-anchor" href="#_6-21-5-manet-multi-scale-attention-network" aria-label="Permalink to &quot;6.21.5. MANet (Multi-scale Attention Network)&quot;">​</a></h3><p>Attention-based segmentation architecture.</p><p><strong>Components:</strong></p><ul><li>Multi-scale feature extraction</li><li>Attention mechanisms</li><li>Feature aggregation</li></ul><h2 id="_6-22-pre-trained-weights-cho-segmentation" tabindex="-1">6.22. Pre-trained Weights cho Segmentation <a class="header-anchor" href="#_6-22-pre-trained-weights-cho-segmentation" aria-label="Permalink to &quot;6.22. Pre-trained Weights cho Segmentation&quot;">​</a></h2><h3 id="_6-22-1-encoder-pre-training" tabindex="-1">6.22.1. Encoder Pre-training <a class="header-anchor" href="#_6-22-1-encoder-pre-training" aria-label="Permalink to &quot;6.22.1. Encoder Pre-training&quot;">​</a></h3><p>Segmentation models sử dụng pre-trained encoders:</p><p><strong>SSL4EO Weights:</strong> Available cho encoders:</p><ul><li>ResNet-18, 34, 50 với MoCo pre-training</li><li>Sentinel-1 và Sentinel-2 data</li><li>Significant improvement over ImageNet</li></ul><p><strong>Usage:</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># Load encoder với TorchGeo weights</span></span>
<span class="line"><span>encoder = resnet50(weights=ResNet50_Weights.SENTINEL2_ALL_MOCO)</span></span>
<span class="line"><span># Use as backbone cho segmentation model</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h3 id="_6-22-2-full-model-weights" tabindex="-1">6.22.2. Full Model Weights <a class="header-anchor" href="#_6-22-2-full-model-weights" aria-label="Permalink to &quot;6.22.2. Full Model Weights&quot;">​</a></h3><p>Some datasets provide full segmentation model weights:</p><p><strong>ChesapeakeCVPR:</strong></p><ul><li>U-Net trained on land cover</li><li>Available cho evaluation</li></ul><p><strong>Custom Training:</strong> Most use cases require training segmentation head from scratch với pre-trained encoder.</p><h3 id="_6-22-3-transfer-learning-strategy" tabindex="-1">6.22.3. Transfer Learning Strategy <a class="header-anchor" href="#_6-22-3-transfer-learning-strategy" aria-label="Permalink to &quot;6.22.3. Transfer Learning Strategy&quot;">​</a></h3><p><strong>Two-stage Approach:</strong></p><ol><li>Load pre-trained encoder</li><li>Initialize decoder randomly</li><li>Fine-tune entire model</li></ol><p><strong>Layer-wise Learning Rates:</strong></p><ul><li>Lower LR cho pre-trained encoder</li><li>Higher LR cho decoder</li><li>Gradual unfreezing</li></ul><h2 id="_6-23-segmentation-datasets" tabindex="-1">6.23. Segmentation Datasets <a class="header-anchor" href="#_6-23-segmentation-datasets" aria-label="Permalink to &quot;6.23. Segmentation Datasets&quot;">​</a></h2><h3 id="_6-23-1-chesapeakecvpr" tabindex="-1">6.23.1. ChesapeakeCVPR <a class="header-anchor" href="#_6-23-1-chesapeakecvpr" aria-label="Permalink to &quot;6.23.1. ChesapeakeCVPR&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Attribute</th><th>Value</th></tr></thead><tbody><tr><td><strong>Source</strong></td><td>NAIP + Landsat + other</td></tr><tr><td><strong>Classes</strong></td><td>7 land cover classes</td></tr><tr><td><strong>Coverage</strong></td><td>Chesapeake Bay watershed, USA</td></tr><tr><td><strong>Resolution</strong></td><td>1m (NAIP), 30m (Landsat)</td></tr></tbody></table><p><strong>Classes:</strong> Water, Tree Canopy / Forest, Low Vegetation / Field, Barren Land, Impervious (other), Impervious (road), No Data</p><p><strong>Usage:</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>from torchgeo.datasets import ChesapeakeCVPR</span></span>
<span class="line"><span>from torchgeo.samplers import RandomGeoSampler</span></span>
<span class="line"><span></span></span>
<span class="line"><span>dataset = ChesapeakeCVPR(root=&quot;data&quot;, crs=CRS, res=1.0)</span></span>
<span class="line"><span>sampler = RandomGeoSampler(dataset, size=256, length=1000)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h3 id="_6-23-2-landcover-ai" tabindex="-1">6.23.2. LandCover.ai <a class="header-anchor" href="#_6-23-2-landcover-ai" aria-label="Permalink to &quot;6.23.2. LandCover.ai&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Attribute</th><th>Value</th></tr></thead><tbody><tr><td><strong>Source</strong></td><td>Aerial orthophotos</td></tr><tr><td><strong>Classes</strong></td><td>4 classes + background</td></tr><tr><td><strong>Coverage</strong></td><td>Poland</td></tr><tr><td><strong>Resolution</strong></td><td>0.25m - 0.5m</td></tr></tbody></table><p><strong>Classes:</strong> Building, Woodland, Water, Road, Background</p><p><strong>Đặc điểm:</strong></p><ul><li>High-resolution imagery</li><li>Building và road extraction</li><li>European urban/rural mix</li></ul><h3 id="_6-23-3-geonrw" tabindex="-1">6.23.3. GeoNRW <a class="header-anchor" href="#_6-23-3-geonrw" aria-label="Permalink to &quot;6.23.3. GeoNRW&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Attribute</th><th>Value</th></tr></thead><tbody><tr><td><strong>Source</strong></td><td>Aerial imagery</td></tr><tr><td><strong>Classes</strong></td><td>10 classes</td></tr><tr><td><strong>Coverage</strong></td><td>North Rhine-Westphalia, Germany</td></tr><tr><td><strong>Resolution</strong></td><td>1m</td></tr></tbody></table><p><strong>Classes:</strong> Forest, Water, Agricultural, Urban Fabric, Industrial, Road, Railway, etc.</p><h3 id="_6-23-4-spacenet" tabindex="-1">6.23.4. SpaceNet <a class="header-anchor" href="#_6-23-4-spacenet" aria-label="Permalink to &quot;6.23.4. SpaceNet&quot;">​</a></h3><p>SpaceNet provides building footprint segmentation datasets:</p><table tabindex="0"><thead><tr><th>Dataset</th><th>Coverage</th><th>Buildings</th></tr></thead><tbody><tr><td>SpaceNet 1</td><td>Rio de Janeiro</td><td>382k</td></tr><tr><td>SpaceNet 2</td><td>Las Vegas, Paris, Shanghai, Khartoum</td><td>858k</td></tr><tr><td>SpaceNet 4</td><td>Atlanta</td><td>126k</td></tr><tr><td>SpaceNet 7</td><td>Global urban areas</td><td>Temporal</td></tr></tbody></table><p><strong>Use Cases:</strong></p><ul><li>Building footprint extraction</li><li>Urban mapping</li><li>Change detection (SpaceNet 7)</li></ul><h3 id="_6-23-5-inria-aerial-image-labeling" tabindex="-1">6.23.5. INRIA Aerial Image Labeling <a class="header-anchor" href="#_6-23-5-inria-aerial-image-labeling" aria-label="Permalink to &quot;6.23.5. INRIA Aerial Image Labeling&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Attribute</th><th>Value</th></tr></thead><tbody><tr><td><strong>Task</strong></td><td>Building segmentation</td></tr><tr><td><strong>Coverage</strong></td><td>5 cities (US và Austria)</td></tr><tr><td><strong>Resolution</strong></td><td>0.3m</td></tr><tr><td><strong>Area</strong></td><td>810 km²</td></tr></tbody></table><p><strong>Đặc điểm:</strong></p><ul><li>Binary segmentation (building/not building)</li><li>High-resolution RGB</li><li>Diverse urban environments</li></ul><h3 id="_6-23-6-potsdam-va-vaihingen" tabindex="-1">6.23.6. Potsdam và Vaihingen <a class="header-anchor" href="#_6-23-6-potsdam-va-vaihingen" aria-label="Permalink to &quot;6.23.6. Potsdam và Vaihingen&quot;">​</a></h3><p>ISPRS 2D Semantic Labeling datasets:</p><table tabindex="0"><thead><tr><th>Dataset</th><th>Resolution</th><th>Classes</th></tr></thead><tbody><tr><td>Potsdam</td><td>5cm</td><td>6</td></tr><tr><td>Vaihingen</td><td>9cm</td><td>6</td></tr></tbody></table><p><strong>Classes:</strong> Impervious Surface, Building, Low Vegetation, Tree, Car, Clutter</p><p><strong>Đặc điểm:</strong></p><ul><li>Very high resolution</li><li>Urban semantic segmentation</li><li>Standard benchmark cho aerial imagery</li></ul><h2 id="_6-24-semanticsegmentationtask" tabindex="-1">6.24. SemanticSegmentationTask <a class="header-anchor" href="#_6-24-semanticsegmentationtask" aria-label="Permalink to &quot;6.24. SemanticSegmentationTask&quot;">​</a></h2><h3 id="_6-24-1-overview" tabindex="-1">6.24.1. Overview <a class="header-anchor" href="#_6-24-1-overview" aria-label="Permalink to &quot;6.24.1. Overview&quot;">​</a></h3><p>TorchGeo cung cấp <code>SemanticSegmentationTask</code> Lightning module cho streamlined training.</p><p><strong>Features:</strong></p><ul><li>Configurable encoder và decoder</li><li>Support cho various loss functions</li><li>Standard metrics (IoU, Dice, accuracy)</li><li>Integration với TorchGeo datasets</li></ul><h3 id="_6-24-2-configuration" tabindex="-1">6.24.2. Configuration <a class="header-anchor" href="#_6-24-2-configuration" aria-label="Permalink to &quot;6.24.2. Configuration&quot;">​</a></h3><p><strong>Architecture Selection:</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>task = SemanticSegmentationTask(</span></span>
<span class="line"><span>    model=&quot;unet&quot;,</span></span>
<span class="line"><span>    backbone=&quot;resnet50&quot;,</span></span>
<span class="line"><span>    weights=&quot;ssl4eo&quot;,</span></span>
<span class="line"><span>    in_channels=4,  # RGBIR</span></span>
<span class="line"><span>    num_classes=7,</span></span>
<span class="line"><span>    loss=&quot;ce&quot;,  # or &quot;focal&quot;, &quot;dice&quot;</span></span>
<span class="line"><span>    lr=1e-4,</span></span>
<span class="line"><span>)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p><strong>Loss Functions:</strong></p><ul><li>Cross Entropy: Standard cho multi-class</li><li>Focal Loss: Handles class imbalance</li><li>Dice Loss: Optimizes overlap metric</li><li>Combination: CE + Dice common</li></ul><h3 id="_6-24-3-metrics" tabindex="-1">6.24.3. Metrics <a class="header-anchor" href="#_6-24-3-metrics" aria-label="Permalink to &quot;6.24.3. Metrics&quot;">​</a></h3><p><strong>Per-pixel Metrics:</strong></p><ul><li>Overall Accuracy</li><li>Per-class Accuracy</li><li>Mean Accuracy</li></ul><p><strong>IoU-based Metrics:</strong></p><ul><li>Per-class IoU</li><li>Mean IoU (mIoU)</li><li>Frequency-weighted IoU</li></ul><p><strong>Dice Score:</strong></p><ul><li>Per-class Dice</li><li>Mean Dice</li></ul><h2 id="_6-25-training-best-practices" tabindex="-1">6.25. Training Best Practices <a class="header-anchor" href="#_6-25-training-best-practices" aria-label="Permalink to &quot;6.25. Training Best Practices&quot;">​</a></h2><h3 id="_6-25-1-data-preprocessing" tabindex="-1">6.25.1. Data Preprocessing <a class="header-anchor" href="#_6-25-1-data-preprocessing" aria-label="Permalink to &quot;6.25.1. Data Preprocessing&quot;">​</a></h3><p><strong>Normalization:</strong></p><ul><li>Use sensor-specific statistics</li><li>TorchGeo provides per-band mean/std</li><li>Consistent normalization train/test</li></ul><p><strong>Patch Sampling:</strong> For large rasters:</p><ul><li>RandomGeoSampler cho training</li><li>GridGeoSampler cho inference</li><li>Appropriate patch size (256, 512)</li><li>Overlap cho inference</li></ul><h3 id="_6-25-2-class-imbalance" tabindex="-1">6.25.2. Class Imbalance <a class="header-anchor" href="#_6-25-2-class-imbalance" aria-label="Permalink to &quot;6.25.2. Class Imbalance&quot;">​</a></h3><p>Remote sensing often has severe class imbalance:</p><p><strong>Solutions:</strong></p><ul><li>Class weighting in loss function</li><li>Focal Loss</li><li>Over-sampling rare classes</li><li>Data augmentation cho minority classes</li><li>Dice/IoU loss</li></ul><p><strong>Computing Weights:</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># Inverse frequency weighting</span></span>
<span class="line"><span>class_weights = 1.0 / class_frequencies</span></span>
<span class="line"><span># Or median frequency balancing</span></span>
<span class="line"><span>class_weights = median_freq / class_frequencies</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h3 id="_6-25-3-augmentation" tabindex="-1">6.25.3. Augmentation <a class="header-anchor" href="#_6-25-3-augmentation" aria-label="Permalink to &quot;6.25.3. Augmentation&quot;">​</a></h3><p><strong>Geometric:</strong></p><ul><li>Random flip (horizontal, vertical)</li><li>Random rotation (90°, 180°, 270°, or arbitrary)</li><li>Random scale</li><li>Random crop</li></ul><p><strong>Photometric:</strong></p><ul><li>Brightness và contrast adjustment</li><li>Gaussian noise</li><li>Blur</li></ul><p><strong>Important:</strong></p><ul><li>Apply same transforms to image và mask</li><li>Preserve spatial alignment</li><li>Use nearest neighbor for mask interpolation</li></ul><h3 id="_6-25-4-multi-scale-training" tabindex="-1">6.25.4. Multi-scale Training <a class="header-anchor" href="#_6-25-4-multi-scale-training" aria-label="Permalink to &quot;6.25.4. Multi-scale Training&quot;">​</a></h3><p><strong>Input Scales:</strong></p><ul><li>Train với multiple input resolutions</li><li>Improves scale invariance</li><li>Helps với objects của different sizes</li></ul><p><strong>Multi-scale Inference:</strong></p><ul><li>Process at multiple scales</li><li>Merge predictions</li><li>Improves accuracy với computation cost</li></ul><h2 id="_6-26-inference-strategies" tabindex="-1">6.26. Inference Strategies <a class="header-anchor" href="#_6-26-inference-strategies" aria-label="Permalink to &quot;6.26. Inference Strategies&quot;">​</a></h2><h3 id="_6-26-1-sliding-window" tabindex="-1">6.26.1. Sliding Window <a class="header-anchor" href="#_6-26-1-sliding-window" aria-label="Permalink to &quot;6.26.1. Sliding Window&quot;">​</a></h3><p>For large images:</p><ol><li>Divide into overlapping patches</li><li>Run model on each patch</li><li>Merge predictions</li></ol><p><strong>Overlap Handling:</strong></p><ul><li>Average probabilities in overlap regions</li><li>Or max probability</li><li>Or learned fusion</li></ul><h3 id="_6-26-2-test-time-augmentation-tta" tabindex="-1">6.26.2. Test Time Augmentation (TTA) <a class="header-anchor" href="#_6-26-2-test-time-augmentation-tta" aria-label="Permalink to &quot;6.26.2. Test Time Augmentation (TTA)&quot;">​</a></h3><p>Apply augmentations at inference:</p><ul><li>Horizontal/vertical flips</li><li>90° rotations</li><li>Average predictions</li></ul><p><strong>Benefits:</strong></p><ul><li>Improved accuracy (1-2% typical)</li><li>More robust predictions</li><li>Smoother boundaries</li></ul><h3 id="_6-26-3-post-processing" tabindex="-1">6.26.3. Post-processing <a class="header-anchor" href="#_6-26-3-post-processing" aria-label="Permalink to &quot;6.26.3. Post-processing&quot;">​</a></h3><p><strong>Morphological Operations:</strong></p><ul><li>Remove small isolated regions</li><li>Fill holes</li><li>Smooth boundaries</li></ul><p><strong>CRF (Conditional Random Field):</strong></p><ul><li>Refine boundaries</li><li>Spatial consistency</li><li>Consider image evidence</li></ul><p><strong>Vector Conversion:</strong></p><ul><li>Convert raster mask to vector polygons</li><li>Simplification cho cleaner shapes</li><li>Export to GIS formats</li></ul><h2 id="_6-27-benchmark-results" tabindex="-1">6.27. Benchmark Results <a class="header-anchor" href="#_6-27-benchmark-results" aria-label="Permalink to &quot;6.27. Benchmark Results&quot;">​</a></h2><h3 id="_6-27-1-chesapeakecvpr-results" tabindex="-1">6.27.1. ChesapeakeCVPR Results <a class="header-anchor" href="#_6-27-1-chesapeakecvpr-results" aria-label="Permalink to &quot;6.27.1. ChesapeakeCVPR Results&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Model</th><th>Encoder</th><th>Pre-training</th><th>mIoU</th></tr></thead><tbody><tr><td>U-Net</td><td>ResNet-50</td><td>ImageNet</td><td>62.3</td></tr><tr><td>U-Net</td><td>ResNet-50</td><td>SSL4EO</td><td>66.8</td></tr><tr><td>DeepLabV3+</td><td>ResNet-50</td><td>SSL4EO</td><td>68.2</td></tr><tr><td>FPN</td><td>ResNet-50</td><td>SSL4EO</td><td>67.5</td></tr></tbody></table><h3 id="_6-27-2-landcover-ai-results" tabindex="-1">6.27.2. LandCover.ai Results <a class="header-anchor" href="#_6-27-2-landcover-ai-results" aria-label="Permalink to &quot;6.27.2. LandCover.ai Results&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Model</th><th>Encoder</th><th>mIoU</th></tr></thead><tbody><tr><td>U-Net</td><td>EfficientNet-B4</td><td>78.5</td></tr><tr><td>FPN</td><td>ResNet-101</td><td>79.2</td></tr><tr><td>DeepLabV3+</td><td>Xception</td><td>80.1</td></tr></tbody></table><h3 id="_6-27-3-potsdam-results" tabindex="-1">6.27.3. Potsdam Results <a class="header-anchor" href="#_6-27-3-potsdam-results" aria-label="Permalink to &quot;6.27.3. Potsdam Results&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Model</th><th>OA</th><th>mIoU</th></tr></thead><tbody><tr><td>U-Net</td><td>89.2</td><td>76.8</td></tr><tr><td>DeepLabV3+</td><td>90.5</td><td>79.3</td></tr><tr><td>HRNet</td><td>91.2</td><td>81.5</td></tr></tbody></table><p><strong>Observations:</strong></p><ul><li>Domain-specific pre-training (SSL4EO) consistently helps</li><li>DeepLabV3+ generally strong performer</li><li>HRNet excellent for high-resolution imagery</li></ul><h2 id="_6-28-advanced-topics" tabindex="-1">6.28. Advanced Topics <a class="header-anchor" href="#_6-28-advanced-topics" aria-label="Permalink to &quot;6.28. Advanced Topics&quot;">​</a></h2><h3 id="_6-28-1-instance-segmentation" tabindex="-1">6.28.1. Instance Segmentation <a class="header-anchor" href="#_6-28-1-instance-segmentation" aria-label="Permalink to &quot;6.28.1. Instance Segmentation&quot;">​</a></h3><p>Beyond semantic segmentation:</p><ul><li>Mask R-CNN cho instance-level</li><li>Separate each object instance</li><li>Building instance extraction</li></ul><p>TorchGeo supports through integration với detectron2 hoặc mmdetection.</p><h3 id="_6-28-2-panoptic-segmentation" tabindex="-1">6.28.2. Panoptic Segmentation <a class="header-anchor" href="#_6-28-2-panoptic-segmentation" aria-label="Permalink to &quot;6.28.2. Panoptic Segmentation&quot;">​</a></h3><p>Combining semantic và instance:</p><ul><li>&quot;Stuff&quot; classes (background, water)</li><li>&quot;Things&quot; classes (buildings, vehicles)</li><li>Unified output</li></ul><h3 id="_6-28-3-multi-temporal-segmentation" tabindex="-1">6.28.3. Multi-temporal Segmentation <a class="header-anchor" href="#_6-28-3-multi-temporal-segmentation" aria-label="Permalink to &quot;6.28.3. Multi-temporal Segmentation&quot;">​</a></h3><p>Using time series:</p><ul><li>Stack multiple dates</li><li>Recurrent architectures (ConvLSTM)</li><li>Attention over time</li></ul><p><strong>Applications:</strong></p><ul><li>Crop mapping với growing season</li><li>Change detection</li><li>Seasonal land cover</li></ul><h3 id="_6-28-4-multi-modal-fusion" tabindex="-1">6.28.4. Multi-modal Fusion <a class="header-anchor" href="#_6-28-4-multi-modal-fusion" aria-label="Permalink to &quot;6.28.4. Multi-modal Fusion&quot;">​</a></h3><p>Combining data sources:</p><p><strong>Early Fusion:</strong></p><ul><li>Concatenate inputs (optical + SAR)</li><li>Single network processes all</li></ul><p><strong>Late Fusion:</strong></p><ul><li>Separate encoders</li><li>Merge at decision level</li></ul><p><strong>Mid-level Fusion:</strong></p><ul><li>Separate encoders</li><li>Merge features before decoder</li></ul><p>TorchGeo IntersectionDataset facilitates loading aligned multi-modal data.</p><h3 id="_6-28-5-uncertainty-quantification" tabindex="-1">6.28.5. Uncertainty Quantification <a class="header-anchor" href="#_6-28-5-uncertainty-quantification" aria-label="Permalink to &quot;6.28.5. Uncertainty Quantification&quot;">​</a></h3><p>Estimating prediction confidence:</p><ul><li>Monte Carlo Dropout</li><li>Deep Ensembles</li><li>Evidential Deep Learning</li></ul><p>Important cho:</p><ul><li>Identifying unreliable predictions</li><li>Active learning</li><li>Decision support</li></ul><h2 id="_6-29-use-cases" tabindex="-1">6.29. Use Cases <a class="header-anchor" href="#_6-29-use-cases" aria-label="Permalink to &quot;6.29. Use Cases&quot;">​</a></h2><h3 id="_6-29-1-land-cover-mapping" tabindex="-1">6.29.1. Land Cover Mapping <a class="header-anchor" href="#_6-29-1-land-cover-mapping" aria-label="Permalink to &quot;6.29.1. Land Cover Mapping&quot;">​</a></h3><p><strong>Task:</strong> Classify every pixel into land cover categories.</p><p><strong>Approach:</strong></p><ul><li>Sentinel-2 data</li><li>U-Net với SSL4EO pre-trained encoder</li><li>10-15 classes typically</li></ul><p><strong>Challenges:</strong></p><ul><li>Class confusion (e.g., grass vs crop)</li><li>Seasonal variation</li><li>Cloud contamination</li></ul><h3 id="_6-29-2-building-footprint-extraction" tabindex="-1">6.29.2. Building Footprint Extraction <a class="header-anchor" href="#_6-29-2-building-footprint-extraction" aria-label="Permalink to &quot;6.29.2. Building Footprint Extraction&quot;">​</a></h3><p><strong>Task:</strong> Segment building pixels từ aerial/satellite imagery.</p><p><strong>Approach:</strong></p><ul><li>High-resolution imagery (0.3-1m)</li><li>Binary hoặc instance segmentation</li><li>Post-process to polygons</li></ul><p><strong>Challenges:</strong></p><ul><li>Dense urban areas</li><li>Varying building sizes</li><li>Shadows và occlusion</li></ul><h3 id="_6-29-3-agricultural-field-delineation" tabindex="-1">6.29.3. Agricultural Field Delineation <a class="header-anchor" href="#_6-29-3-agricultural-field-delineation" aria-label="Permalink to &quot;6.29.3. Agricultural Field Delineation&quot;">​</a></h3><p><strong>Task:</strong> Identify boundaries của agricultural fields.</p><p><strong>Approach:</strong></p><ul><li>Multi-temporal Sentinel-2</li><li>Edge detection hoặc semantic segmentation</li><li>Vectorization</li></ul><p><strong>Challenges:</strong></p><ul><li>Fuzzy field boundaries</li><li>Seasonal changes</li><li>Fragmented landscapes</li></ul><h3 id="_6-29-4-flood-mapping" tabindex="-1">6.29.4. Flood Mapping <a class="header-anchor" href="#_6-29-4-flood-mapping" aria-label="Permalink to &quot;6.29.4. Flood Mapping&quot;">​</a></h3><p><strong>Task:</strong> Identify inundated areas từ satellite imagery.</p><p><strong>Approach:</strong></p><ul><li>SAR data (Sentinel-1) cho all-weather</li><li>Binary segmentation (water/non-water)</li><li>Rapid response requirement</li></ul><p><strong>Challenges:</strong></p><ul><li>Urban flooding (mixed pixels)</li><li>Vegetation trong water</li><li>False positives (shadows, wet surfaces)</li></ul><h3 id="_6-29-5-road-network-extraction" tabindex="-1">6.29.5. Road Network Extraction <a class="header-anchor" href="#_6-29-5-road-network-extraction" aria-label="Permalink to &quot;6.29.5. Road Network Extraction&quot;">​</a></h3><p><strong>Task:</strong> Extract road network từ imagery.</p><p><strong>Approach:</strong></p><ul><li>High-resolution imagery</li><li>Semantic segmentation + skeletonization</li><li>Graph extraction cho network topology</li></ul><p><strong>Challenges:</strong></p><ul><li>Occluded by trees</li><li>Varying road widths</li><li>Junctions và complex topology</li></ul><p>Segmentation trong TorchGeo provides essential tools cho converting satellite imagery into actionable spatial information, với pre-trained models significantly accelerating development cycles.</p>`,210)])])}const h=a(s,[["render",l]]);export{g as __pageData,h as default};
