import{_ as s,c as i,o as e,a2 as n}from"./chunks/framework.nRfFlDZQ.js";const g=JSON.parse('{"title":"Chương 5: Change Detection Models trong TorchGeo","description":"","frontmatter":{},"headers":[],"relativePath":"chuong-05-torchgeo/muc-04-change-detection/01-change-detection-models.md","filePath":"chuong-05-torchgeo/muc-04-change-detection/01-change-detection-models.md","lastUpdated":null}'),t={name:"chuong-05-torchgeo/muc-04-change-detection/01-change-detection-models.md"};function l(r,a,o,p,h,d){return e(),i("div",null,[...a[0]||(a[0]=[n(`<h1 id="chuong-5-change-detection-models-trong-torchgeo" tabindex="-1">Chương 5: Change Detection Models trong TorchGeo <a class="header-anchor" href="#chuong-5-change-detection-models-trong-torchgeo" aria-label="Permalink to &quot;Chương 5: Change Detection Models trong TorchGeo&quot;">​</a></h1><h2 id="_6-30-tong-quan-change-detection" tabindex="-1">6.30. Tổng quan Change Detection <a class="header-anchor" href="#_6-30-tong-quan-change-detection" aria-label="Permalink to &quot;6.30. Tổng quan Change Detection&quot;">​</a></h2><p>Change detection là task xác định và phân tích những thay đổi trên bề mặt Trái Đất qua thời gian bằng cách so sánh ảnh vệ tinh từ các thời điểm khác nhau. Đây là một trong những ứng dụng quan trọng nhất của remote sensing, với applications trong urban expansion monitoring, disaster assessment, deforestation tracking, agricultural monitoring, và nhiều lĩnh vực khác.</p><p>TorchGeo cung cấp support cho change detection thông qua datasets, data loading utilities cho temporal data, và integration với các deep learning approaches cho bi-temporal và multi-temporal change detection.</p><h2 id="_6-31-formulations-cua-change-detection" tabindex="-1">6.31. Formulations của Change Detection <a class="header-anchor" href="#_6-31-formulations-cua-change-detection" aria-label="Permalink to &quot;6.31. Formulations của Change Detection&quot;">​</a></h2><h3 id="_6-31-1-binary-change-detection" tabindex="-1">6.31.1. Binary Change Detection <a class="header-anchor" href="#_6-31-1-binary-change-detection" aria-label="Permalink to &quot;6.31.1. Binary Change Detection&quot;">​</a></h3><p>Đơn giản nhất - xác định change hay no-change cho mỗi pixel:</p><ul><li>Input: Two images (pre và post)</li><li>Output: Binary mask (0 = no change, 1 = change)</li></ul><p><strong>Pros:</strong></p><ul><li>Simple formulation</li><li>Straightforward evaluation</li><li>Less annotation effort</li></ul><p><strong>Cons:</strong></p><ul><li>Không phân loại loại change</li><li>May miss subtle changes</li><li>Limited information for analysis</li></ul><h3 id="_6-31-2-semantic-change-detection" tabindex="-1">6.31.2. Semantic Change Detection <a class="header-anchor" href="#_6-31-2-semantic-change-detection" aria-label="Permalink to &quot;6.31.2. Semantic Change Detection&quot;">​</a></h3><p>Phân loại loại change cho mỗi pixel:</p><ul><li>Input: Two images</li><li>Output: Multi-class mask indicating change type</li></ul><p><strong>Example Classes:</strong></p><ul><li>No change</li><li>Building construction</li><li>Building demolition</li><li>Vegetation gain</li><li>Vegetation loss</li><li>Water body change</li></ul><p><strong>Pros:</strong></p><ul><li>Rich information</li><li>Actionable insights</li><li>Better understanding of dynamics</li></ul><p><strong>Cons:</strong></p><ul><li>More annotation required</li><li>Class imbalance issues</li><li>More complex models</li></ul><h3 id="_6-31-3-from-to-change-detection" tabindex="-1">6.31.3. From-to Change Detection <a class="header-anchor" href="#_6-31-3-from-to-change-detection" aria-label="Permalink to &quot;6.31.3. From-to Change Detection&quot;">​</a></h3><p>Identify both source và destination land cover:</p><ul><li>Input: Two images</li><li>Output: Change matrix (from class A to class B)</li></ul><p><strong>Example:</strong></p><ul><li>Forest → Urban</li><li>Agricultural → Forest</li><li>Water → Land (or vice versa)</li></ul><p><strong>Pros:</strong></p><ul><li>Complete change characterization</li><li>Supports transition analysis</li><li>Links với land cover classification</li></ul><p><strong>Cons:</strong></p><ul><li>N×N possible transitions cho N classes</li><li>Sparse annotations</li><li>Complex training</li></ul><h3 id="_6-31-4-multi-temporal-change-detection" tabindex="-1">6.31.4. Multi-temporal Change Detection <a class="header-anchor" href="#_6-31-4-multi-temporal-change-detection" aria-label="Permalink to &quot;6.31.4. Multi-temporal Change Detection&quot;">​</a></h3><p>Extend beyond bi-temporal to time series:</p><ul><li>Input: Sequence of images (3 or more dates)</li><li>Output: Change points, trajectories, or trends</li></ul><p><strong>Applications:</strong></p><ul><li>Continuous monitoring</li><li>Trend analysis</li><li>Seasonal pattern detection</li></ul><h2 id="_6-32-deep-learning-architectures" tabindex="-1">6.32. Deep Learning Architectures <a class="header-anchor" href="#_6-32-deep-learning-architectures" aria-label="Permalink to &quot;6.32. Deep Learning Architectures&quot;">​</a></h2><h3 id="_6-32-1-siamese-networks" tabindex="-1">6.32.1. Siamese Networks <a class="header-anchor" href="#_6-32-1-siamese-networks" aria-label="Permalink to &quot;6.32.1. Siamese Networks&quot;">​</a></h3><p>Siamese architecture xử lý hai images với shared weights:</p><p><strong>Architecture:</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Image_t1 → Encoder → Features_t1</span></span>
<span class="line"><span>Image_t2 → Encoder → Features_t2</span></span>
<span class="line"><span>(Features_t1, Features_t2) → Comparison Module → Change Map</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p><strong>Key Components:</strong></p><ul><li><strong>Shared Encoder:</strong> Same CNN/Transformer processes both images</li><li><strong>Comparison Module:</strong> Computes difference/similarity</li><li><strong>Decoder:</strong> Generates change map</li></ul><p><strong>Comparison Strategies:</strong></p><ul><li>Feature concatenation: [F1, F2]</li><li>Feature difference: |F1 - F2|</li><li>Feature correlation: F1 * F2</li><li>Learned comparison</li></ul><p><strong>Advantages:</strong></p><ul><li>Weight sharing ensures consistent feature extraction</li><li>Naturally handles temporal comparison</li><li>Flexible comparison module</li></ul><h3 id="_6-32-2-unet-based-change-detection" tabindex="-1">6.32.2. UNet-based Change Detection <a class="header-anchor" href="#_6-32-2-unet-based-change-detection" aria-label="Permalink to &quot;6.32.2. UNet-based Change Detection&quot;">​</a></h3><p>Adapting U-Net cho change detection:</p><p><strong>Early Fusion:</strong></p><ul><li>Concatenate t1 và t2 images as input (6 channels for RGB)</li><li>Single U-Net processes concatenated input</li><li>Output is change map</li></ul><p><strong>Late Fusion:</strong></p><ul><li>Separate encoders cho t1 và t2</li><li>Merge features at bottleneck or decoder</li><li>Share decoder</li></ul><p><strong>Skip Connection Modifications:</strong></p><ul><li>Temporal attention trong skip connections</li><li>Difference features in skip connections</li></ul><h3 id="_6-32-3-fc-ef-va-fc-siam-conc-diff" tabindex="-1">6.32.3. FC-EF và FC-Siam-Conc/Diff <a class="header-anchor" href="#_6-32-3-fc-ef-va-fc-siam-conc-diff" aria-label="Permalink to &quot;6.32.3. FC-EF và FC-Siam-Conc/Diff&quot;">​</a></h3><p>Fully Convolutional architectures specifically designed cho change detection:</p><p><strong>FC-EF (Early Fusion):</strong></p><ul><li>Concatenate images as input</li><li>Standard FCN architecture</li><li>Simple but effective</li></ul><p><strong>FC-Siam-Conc (Siamese Concatenation):</strong></p><ul><li>Siamese encoder</li><li>Concatenate features at each level</li><li>Shared decoder</li></ul><p><strong>FC-Siam-Diff (Siamese Difference):</strong></p><ul><li>Siamese encoder</li><li>Compute difference at each level</li><li>Shared decoder</li></ul><h3 id="_6-32-4-attention-based-models" tabindex="-1">6.32.4. Attention-based Models <a class="header-anchor" href="#_6-32-4-attention-based-models" aria-label="Permalink to &quot;6.32.4. Attention-based Models&quot;">​</a></h3><p><strong>DTCDSCN (Dual-Task Change Detection with Semantic Consistency):</strong></p><ul><li>Dual attention modules</li><li>Semantic consistency constraint</li><li>Multi-task learning</li></ul><p><strong>BIT (Binary Transformer):</strong></p><ul><li>Transformer-based change detection</li><li>Self-attention for temporal comparison</li><li>State-of-the-art performance</li></ul><h3 id="_6-32-5-stanet-spatial-temporal-attention-network" tabindex="-1">6.32.5. STANet (Spatial-Temporal Attention Network) <a class="header-anchor" href="#_6-32-5-stanet-spatial-temporal-attention-network" aria-label="Permalink to &quot;6.32.5. STANet (Spatial-Temporal Attention Network)&quot;">​</a></h3><p>Combines spatial và temporal attention:</p><ul><li>PAM (Position Attention Module)</li><li>BAM (Basic Attention Module)</li><li>Multi-scale features</li></ul><h2 id="_6-33-change-detection-datasets" tabindex="-1">6.33. Change Detection Datasets <a class="header-anchor" href="#_6-33-change-detection-datasets" aria-label="Permalink to &quot;6.33. Change Detection Datasets&quot;">​</a></h2><h3 id="_6-33-1-oscd-onera-satellite-change-detection" tabindex="-1">6.33.1. OSCD (Onera Satellite Change Detection) <a class="header-anchor" href="#_6-33-1-oscd-onera-satellite-change-detection" aria-label="Permalink to &quot;6.33.1. OSCD (Onera Satellite Change Detection)&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Attribute</th><th>Value</th></tr></thead><tbody><tr><td><strong>Source</strong></td><td>Sentinel-2</td></tr><tr><td><strong>Pairs</strong></td><td>24 image pairs</td></tr><tr><td><strong>Size</strong></td><td>Variable (600×600 to 10000×10000)</td></tr><tr><td><strong>Classes</strong></td><td>Binary (change/no-change)</td></tr><tr><td><strong>Change Type</strong></td><td>Urban change</td></tr></tbody></table><p><strong>Đặc điểm:</strong></p><ul><li>Urban areas worldwide</li><li>Multi-spectral (13 bands)</li><li>Challenging scenarios</li></ul><p><strong>Usage trong TorchGeo:</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>from torchgeo.datasets import OSCD</span></span>
<span class="line"><span></span></span>
<span class="line"><span>dataset = OSCD(root=&quot;data&quot;, split=&quot;train&quot;, download=True)</span></span>
<span class="line"><span>sample = dataset[0]</span></span>
<span class="line"><span># sample[&quot;image1&quot;], sample[&quot;image2&quot;], sample[&quot;mask&quot;]</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h3 id="_6-33-2-levir-cd" tabindex="-1">6.33.2. LEVIR-CD <a class="header-anchor" href="#_6-33-2-levir-cd" aria-label="Permalink to &quot;6.33.2. LEVIR-CD&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Attribute</th><th>Value</th></tr></thead><tbody><tr><td><strong>Source</strong></td><td>Google Earth</td></tr><tr><td><strong>Pairs</strong></td><td>637 image pairs</td></tr><tr><td><strong>Size</strong></td><td>1024×1024 pixels</td></tr><tr><td><strong>Resolution</strong></td><td>0.5m</td></tr><tr><td><strong>Classes</strong></td><td>Binary (building change)</td></tr></tbody></table><p><strong>Đặc điểm:</strong></p><ul><li>Building construction và demolition</li><li>High resolution</li><li>Large dataset</li><li>10-year time span</li></ul><h3 id="_6-33-3-whu-building-change-detection" tabindex="-1">6.33.3. WHU Building Change Detection <a class="header-anchor" href="#_6-33-3-whu-building-change-detection" aria-label="Permalink to &quot;6.33.3. WHU Building Change Detection&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Attribute</th><th>Value</th></tr></thead><tbody><tr><td><strong>Source</strong></td><td>Aerial imagery</td></tr><tr><td><strong>Pairs</strong></td><td>1 pair</td></tr><tr><td><strong>Size</strong></td><td>32507×15354 pixels</td></tr><tr><td><strong>Resolution</strong></td><td>0.075m</td></tr><tr><td><strong>Classes</strong></td><td>Binary</td></tr></tbody></table><p><strong>Đặc điểm:</strong></p><ul><li>Very high resolution</li><li>Building change only</li><li>Single large area</li></ul><h3 id="_6-33-4-second-semantic-change-detection-dataset" tabindex="-1">6.33.4. SECOND (Semantic Change Detection Dataset) <a class="header-anchor" href="#_6-33-4-second-semantic-change-detection-dataset" aria-label="Permalink to &quot;6.33.4. SECOND (Semantic Change Detection Dataset)&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Attribute</th><th>Value</th></tr></thead><tbody><tr><td><strong>Source</strong></td><td>Aerial imagery</td></tr><tr><td><strong>Pairs</strong></td><td>4662 pairs</td></tr><tr><td><strong>Size</strong></td><td>512×512 pixels</td></tr><tr><td><strong>Classes</strong></td><td>6 semantic changes</td></tr></tbody></table><p><strong>Classes:</strong></p><ul><li>No change</li><li>Change to low vegetation</li><li>Change to trees</li><li>Change to water</li><li>Change to playgrounds</li><li>Change to buildings</li></ul><h3 id="_6-33-5-xview2" tabindex="-1">6.33.5. xView2 <a class="header-anchor" href="#_6-33-5-xview2" aria-label="Permalink to &quot;6.33.5. xView2&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Attribute</th><th>Value</th></tr></thead><tbody><tr><td><strong>Source</strong></td><td>WorldView, GeoEye</td></tr><tr><td><strong>Task</strong></td><td>Building damage assessment</td></tr><tr><td><strong>Classes</strong></td><td>4 damage levels</td></tr><tr><td><strong>Events</strong></td><td>Multiple natural disasters</td></tr></tbody></table><p><strong>Classes:</strong></p><ul><li>No damage</li><li>Minor damage</li><li>Major damage</li><li>Destroyed</li></ul><p><strong>Đặc điểm:</strong></p><ul><li>Real disaster events</li><li>Pre và post-disaster imagery</li><li>Building-level damage assessment</li></ul><h3 id="_6-33-6-spacenet-7" tabindex="-1">6.33.6. SpaceNet 7 <a class="header-anchor" href="#_6-33-6-spacenet-7" aria-label="Permalink to &quot;6.33.6. SpaceNet 7&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Attribute</th><th>Value</th></tr></thead><tbody><tr><td><strong>Source</strong></td><td>Planet</td></tr><tr><td><strong>Task</strong></td><td>Monthly building change</td></tr><tr><td><strong>Duration</strong></td><td>24 months</td></tr><tr><td><strong>Coverage</strong></td><td>100 global sites</td></tr></tbody></table><p><strong>Đặc điểm:</strong></p><ul><li>Multi-temporal (not just bi-temporal)</li><li>Monthly observations</li><li>Building tracking over time</li></ul><h2 id="_6-34-training-change-detection-models" tabindex="-1">6.34. Training Change Detection Models <a class="header-anchor" href="#_6-34-training-change-detection-models" aria-label="Permalink to &quot;6.34. Training Change Detection Models&quot;">​</a></h2><h3 id="_6-34-1-data-loading" tabindex="-1">6.34.1. Data Loading <a class="header-anchor" href="#_6-34-1-data-loading" aria-label="Permalink to &quot;6.34.1. Data Loading&quot;">​</a></h3><p><strong>Bi-temporal Loading:</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># Load paired images</span></span>
<span class="line"><span>sample = {</span></span>
<span class="line"><span>    &quot;image1&quot;: preprocess(load(path_t1)),</span></span>
<span class="line"><span>    &quot;image2&quot;: preprocess(load(path_t2)),</span></span>
<span class="line"><span>    &quot;mask&quot;: load(change_mask)</span></span>
<span class="line"><span>}</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p><strong>TorchGeo Approach:</strong></p><ul><li>Sử dụng custom dataset hoặc adapt existing</li><li>Handle temporal alignment</li><li>Consistent preprocessing</li></ul><h3 id="_6-34-2-augmentation" tabindex="-1">6.34.2. Augmentation <a class="header-anchor" href="#_6-34-2-augmentation" aria-label="Permalink to &quot;6.34.2. Augmentation&quot;">​</a></h3><p><strong>Paired Augmentation:</strong></p><ul><li>Apply same geometric transform to both images</li><li>Ensures spatial alignment maintained</li><li>Photometric can differ (different acquisition conditions)</li></ul><p><strong>Recommended Augmentations:</strong></p><ul><li>Random flip (same for both)</li><li>Random rotation (same for both)</li><li>Random crop (same for both)</li><li>Color jittering (separate for each, mimics condition variation)</li></ul><h3 id="_6-34-3-loss-functions" tabindex="-1">6.34.3. Loss Functions <a class="header-anchor" href="#_6-34-3-loss-functions" aria-label="Permalink to &quot;6.34.3. Loss Functions&quot;">​</a></h3><p><strong>Binary Cross Entropy:</strong> Standard cho binary change detection.</p><p><strong>Focal Loss:</strong> Handles severe class imbalance (most pixels unchanged).</p><p><strong>Dice Loss:</strong> Better for imbalanced segmentation.</p><p><strong>Combined Loss:</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>L = α * BCE + β * Dice</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><h3 id="_6-34-4-class-imbalance" tabindex="-1">6.34.4. Class Imbalance <a class="header-anchor" href="#_6-34-4-class-imbalance" aria-label="Permalink to &quot;6.34.4. Class Imbalance&quot;">​</a></h3><p>Change detection has extreme imbalance (typically &lt;5% change):</p><p><strong>Strategies:</strong></p><ul><li>Focal Loss với appropriate γ</li><li>Class weighting</li><li>Over-sampling change areas</li><li>Patch selection biased toward change</li></ul><h3 id="_6-34-5-evaluation-metrics" tabindex="-1">6.34.5. Evaluation Metrics <a class="header-anchor" href="#_6-34-5-evaluation-metrics" aria-label="Permalink to &quot;6.34.5. Evaluation Metrics&quot;">​</a></h3><p><strong>Pixel-level:</strong></p><ul><li>Precision, Recall, F1</li><li>IoU (Intersection over Union)</li><li>Overall Accuracy</li><li>Kappa coefficient</li></ul><p><strong>Object-level:</strong></p><ul><li>Detection rate</li><li>False alarm rate</li><li>Per-change accuracy</li></ul><h2 id="_6-35-pre-trained-models-cho-change-detection" tabindex="-1">6.35. Pre-trained Models cho Change Detection <a class="header-anchor" href="#_6-35-pre-trained-models-cho-change-detection" aria-label="Permalink to &quot;6.35. Pre-trained Models cho Change Detection&quot;">​</a></h2><h3 id="_6-35-1-transfer-tu-classification-segmentation" tabindex="-1">6.35.1. Transfer từ Classification/Segmentation <a class="header-anchor" href="#_6-35-1-transfer-tu-classification-segmentation" aria-label="Permalink to &quot;6.35.1. Transfer từ Classification/Segmentation&quot;">​</a></h3><p>Using pre-trained encoders:</p><ul><li>Load SSL4EO hoặc similar weights</li><li>Use as encoder in Siamese/U-Net architecture</li><li>Fine-tune for change detection</li></ul><p><strong>Approach:</strong></p><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># Pre-trained encoder</span></span>
<span class="line"><span>encoder = resnet50(weights=SSL4EO_WEIGHTS)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># Siamese change detection</span></span>
<span class="line"><span>class SiameseCD(nn.Module):</span></span>
<span class="line"><span>    def __init__(self, encoder):</span></span>
<span class="line"><span>        self.encoder = encoder</span></span>
<span class="line"><span>        self.decoder = build_decoder()</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    def forward(self, x1, x2):</span></span>
<span class="line"><span>        f1 = self.encoder(x1)</span></span>
<span class="line"><span>        f2 = self.encoder(x2)</span></span>
<span class="line"><span>        diff = torch.abs(f1 - f2)</span></span>
<span class="line"><span>        return self.decoder(diff)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><h3 id="_6-35-2-change-detection-specific-pre-training" tabindex="-1">6.35.2. Change Detection Specific Pre-training <a class="header-anchor" href="#_6-35-2-change-detection-specific-pre-training" aria-label="Permalink to &quot;6.35.2. Change Detection Specific Pre-training&quot;">​</a></h3><p>Emerging approaches:</p><ul><li>Self-supervised với temporal data</li><li>Contrastive learning across time</li><li>Masked autoencoder for change</li></ul><h3 id="_6-35-3-available-implementations" tabindex="-1">6.35.3. Available Implementations <a class="header-anchor" href="#_6-35-3-available-implementations" aria-label="Permalink to &quot;6.35.3. Available Implementations&quot;">​</a></h3><p>TorchGeo integrates với:</p><ul><li><strong>OpenCD:</strong> Open source change detection toolbox</li><li><strong>Custom implementations:</strong> For common architectures</li><li><strong>torchvision compatibility:</strong> Leverage existing models</li></ul><h2 id="_6-36-benchmark-results" tabindex="-1">6.36. Benchmark Results <a class="header-anchor" href="#_6-36-benchmark-results" aria-label="Permalink to &quot;6.36. Benchmark Results&quot;">​</a></h2><h3 id="_6-36-1-oscd-results" tabindex="-1">6.36.1. OSCD Results <a class="header-anchor" href="#_6-36-1-oscd-results" aria-label="Permalink to &quot;6.36.1. OSCD Results&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Model</th><th>F1</th><th>IoU</th></tr></thead><tbody><tr><td>FC-EF</td><td>23.0</td><td>13.0</td></tr><tr><td>FC-Siam-Diff</td><td>28.5</td><td>16.6</td></tr><tr><td>U-Net CD</td><td>35.2</td><td>21.4</td></tr><tr><td>BIT</td><td>52.1</td><td>35.2</td></tr></tbody></table><h3 id="_6-36-2-levir-cd-results" tabindex="-1">6.36.2. LEVIR-CD Results <a class="header-anchor" href="#_6-36-2-levir-cd-results" aria-label="Permalink to &quot;6.36.2. LEVIR-CD Results&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Model</th><th>F1</th><th>IoU</th></tr></thead><tbody><tr><td>FC-Siam-Conc</td><td>83.4</td><td>71.6</td></tr><tr><td>FC-Siam-Diff</td><td>86.3</td><td>75.9</td></tr><tr><td>DTCDSCN</td><td>87.8</td><td>78.3</td></tr><tr><td>BIT</td><td>89.3</td><td>80.7</td></tr></tbody></table><h3 id="_6-36-3-xview2-results" tabindex="-1">6.36.3. xView2 Results <a class="header-anchor" href="#_6-36-3-xview2-results" aria-label="Permalink to &quot;6.36.3. xView2 Results&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Model</th><th>F1 Localization</th><th>F1 Classification</th></tr></thead><tbody><tr><td>U-Net baseline</td><td>75.0</td><td>42.0</td></tr><tr><td>HRNet</td><td>82.5</td><td>53.2</td></tr><tr><td>Competition winners</td><td>88.0</td><td>65.0</td></tr></tbody></table><h2 id="_6-37-advanced-topics" tabindex="-1">6.37. Advanced Topics <a class="header-anchor" href="#_6-37-advanced-topics" aria-label="Permalink to &quot;6.37. Advanced Topics&quot;">​</a></h2><h3 id="_6-37-1-multi-temporal-change-detection" tabindex="-1">6.37.1. Multi-temporal Change Detection <a class="header-anchor" href="#_6-37-1-multi-temporal-change-detection" aria-label="Permalink to &quot;6.37.1. Multi-temporal Change Detection&quot;">​</a></h3><p>Beyond bi-temporal:</p><p><strong>Time Series Processing:</strong></p><ul><li>3D convolutions</li><li>Recurrent networks (LSTM, GRU)</li><li>Temporal attention</li></ul><p><strong>Architectures:</strong></p><ul><li>ConvLSTM-based change detection</li><li>Temporal Transformer</li><li>U-TAE (U-Net with Temporal Attention)</li></ul><p><strong>Applications:</strong></p><ul><li>Continuous monitoring</li><li>Change trajectory analysis</li><li>Anomaly detection in time series</li></ul><h3 id="_6-37-2-multi-sensor-change-detection" tabindex="-1">6.37.2. Multi-sensor Change Detection <a class="header-anchor" href="#_6-37-2-multi-sensor-change-detection" aria-label="Permalink to &quot;6.37.2. Multi-sensor Change Detection&quot;">​</a></h3><p>Using different sensors at t1 và t2:</p><p><strong>Challenges:</strong></p><ul><li>Different spectral bands</li><li>Different resolutions</li><li>Different viewing geometries</li></ul><p><strong>Approaches:</strong></p><ul><li>Sensor-specific encoders</li><li>Domain adaptation</li><li>Learned alignment</li></ul><h3 id="_6-37-3-unsupervised-change-detection" tabindex="-1">6.37.3. Unsupervised Change Detection <a class="header-anchor" href="#_6-37-3-unsupervised-change-detection" aria-label="Permalink to &quot;6.37.3. Unsupervised Change Detection&quot;">​</a></h3><p>When labels unavailable:</p><p><strong>Deep Learning Approaches:</strong></p><ul><li>Autoencoder-based (reconstruction error as change)</li><li>Deep clustering</li><li>Self-supervised with pseudo-labels</li></ul><p><strong>Traditional (for comparison):</strong></p><ul><li>Image differencing</li><li>CVA (Change Vector Analysis)</li><li>PCA-based methods</li></ul><h3 id="_6-37-4-weakly-supervised-change-detection" tabindex="-1">6.37.4. Weakly Supervised Change Detection <a class="header-anchor" href="#_6-37-4-weakly-supervised-change-detection" aria-label="Permalink to &quot;6.37.4. Weakly Supervised Change Detection&quot;">​</a></h3><p>With limited labels:</p><p><strong>Approaches:</strong></p><ul><li>Image-level labels (change exists or not)</li><li>Partial pixel labels</li><li>Active learning for annotation</li><li>Semi-supervised methods</li></ul><h2 id="_6-38-use-cases" tabindex="-1">6.38. Use Cases <a class="header-anchor" href="#_6-38-use-cases" aria-label="Permalink to &quot;6.38. Use Cases&quot;">​</a></h2><h3 id="_6-38-1-urban-expansion-monitoring" tabindex="-1">6.38.1. Urban Expansion Monitoring <a class="header-anchor" href="#_6-38-1-urban-expansion-monitoring" aria-label="Permalink to &quot;6.38.1. Urban Expansion Monitoring&quot;">​</a></h3><p><strong>Objective:</strong> Track city growth over time.</p><p><strong>Approach:</strong></p><ul><li>Annual or multi-year intervals</li><li>Building và impervious surface detection</li><li>Semantic change (vegetation → urban)</li></ul><p><strong>Data:</strong></p><ul><li>Sentinel-2 hoặc high-resolution</li><li>LEVIR-CD type training</li></ul><h3 id="_6-38-2-disaster-damage-assessment" tabindex="-1">6.38.2. Disaster Damage Assessment <a class="header-anchor" href="#_6-38-2-disaster-damage-assessment" aria-label="Permalink to &quot;6.38.2. Disaster Damage Assessment&quot;">​</a></h3><p><strong>Objective:</strong> Rapidly assess damage after disasters.</p><p><strong>Approach:</strong></p><ul><li>Pre-event baseline imagery</li><li>Post-event rapid acquisition</li><li>Building damage classification</li></ul><p><strong>Data:</strong></p><ul><li>xView2 training</li><li>Various satellite sources</li><li>Rapid response requirement</li></ul><h3 id="_6-38-3-deforestation-monitoring" tabindex="-1">6.38.3. Deforestation Monitoring <a class="header-anchor" href="#_6-38-3-deforestation-monitoring" aria-label="Permalink to &quot;6.38.3. Deforestation Monitoring&quot;">​</a></h3><p><strong>Objective:</strong> Detect forest loss.</p><p><strong>Approach:</strong></p><ul><li>Regular (monthly/quarterly) monitoring</li><li>Binary change (forest → non-forest)</li><li>Alert generation</li></ul><p><strong>Data:</strong></p><ul><li>Sentinel-1 (SAR, all-weather)</li><li>Sentinel-2 (optical)</li><li>Landsat (historical)</li></ul><h3 id="_6-38-4-agricultural-change" tabindex="-1">6.38.4. Agricultural Change <a class="header-anchor" href="#_6-38-4-agricultural-change" aria-label="Permalink to &quot;6.38.4. Agricultural Change&quot;">​</a></h3><p><strong>Objective:</strong> Monitor agricultural practices và land use.</p><p><strong>Approach:</strong></p><ul><li>Seasonal comparison</li><li>Crop rotation detection</li><li>Field boundary changes</li></ul><p><strong>Data:</strong></p><ul><li>Multi-temporal Sentinel-2</li><li>Crop type ground truth</li><li>Agricultural calendars</li></ul><h3 id="_6-38-5-coastal-erosion-monitoring" tabindex="-1">6.38.5. Coastal Erosion Monitoring <a class="header-anchor" href="#_6-38-5-coastal-erosion-monitoring" aria-label="Permalink to &quot;6.38.5. Coastal Erosion Monitoring&quot;">​</a></h3><p><strong>Objective:</strong> Track shoreline changes.</p><p><strong>Approach:</strong></p><ul><li>Annual hoặc seasonal comparison</li><li>Land-water boundary detection</li><li>Long-term trend analysis</li></ul><p><strong>Data:</strong></p><ul><li>Sentinel-2, Landsat</li><li>Historical archives</li><li>Tide-normalized selection</li></ul><h2 id="_6-39-implementation-trong-torchgeo" tabindex="-1">6.39. Implementation trong TorchGeo <a class="header-anchor" href="#_6-39-implementation-trong-torchgeo" aria-label="Permalink to &quot;6.39. Implementation trong TorchGeo&quot;">​</a></h2><h3 id="_6-39-1-loading-change-detection-data" tabindex="-1">6.39.1. Loading Change Detection Data <a class="header-anchor" href="#_6-39-1-loading-change-detection-data" aria-label="Permalink to &quot;6.39.1. Loading Change Detection Data&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Using OSCD dataset</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torchgeo.datasets </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> OSCD</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">dataset </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OSCD(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">root</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;data&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">split</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;train&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sample </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dataset:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    image1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sample[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;image1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Pre-change</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    image2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sample[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;image2&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Post-change</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sample[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;mask&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]      </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Change mask</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><h3 id="_6-39-2-custom-change-detection-dataset" tabindex="-1">6.39.2. Custom Change Detection Dataset <a class="header-anchor" href="#_6-39-2-custom-change-detection-dataset" aria-label="Permalink to &quot;6.39.2. Custom Change Detection Dataset&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> CustomChangeDataset</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">torch</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">utils</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">data</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Dataset</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, root, transform</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.pairs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> load_pairs(root)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.transform </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> transform</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __getitem__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, idx):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        t1_path, t2_path, mask_path </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.pairs[idx]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        sample </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;image1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: load_image(t1_path),</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;image2&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: load_image(t2_path),</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;mask&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: load_mask(mask_path)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        }</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.transform:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            sample </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.transform(sample)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sample</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><h3 id="_6-39-3-model-training" tabindex="-1">6.39.3. Model Training <a class="header-anchor" href="#_6-39-3-model-training" aria-label="Permalink to &quot;6.39.3. Model Training&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Simple change detection training</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> SiameseUNet(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">encoder</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;resnet50&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">pretrained</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">criterion </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> FocalLoss()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">optimizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Adam(model.parameters(), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">lr</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> epoch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(epochs):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> batch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dataloader:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        img1, img2, mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> batch[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;image1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], batch[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;image2&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], batch[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;mask&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        pred </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model(img1, img2)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> criterion(pred, mask)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        optimizer.zero_grad()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        loss.backward()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        optimizer.step()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><p>Change detection trong TorchGeo enables powerful temporal analysis of Earth observation data, supporting critical applications từ urban planning to disaster response.</p>`,208)])])}const u=s(t,[["render",l]]);export{g as __pageData,u as default};
