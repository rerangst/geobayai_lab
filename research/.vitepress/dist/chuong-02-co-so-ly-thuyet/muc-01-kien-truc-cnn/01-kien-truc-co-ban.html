<!DOCTYPE html>
<html lang="vi-VN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Chương 2: Kiến trúc Convolutional Neural Network Cơ bản | Deep Learning trong Viễn thám</title>
    <meta name="description" content="Nghiên cứu ứng dụng CNN và Deep Learning trong phân tích ảnh viễn thám">
    <meta name="generator" content="VitePress v1.6.4">
    <link rel="preload stylesheet" href="/sen_doc/assets/style.W3JISx3E.css" as="style">
    <link rel="preload stylesheet" href="/sen_doc/vp-icons.css" as="style">
    
    <script type="module" src="/sen_doc/assets/app.CC91Ong8.js"></script>
    <link rel="preload" href="/sen_doc/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/framework.nRfFlDZQ.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/theme._C7CsDik.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/katex.Cu_Erd72.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/dagre-6UL2VRFP.DfaksD8U.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/cose-bilkent-S5V4N54A.BYPSb5FJ.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/c4Diagram-YG6GDRKO.dJjRNUt_.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/flowDiagram-NV44I4VS.DuzLVa0O.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/erDiagram-Q2GNP2WA.BAfvgf_C.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/gitGraphDiagram-NY62KEGX.D1RzsIM8.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/ganttDiagram-JELNMOA3.Dq6LY6bS.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/infoDiagram-WHAUD3N6.BJQBPuj7.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/pieDiagram-ADFJNKIX.DxDfrbqc.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/quadrantDiagram-AYHSOK5B.kQ9GqljE.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/xychartDiagram-PRI3JC2R.ZdU-PVOa.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/requirementDiagram-UZGBJVZJ.BomXZlm3.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/sequenceDiagram-WL72ISMW.C9fvGbCt.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/classDiagram-2ON5EDUG.3u7eY1R8.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/classDiagram-v2-WZHVMYZB.3u7eY1R8.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/stateDiagram-FKZM4ZOC.BP3qoQlt.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/stateDiagram-v2-4FDKWEC3.DCa7S_Zi.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/journeyDiagram-XKPGCS4Q.Cgruk6ZT.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/timeline-definition-IT6M3QCI.B-w43BkB.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/mindmap-definition-VGOIOE7T.D2bibyG1.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/kanban-definition-3W4ZIXB7.qErJgjGR.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/sankeyDiagram-TZEHDZUN.qJdUpJAZ.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/diagram-S2PKOQOG.C1cLAlO0.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/diagram-QEK2KX5R.BmPmLRV5.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/blockDiagram-VD42YOAC.3ATsMDgc.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/architectureDiagram-VXUJARFQ.DoTHGRZ2.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/diagram-PSM6KHXK.ByynVTNu.js">
    <link rel="modulepreload" href="/sen_doc/assets/chunks/virtual_mermaid-config.CQTEIV6y.js">
    <link rel="modulepreload" href="/sen_doc/assets/chuong-02-co-so-ly-thuyet_muc-01-kien-truc-cnn_01-kien-truc-co-ban.md.D11mryt7.lean.js">
    <meta name="theme-color" content="#3eaf7c">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5d98c3a5><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0b0ada53></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0b0ada53>Skip to content</a><!--]--><!----><header class="VPNav" data-v-5d98c3a5 data-v-ae24b3ad><div class="VPNavBar" data-v-ae24b3ad data-v-6aa21345><div class="wrapper" data-v-6aa21345><div class="container" data-v-6aa21345><div class="title" data-v-6aa21345><div class="VPNavBarTitle has-sidebar" data-v-6aa21345 data-v-1168a8e4><a class="title" href="/sen_doc/" data-v-1168a8e4><!--[--><!--]--><!----><span data-v-1168a8e4>Deep Learning trong Viễn thám</span><!--[--><!--]--></a></div></div><div class="content" data-v-6aa21345><div class="content-body" data-v-6aa21345><!--[--><!--]--><div class="VPNavBarSearch search" data-v-6aa21345><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-6aa21345 data-v-dc692963><span id="main-nav-aria-label" class="visually-hidden" data-v-dc692963> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/sen_doc/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Trang chủ</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/sen_doc/chuong-01-gioi-thieu/muc-01-tong-quan/01-gioi-thieu-cnn-deep-learning.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Giới thiệu</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/sen_doc/chuong-03-kien-truc-model/muc-01-tong-quan/01-tong-quan.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Kiến trúc Model</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/sen_doc/chuong-04-xview-challenges/00-gioi-thieu-xview.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>xView</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/sen_doc/chuong-05-ung-dung-tau-bien/muc-01-dac-diem-bai-toan/01-dac-diem.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Ứng dụng</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-6aa21345 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-6aa21345 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/tchatb/sen_doc" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-6aa21345 data-v-bb2aa2f0 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-cf11d7a2><span class="vpi-more-horizontal icon" data-v-cf11d7a2></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><!----><!--[--><!--[--><!----><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>Giao diện</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/tchatb/sen_doc" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-6aa21345 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-6aa21345><div class="divider-line" data-v-6aa21345></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-5d98c3a5 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-8a42e2b4><button data-v-8a42e2b4>Về đầu trang</button><!----></div></div></div><aside class="VPSidebar" data-v-5d98c3a5 data-v-319d5ca6><div class="curtain" data-v-319d5ca6></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-319d5ca6><span class="visually-hidden" id="sidebar-aria-label" data-v-319d5ca6> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 1: Giới thiệu</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-01-gioi-thieu/muc-01-tong-quan/01-gioi-thieu-cnn-deep-learning.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>1.1. Tổng quan CNN & Deep Learning</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible has-active" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 2: Cơ sở lý thuyết</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-01-kien-truc-cnn/01-kien-truc-co-ban.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.1.1. Kiến trúc CNN cơ bản</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-01-kien-truc-cnn/02-backbone-networks.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.1.2. Backbone Networks</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/01-phan-loai-anh.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.2.1. Phân loại ảnh</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/02-phat-hien-doi-tuong.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.2.2. Phát hiện đối tượng</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/03-phan-doan-ngu-nghia.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.2.3. Phân đoạn ngữ nghĩa</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/04-instance-segmentation.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>2.2.4. Instance Segmentation</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible collapsed" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 3: Kiến trúc Mô hình</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-03-kien-truc-model/muc-01-tong-quan/01-tong-quan.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>3.1. Tổng quan TorchGeo</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-03-kien-truc-model/muc-02-classification/01-classification-models.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>3.2. Classification Models</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-03-kien-truc-model/muc-03-segmentation/01-segmentation-models.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>3.3. Segmentation Models</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-03-kien-truc-model/muc-04-change-detection/01-change-detection-models.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>3.4. Change Detection</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-03-kien-truc-model/muc-05-pretrained-weights/01-pretrained-weights.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>3.5. Pre-trained Weights</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 4: xView Challenges</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/00-gioi-thieu-xview.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giới thiệu xView</p><!--]--></a><!----></div><!----></div><section class="VPSidebarItem level-1 collapsible collapsed" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h3 class="text" data-v-b3fd67f8>4.1. xView1 - Object Detection</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/muc-01-xview1-object-detection/01-dataset.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/muc-01-xview1-object-detection/02-giai-nhat.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhất</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/muc-01-xview1-object-detection/03-giai-nhi.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhì</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/muc-01-xview1-object-detection/04-giai-ba.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải ba</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/muc-01-xview1-object-detection/05-giai-tu.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải tư</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/muc-01-xview1-object-detection/06-giai-nam.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải năm</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible collapsed" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h3 class="text" data-v-b3fd67f8>4.2. xView2 - Building Damage</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/muc-02-xview2-building-damage/01-dataset.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Dataset (xBD)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/muc-02-xview2-building-damage/02-giai-nhat.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhất</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/muc-02-xview2-building-damage/03-giai-nhi.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhì</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/muc-02-xview2-building-damage/04-giai-ba.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải ba</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/muc-02-xview2-building-damage/05-giai-tu.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải tư</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/muc-02-xview2-building-damage/06-giai-nam.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải năm</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible collapsed" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h3 class="text" data-v-b3fd67f8>4.3. xView3 - Maritime (SAR)</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/muc-03-xview3-maritime/01-dataset.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Dataset</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/muc-03-xview3-maritime/02-giai-nhat.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhất</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/muc-03-xview3-maritime/03-giai-nhi.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải nhì</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/muc-03-xview3-maritime/04-giai-ba.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải ba</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/muc-03-xview3-maritime/05-giai-tu.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải tư</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-04-xview-challenges/muc-03-xview3-maritime/06-giai-nam.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Giải năm</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible collapsed" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 5: Phát hiện Tàu biển</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-ung-dung-tau-bien/muc-01-dac-diem-bai-toan/01-dac-diem.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.1. Đặc điểm bài toán</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-ung-dung-tau-bien/muc-02-mo-hinh/01-cac-mo-hinh.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.2. Các mô hình</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-ung-dung-tau-bien/muc-03-quy-trinh/01-pipeline.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.3. Quy trình xử lý</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-05-ung-dung-tau-bien/muc-04-bo-du-lieu/01-datasets.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>5.4. Bộ dữ liệu</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible collapsed" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 6: Phát hiện Dầu loang</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-ung-dung-dau-loang/muc-01-dac-diem-bai-toan/01-dac-diem.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>6.1. Đặc điểm bài toán</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-ung-dung-dau-loang/muc-02-mo-hinh/01-cac-mo-hinh.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>6.2. Các mô hình</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-ung-dung-dau-loang/muc-03-quy-trinh/01-pipeline.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>6.3. Quy trình xử lý</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-06-ung-dung-dau-loang/muc-04-bo-du-lieu/01-datasets.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>6.4. Bộ dữ liệu</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Chương 7: Kết luận</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/sen_doc/chuong-07-ket-luan/muc-01-tong-ket/01-ket-luan.html" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>7.1. Tổng kết</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5d98c3a5 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-a5bbad30><div class="content" data-v-a5bbad30><div class="outline-marker" data-v-a5bbad30></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a5bbad30>Mục lục trang</div><ul class="VPDocOutlineItem root" data-v-a5bbad30 data-v-b933a997><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _sen_doc_chuong-02-co-so-ly-thuyet_muc-01-kien-truc-cnn_01-kien-truc-co-ban" data-v-39a288b8><div><h1 id="chuong-2-kien-truc-convolutional-neural-network-co-ban" tabindex="-1">Chương 2: Kiến trúc Convolutional Neural Network Cơ bản <a class="header-anchor" href="#chuong-2-kien-truc-convolutional-neural-network-co-ban" aria-label="Permalink to &quot;Chương 2: Kiến trúc Convolutional Neural Network Cơ bản&quot;">​</a></h1><h2 id="gioi-thieu" tabindex="-1">Giới thiệu <a class="header-anchor" href="#gioi-thieu" aria-label="Permalink to &quot;Giới thiệu&quot;">​</a></h2><p>Sau khi đã nắm được bối cảnh và mục tiêu nghiên cứu ở <strong>Chương 1</strong>, chương này trình bày cơ sở lý thuyết về mạng CNN và các phương pháp xử lý ảnh viễn thám. Đây là nền tảng kiến thức cần thiết để hiểu các kiến trúc mô hình cụ thể được giới thiệu ở <strong>Chương 5</strong> (TorchGeo) và các giải pháp từ cuộc thi <strong>Chương 6</strong> (xView Challenges).</p><p>Chương này được chia thành hai mục chính: <strong>Mục 2.1</strong> trình bày kiến trúc CNN cơ bản và các mạng backbone hiện đại, <strong>Mục 2.2</strong> giới thiệu các phương pháp xử lý ảnh bao gồm classification, object detection, semantic segmentation, và instance segmentation.</p><h2 id="_2-1-tong-quan-ve-kien-truc-cnn" tabindex="-1">2.1. Tổng quan về Kiến trúc CNN <a class="header-anchor" href="#_2-1-tong-quan-ve-kien-truc-cnn" aria-label="Permalink to &quot;2.1. Tổng quan về Kiến trúc CNN&quot;">​</a></h2><p>Convolutional Neural Network (CNN) là một kiến trúc mạng nơ-ron được thiết kế đặc biệt để xử lý dữ liệu có cấu trúc không gian, điển hình là ảnh số. Khác với mạng nơ-ron fully connected truyền thống vốn xử lý đầu vào như một vector phẳng, CNN bảo toàn cấu trúc không gian của dữ liệu thông qua việc sử dụng các phép toán convolution. Điều này cho phép mạng học được các đặc trưng có ý nghĩa về mặt không gian như cạnh, góc, kết cấu, và hình dạng đối tượng.</p><h3 id="_2-1-1-tai-sao-can-cnn-thay-vi-mang-fully-connected" tabindex="-1">2.1.1. Tại sao cần CNN thay vì mạng Fully Connected? <a class="header-anchor" href="#_2-1-1-tai-sao-can-cnn-thay-vi-mang-fully-connected" aria-label="Permalink to &quot;2.1.1. Tại sao cần CNN thay vì mạng Fully Connected?&quot;">​</a></h3><p>Việc sử dụng Multilayer Perceptron (MLP) cho xử lý ảnh gặp phải vấn đề nghiêm trọng về số lượng tham số [1]. Xét một ảnh có kích thước khiêm tốn 100×100 pixel với 3 kênh màu RGB, ta có 30,000 giá trị đầu vào. Nếu sử dụng một lớp ẩn với 1,000 nơ-ron, số lượng tham số kết nối đã lên tới 30 triệu.</p><p><strong>Thách thức trong viễn thám:</strong> Ảnh vệ tinh thường có độ phân giải và số kênh phổ cao hơn đáng kể so với ảnh tự nhiên. Ảnh Sentinel-2 có 13 kênh phổ với độ phân giải 10-60m, ảnh WorldView-3 có 16 kênh với độ phân giải 0.3-1.2m. Một tile ảnh Sentinel-2 kích thước 512×512×13 chứa hơn 3 triệu giá trị - việc sử dụng MLP trở nên hoàn toàn không khả thi.</p><div class="mermaid"></div><p>CNN giải quyết vấn đề này dựa trên hai nguyên lý quan trọng:</p><p><strong>Tính bất biến với phép tịnh tiến (Translation Invariance):</strong> Một đặc trưng có ý nghĩa (ví dụ: cạnh của tàu biển) nên được nhận dạng bất kể nó xuất hiện ở vị trí nào trong ảnh. CNN đạt được điều này bằng cách sử dụng cùng một bộ lọc trượt qua toàn bộ ảnh, thay vì học các tham số riêng biệt cho từng vị trí.</p><p><strong>Tính cục bộ (Locality):</strong> Các đặc trưng thị giác cơ bản như cạnh, góc, và kết cấu phụ thuộc vào các pixel lân cận, không phụ thuộc vào các pixel ở xa. CNN khai thác điều này bằng cách hạn chế mỗi nơ-ron chỉ &quot;nhìn thấy&quot; một vùng nhỏ của ảnh đầu vào, gọi là receptive field cục bộ.</p><h3 id="_2-1-2-cau-truc-phan-cap-cua-cnn" tabindex="-1">2.1.2. Cấu trúc phân cấp của CNN <a class="header-anchor" href="#_2-1-2-cau-truc-phan-cap-cua-cnn" aria-label="Permalink to &quot;2.1.2. Cấu trúc phân cấp của CNN&quot;">​</a></h3><p>Một mạng CNN điển hình được cấu thành từ nhiều lớp xếp chồng lên nhau, mỗi lớp thực hiện một phép biến đổi cụ thể. Kiến trúc này có thể được hình dung như một pipeline xử lý phân cấp:</p><div class="mermaid"></div><p>Các lớp đầu học được các đặc trưng cấp thấp như cạnh theo nhiều hướng và thay đổi cường độ sáng. Các lớp giữa kết hợp các đặc trưng cấp thấp để tạo thành các pattern phức tạp hơn như kết cấu bề mặt nước hay góc của công trình. Các lớp sâu hơn học được các đặc trưng ngữ nghĩa cao như hình dạng tàu biển hay vùng dầu loang.</p><h2 id="_2-2-phep-toan-tuong-quan-cheo-cross-correlation" tabindex="-1">2.2. Phép toán Tương quan chéo (Cross-Correlation) <a class="header-anchor" href="#_2-2-phep-toan-tuong-quan-cheo-cross-correlation" aria-label="Permalink to &quot;2.2. Phép toán Tương quan chéo (Cross-Correlation)&quot;">​</a></h2><h3 id="_2-2-1-đinh-nghia-va-cong-thuc" tabindex="-1">2.2.1. Định nghĩa và Công thức <a class="header-anchor" href="#_2-2-1-đinh-nghia-va-cong-thuc" aria-label="Permalink to &quot;2.2.1. Định nghĩa và Công thức&quot;">​</a></h3><p>Phép toán cốt lõi trong lớp convolution thực chất là <strong>tương quan chéo (cross-correlation)</strong> chứ không phải tích chập (convolution) theo nghĩa toán học thuần túy [1]. Tuy nhiên, trong lĩnh vực học sâu, hai thuật ngữ này thường được sử dụng thay thế cho nhau do sự khác biệt chỉ nằm ở việc lật kernel, điều không ảnh hưởng đến khả năng học của mạng.</p><p>Xét đầu vào là ma trận hai chiều <strong>X</strong> có kích thước n_h × n_w và bộ lọc (kernel) <strong>K</strong> có kích thước k_h × k_w. Phép tương quan chéo tạo ra output <strong>Y</strong> với kích thước:</p><p><strong>(n_h - k_h + 1) × (n_w - k_w + 1)</strong></p><p>Giá trị tại mỗi vị trí (i, j) của output được tính bằng cách:</p><ol><li>Đặt kernel chồng lên vùng tương ứng của input</li><li>Nhân từng phần tử (element-wise multiplication)</li><li>Cộng tất cả các tích lại với nhau</li></ol><h3 id="_2-2-2-minh-hoa-phep-tinh-voi-kernel-2×2" tabindex="-1">2.2.2. Minh họa Phép tính với Kernel 2×2 <a class="header-anchor" href="#_2-2-2-minh-hoa-phep-tinh-voi-kernel-2×2" aria-label="Permalink to &quot;2.2.2. Minh họa Phép tính với Kernel 2×2&quot;">​</a></h3><p>Dưới đây là ví dụ minh họa phép tương quan chéo với input 3×3 và kernel 2×2:</p><div class="mermaid"></div><p><strong>Tính giá trị đầu tiên (vị trí 0,0):</strong></p><ul><li>Vùng input được chọn: [[0,1], [3,4]]</li><li>Phép nhân element-wise với kernel: 0×0 + 1×1 + 3×2 + 4×3 = 0 + 1 + 6 + 12 = <strong>19</strong></li></ul><p><strong>Tính giá trị thứ hai (vị trí 0,1):</strong></p><ul><li>Kernel trượt sang phải 1 vị trí</li><li>Vùng input được chọn: [[1,2], [4,5]]</li><li>Phép tính: 1×0 + 2×1 + 4×2 + 5×3 = 0 + 2 + 8 + 15 = <strong>25</strong></li></ul><p>Tương tự, ta tính được các giá trị còn lại: 37 và 43.</p><h3 id="_2-2-3-ung-dung-phat-hien-canh" tabindex="-1">2.2.3. Ứng dụng: Phát hiện cạnh <a class="header-anchor" href="#_2-2-3-ung-dung-phat-hien-canh" aria-label="Permalink to &quot;2.2.3. Ứng dụng: Phát hiện cạnh&quot;">​</a></h3><p>Một ứng dụng kinh điển của phép convolution là phát hiện cạnh (edge detection). Xét kernel đơn giản [[1, -1]] để phát hiện cạnh dọc:</p><div class="mermaid"></div><ul><li>Tại vùng pixel đồng nhất (đều sáng hoặc đều tối): output = 0</li><li>Tại ranh giới sáng-tối: output = 1 (hoặc -1 nếu từ tối sang sáng)</li></ul><p>Điểm mạnh của CNN nằm ở khả năng <strong>học kernel tối ưu từ dữ liệu</strong> thông qua gradient descent, thay vì phải thiết kế thủ công [1]. Các thực nghiệm cho thấy kernel được học tự động có thể hội tụ về giá trị gần với kernel thiết kế thủ công sau một số iterations nhất định.</p><h2 id="_2-3-lop-convolution-convolutional-layer" tabindex="-1">2.3. Lớp Convolution (Convolutional Layer) <a class="header-anchor" href="#_2-3-lop-convolution-convolutional-layer" aria-label="Permalink to &quot;2.3. Lớp Convolution (Convolutional Layer)&quot;">​</a></h2><h3 id="_2-3-1-cac-tham-so-quan-trong" tabindex="-1">2.3.1. Các Tham số Quan trọng <a class="header-anchor" href="#_2-3-1-cac-tham-so-quan-trong" aria-label="Permalink to &quot;2.3.1. Các Tham số Quan trọng&quot;">​</a></h3><p><strong>Kích thước bộ lọc (Kernel Size):</strong> Quyết định receptive field cục bộ của mỗi nơ-ron. Các kích thước phổ biến bao gồm 3×3, 5×5, và 7×7. Bộ lọc 3×3 được sử dụng rộng rãi nhất trong các kiến trúc hiện đại vì có thể xếp chồng nhiều lớp 3×3 để đạt được receptive field tương đương bộ lọc lớn hơn, đồng thời giảm số lượng tham số và tăng khả năng biểu diễn phi tuyến [3].</p><div class="mermaid"></div><p><strong>So sánh số tham số:</strong></p><ul><li>2 lớp Conv 3×3: 2 × (3×3) = 18 tham số + thêm 1 ReLU</li><li>1 lớp Conv 5×5: 5×5 = 25 tham số</li></ul><p>Như vậy, việc xếp chồng kernel nhỏ không chỉ tiết kiệm tham số mà còn tăng khả năng biểu diễn phi tuyến nhờ các hàm kích hoạt xen kẽ giữa các lớp.</p><h3 id="_2-3-2-padding-đem" tabindex="-1">2.3.2. Padding (Đệm) <a class="header-anchor" href="#_2-3-2-padding-đem" aria-label="Permalink to &quot;2.3.2. Padding (Đệm)&quot;">​</a></h3><p>Khi áp dụng kernel k×k lên input n×n, output có kích thước (n-k+1)×(n-k+1), tức nhỏ hơn input. Sau nhiều lớp convolution liên tiếp, kích thước không gian giảm nhanh chóng và có thể dẫn đến mất thông tin ở biên ảnh.</p><p><strong>Padding</strong> là kỹ thuật thêm các pixel (thường có giá trị 0) vào viền ảnh đầu vào để kiểm soát kích thước output. Với padding p (mỗi bên), kích thước output trở thành:</p><p><strong>(n_h - k_h + 2p + 1) × (n_w - k_w + 2p + 1)</strong></p><div class="mermaid"></div><p><strong>Quy tắc thực hành:</strong> Để giữ nguyên kích thước không gian, đặt padding = (k-1)/2 với kernel kích thước k (k lẻ). Ví dụ: kernel 3×3 cần padding = 1, kernel 5×5 cần padding = 2.</p><h3 id="_2-3-3-stride-buoc-nhay" tabindex="-1">2.3.3. Stride (Bước nhảy) <a class="header-anchor" href="#_2-3-3-stride-buoc-nhay" aria-label="Permalink to &quot;2.3.3. Stride (Bước nhảy)&quot;">​</a></h3><p><strong>Stride</strong> xác định số pixel mà kernel di chuyển sau mỗi bước tính toán. Stride = 1 nghĩa là kernel trượt từng pixel một; stride = 2 nghĩa là kernel nhảy 2 pixel mỗi bước, làm giảm kích thước output xuống còn một nửa theo mỗi chiều.</p><p><strong>Công thức tổng quát với cả padding và stride:</strong></p><p>⌊(n_h - k_h + p_h + s_h) / s_h⌋ × ⌊(n_w - k_w + p_w + s_w) / s_w⌋</p><div class="mermaid"></div><p>Trong các kiến trúc hiện đại, stride &gt; 1 thường được sử dụng để giảm kích thước không gian thay cho pooling (gọi là strided convolution), cho phép mạng học cách downsampling tối ưu thay vì sử dụng phép toán cố định.</p><h3 id="_2-3-4-xu-ly-đa-kenh-multiple-channels" tabindex="-1">2.3.4. Xử lý Đa kênh (Multiple Channels) <a class="header-anchor" href="#_2-3-4-xu-ly-đa-kenh-multiple-channels" aria-label="Permalink to &quot;2.3.4. Xử lý Đa kênh (Multiple Channels)&quot;">​</a></h3><p>Ảnh thực tế thường có nhiều kênh: ảnh RGB có 3 kênh, ảnh vệ tinh đa phổ có thể có từ 4 đến 13 kênh hoặc hơn. Để xử lý input có c_i kênh, kernel phải có cùng số kênh: <strong>c_i × k_h × k_w</strong>.</p><div class="mermaid"></div><p>Để tạo nhiều feature map đầu ra (c_o kênh), ta sử dụng c_o bộ kernel riêng biệt. Tổng số tham số của một lớp convolution là: <strong>c_o × c_i × k_h × k_w + c_o</strong> (bao gồm cả bias).</p><h3 id="_2-3-5-tich-chap-1×1" tabindex="-1">2.3.5. Tích chập 1×1 <a class="header-anchor" href="#_2-3-5-tich-chap-1×1" aria-label="Permalink to &quot;2.3.5. Tích chập 1×1&quot;">​</a></h3><p>Mặc dù thoạt nhìn có vẻ không có ý nghĩa vì không tổng hợp thông tin không gian, tích chập 1×1 đóng vai trò quan trọng trong các kiến trúc CNN hiện đại [1]:</p><ul><li><strong>Thay đổi số kênh:</strong> Chuyển từ c_i kênh sang c_o kênh một cách hiệu quả</li><li><strong>Kết hợp thông tin đa kênh:</strong> Mỗi pixel output là tổ hợp tuyến tính của c_i giá trị từ các kênh input tại cùng vị trí</li><li><strong>Tương đương fully connected theo pixel:</strong> Áp dụng cùng phép biến đổi tuyến tính cho mọi vị trí không gian, cho phép tăng hoặc giảm chiều biểu diễn</li></ul><div class="mermaid"></div><h3 id="_2-3-6-đac-điem-anh-vien-tham-va-xu-ly-đa-kenh" tabindex="-1">2.3.6. Đặc điểm Ảnh Viễn thám và Xử lý Đa kênh <a class="header-anchor" href="#_2-3-6-đac-điem-anh-vien-tham-va-xu-ly-đa-kenh" aria-label="Permalink to &quot;2.3.6. Đặc điểm Ảnh Viễn thám và Xử lý Đa kênh&quot;">​</a></h3><p>Ảnh viễn thám có những đặc điểm khác biệt so với ảnh tự nhiên, đòi hỏi các điều chỉnh trong kiến trúc CNN:</p><p><strong>Ảnh đa phổ (Multispectral Imagery):</strong> Không giới hạn ở 3 kênh RGB, ảnh vệ tinh thường có nhiều kênh phổ khác nhau. Sentinel-2 cung cấp 13 kênh từ visible (VIS) đến near-infrared (NIR) và shortwave infrared (SWIR). Khi sử dụng pre-trained weights từ ImageNet (3 kênh), có thể mở rộng lớp convolution đầu tiên để nhận C kênh input, hoặc chọn 3 kênh phù hợp nhất (ví dụ: kênh 4-Red, 3-Green, 2-Blue của Sentinel-2).</p><p><strong>Ảnh SAR (Synthetic Aperture Radar):</strong> Sentinel-1 cung cấp ảnh SAR với 2 kênh phân cực VV (vertical-vertical) và VH (vertical-horizontal). Đặc tính của ảnh SAR khác hoàn toàn với ảnh quang học: không phụ thuộc vào ánh sáng mặt trời, xuyên qua mây, và có speckle noise đặc trưng. Các backbone CNN cần được pre-train hoặc fine-tune đặc biệt cho ảnh SAR để đạt hiệu suất tốt.</p><p><strong>Multi-scale objects:</strong> Trong ảnh vệ tinh chụp từ trên cao, cùng một loại đối tượng có thể xuất hiện ở nhiều tỷ lệ rất khác nhau. Một tàu container có thể dài hàng trăm pixel trong ảnh độ phân giải cao, trong khi một tàu đánh cá nhỏ chỉ vài pixel trong ảnh Sentinel-1. Điều này đòi hỏi kiến trúc multi-scale như Feature Pyramid Network (FPN) và các cơ chế attention để xử lý hiệu quả.</p><h2 id="_2-4-lop-pooling" tabindex="-1">2.4. Lớp Pooling <a class="header-anchor" href="#_2-4-lop-pooling" aria-label="Permalink to &quot;2.4. Lớp Pooling&quot;">​</a></h2><h3 id="_2-4-1-muc-đich-va-nguyen-ly" tabindex="-1">2.4.1. Mục đích và Nguyên lý <a class="header-anchor" href="#_2-4-1-muc-đich-va-nguyen-ly" aria-label="Permalink to &quot;2.4.1. Mục đích và Nguyên lý&quot;">​</a></h3><p>Lớp pooling thực hiện phép giảm mẫu (downsampling), thu nhỏ kích thước không gian của feature map trong khi giữ lại thông tin quan trọng nhất. Pooling phục vụ ba mục đích chính [1]:</p><ol><li><strong>Giảm chi phí tính toán:</strong> Giảm số lượng tham số và phép tính cho các lớp tiếp theo</li><li><strong>Mở rộng receptive field:</strong> Mỗi nơ-ron ở lớp sâu hơn có thể &quot;nhìn thấy&quot; vùng ảnh lớn hơn</li><li><strong>Tăng tính bất biến:</strong> Giảm độ nhạy cảm với các dịch chuyển nhỏ của đối tượng trong ảnh</li></ol><p><strong>Đặc điểm quan trọng:</strong> Khác với lớp convolution, pooling không có tham số học được. Nó áp dụng một phép toán cố định (max hoặc average) lên từng vùng của input. Số kênh output bằng số kênh input vì pooling xử lý từng kênh độc lập.</p><h3 id="_2-4-2-max-pooling-va-average-pooling" tabindex="-1">2.4.2. Max Pooling và Average Pooling <a class="header-anchor" href="#_2-4-2-max-pooling-va-average-pooling" aria-label="Permalink to &quot;2.4.2. Max Pooling và Average Pooling&quot;">​</a></h3><div class="mermaid"></div><p><strong>Max Pooling</strong> chọn giá trị lớn nhất trong mỗi vùng pooling, giữ lại activation mạnh nhất. Phương pháp này phù hợp khi quan tâm đến sự tồn tại của đặc trưng tại một vùng nhất định và tạo tính bất biến với các dịch chuyển nhỏ.</p><p><strong>Average Pooling</strong> tính giá trị trung bình của các phần tử trong vùng pooling, giữ lại thông tin tổng thể về cường độ đặc trưng. Phương pháp này phù hợp cho việc tổng hợp ngữ cảnh và thường được sử dụng ở cuối mạng.</p><h3 id="_2-4-3-global-average-pooling-gap" tabindex="-1">2.4.3. Global Average Pooling (GAP) <a class="header-anchor" href="#_2-4-3-global-average-pooling-gap" aria-label="Permalink to &quot;2.4.3. Global Average Pooling (GAP)&quot;">​</a></h3><p>Global Average Pooling tính trung bình trên toàn bộ feature map cho mỗi kênh, tạo ra output có kích thước 1×1×C (với C là số kênh). Kỹ thuật này được giới thiệu trong Network in Network [6] và được sử dụng rộng rãi trong các kiến trúc hiện đại.</p><div class="mermaid"></div><p>GAP mang lại nhiều lợi ích quan trọng:</p><ul><li><strong>Giảm đáng kể số tham số</strong> so với việc sử dụng các lớp fully connected lớn</li><li><strong>Tránh overfitting</strong> nhờ loại bỏ phần lớn tham số ở phần classifier</li><li><strong>Cho phép xử lý ảnh với kích thước bất kỳ</strong> vì không phụ thuộc vào kích thước không gian cố định</li></ul><h2 id="_2-5-ham-kich-hoat-activation-function" tabindex="-1">2.5. Hàm Kích hoạt (Activation Function) <a class="header-anchor" href="#_2-5-ham-kich-hoat-activation-function" aria-label="Permalink to &quot;2.5. Hàm Kích hoạt (Activation Function)&quot;">​</a></h2><h3 id="_2-5-1-vai-tro-cua-ham-kich-hoat" tabindex="-1">2.5.1. Vai trò của Hàm Kích hoạt <a class="header-anchor" href="#_2-5-1-vai-tro-cua-ham-kich-hoat" aria-label="Permalink to &quot;2.5.1. Vai trò của Hàm Kích hoạt&quot;">​</a></h3><p>Hàm kích hoạt đóng vai trò thiết yếu trong việc thêm tính phi tuyến vào mạng nơ-ron. Nếu không có hàm kích hoạt phi tuyến, việc xếp chồng nhiều lớp convolution hay fully connected sẽ chỉ tương đương với một phép biến đổi tuyến tính duy nhất:</p><p>f(g(x)) = Ax + b (nếu cả f và g đều tuyến tính)</p><p>Với hàm kích hoạt phi tuyến, mạng có thể xấp xỉ các hàm phức tạp tùy ý theo định lý universal approximation, mở ra khả năng học các biểu diễn phức tạp từ dữ liệu.</p><h3 id="_2-5-2-relu-va-cac-bien-the" tabindex="-1">2.5.2. ReLU và các biến thể <a class="header-anchor" href="#_2-5-2-relu-va-cac-bien-the" aria-label="Permalink to &quot;2.5.2. ReLU và các biến thể&quot;">​</a></h3><div class="mermaid"></div><p><strong>ReLU (Rectified Linear Unit)</strong> là hàm kích hoạt được sử dụng phổ biến nhất trong các CNN hiện đại [3] nhờ các ưu điểm:</p><ul><li><strong>Tính toán đơn giản:</strong> Chỉ cần thực hiện phép so sánh với 0</li><li><strong>Giảm vấn đề vanishing gradient:</strong> Gradient bằng 1 khi x &gt; 0, cho phép gradient truyền ngược hiệu quả</li><li><strong>Tạo sparse activation:</strong> Nhiều output bằng 0, giúp biểu diễn hiệu quả và tiết kiệm tính toán</li></ul><p><strong>Nhược điểm &quot;Dying ReLU&quot;:</strong> Nếu input luôn âm (do khởi tạo trọng số không phù hợp hoặc learning rate quá lớn), gradient sẽ bằng 0 và nơ-ron không thể cập nhật được nữa, dẫn đến hiện tượng nơ-ron &quot;chết&quot; vĩnh viễn.</p><p><strong>Leaky ReLU</strong> và <strong>PReLU</strong> được đề xuất để khắc phục vấn đề này bằng cách cho phép một gradient nhỏ khi x &lt; 0, đảm bảo nơ-ron luôn có thể được cập nhật.</p><h3 id="_2-5-3-ham-sigmoid-va-softmax" tabindex="-1">2.5.3. Hàm Sigmoid và Softmax <a class="header-anchor" href="#_2-5-3-ham-sigmoid-va-softmax" aria-label="Permalink to &quot;2.5.3. Hàm Sigmoid và Softmax&quot;">​</a></h3><p><strong>Sigmoid:</strong> σ(x) = 1 / (1 + e^(-x))</p><ul><li>Output nằm trong khoảng (0, 1), thích hợp cho việc biểu diễn xác suất</li><li>Thường được sử dụng cho bài toán phân loại nhị phân (binary classification)</li><li>Nhược điểm: Gặp vấn đề vanishing gradient khi |x| lớn, làm chậm quá trình học</li></ul><p><strong>Softmax:</strong> Biến đổi vector z thành phân phối xác suất:</p><ul><li>softmax(z_i) = e^(z_i) / Σ e^(z_j)</li><li>Tổng các xác suất bằng 1, cho phép diễn giải output như xác suất thuộc từng lớp</li><li>Được sử dụng ở lớp cuối cùng cho bài toán phân loại đa lớp (multi-class classification)</li></ul><h3 id="_2-5-4-ham-kich-hoat-hien-đai-gelu-va-swish" tabindex="-1">2.5.4. Hàm kích hoạt hiện đại: GELU và Swish <a class="header-anchor" href="#_2-5-4-ham-kich-hoat-hien-đai-gelu-va-swish" aria-label="Permalink to &quot;2.5.4. Hàm kích hoạt hiện đại: GELU và Swish&quot;">​</a></h3><p><strong>GELU (Gaussian Error Linear Unit)</strong> kết hợp tính chất của ReLU với một hàm mịn, được sử dụng rộng rãi trong các mô hình Transformer như BERT và Vision Transformer [7]. GELU có thể được xấp xỉ bằng công thức: GELU(x) ≈ 0.5x(1 + tanh(√(2/π)(x + 0.044715x³)))</p><p><strong>Swish</strong> được định nghĩa là f(x) = x × σ(x), tự động điều chỉnh giữa hành vi tuyến tính và phi tuyến tùy thuộc vào giá trị input. Hàm này cho kết quả tốt trên nhiều kiến trúc, đặc biệt là EfficientNet [8].</p><h2 id="_2-6-batch-normalization" tabindex="-1">2.6. Batch Normalization <a class="header-anchor" href="#_2-6-batch-normalization" aria-label="Permalink to &quot;2.6. Batch Normalization&quot;">​</a></h2><h3 id="_2-6-1-van-đe-internal-covariate-shift" tabindex="-1">2.6.1. Vấn đề Internal Covariate Shift <a class="header-anchor" href="#_2-6-1-van-đe-internal-covariate-shift" aria-label="Permalink to &quot;2.6.1. Vấn đề Internal Covariate Shift&quot;">​</a></h3><p>Trong quá trình huấn luyện mạng sâu, phân phối của input tại mỗi lớp thay đổi liên tục theo sự cập nhật của các lớp trước đó. Hiện tượng này được gọi là <strong>internal covariate shift</strong> [4], gây khó khăn cho quá trình học vì mỗi lớp phải liên tục thích nghi với phân phối input mới thay vì tập trung vào việc học các đặc trưng hữu ích.</p><h3 id="_2-6-2-co-che-batch-normalization" tabindex="-1">2.6.2. Cơ chế Batch Normalization <a class="header-anchor" href="#_2-6-2-co-che-batch-normalization" aria-label="Permalink to &quot;2.6.2. Cơ chế Batch Normalization&quot;">​</a></h3><p>Batch Normalization (BN) được đề xuất bởi Ioffe và Szegedy [4] như một giải pháp cho vấn đề trên. BN chuẩn hóa activation của mỗi lớp theo mean và variance của mini-batch hiện tại, sau đó áp dụng phép biến đổi tuyến tính với các tham số học được:</p><div class="mermaid"></div><p><strong>Công thức tổng quát:</strong> y = γ × (x - μ) / √(σ² + ε) + β</p><p>Trong đó:</p><ul><li><strong>μ, σ²:</strong> Mean và variance của mini-batch (trong training) hoặc running average (trong inference)</li><li><strong>ε:</strong> Hằng số nhỏ (thường 10⁻⁵) để tránh chia cho 0</li><li><strong>γ, β:</strong> Tham số scale và shift, được học từ dữ liệu, cho phép mạng khôi phục biểu diễn ban đầu nếu cần thiết</li></ul><h3 id="_2-6-3-loi-ich-cua-batch-normalization" tabindex="-1">2.6.3. Lợi ích của Batch Normalization <a class="header-anchor" href="#_2-6-3-loi-ich-cua-batch-normalization" aria-label="Permalink to &quot;2.6.3. Lợi ích của Batch Normalization&quot;">​</a></h3><p>Batch Normalization mang lại nhiều lợi ích quan trọng cho quá trình huấn luyện [4]:</p><ol><li><strong>Cho phép sử dụng learning rate lớn hơn:</strong> BN ổn định phân phối activation, giảm nguy cơ gradient exploding và cho phép tăng tốc độ học</li><li><strong>Giảm phụ thuộc vào khởi tạo trọng số:</strong> Việc chuẩn hóa làm giảm ảnh hưởng của giá trị khởi tạo ban đầu đến quá trình huấn luyện</li><li><strong>Đóng vai trò regularization:</strong> Noise từ việc ước lượng mean và variance theo mini-batch có tác dụng tương tự dropout, giúp giảm overfitting</li><li><strong>Tăng tốc convergence đáng kể:</strong> Các thực nghiệm cho thấy BN có thể giảm số lượng iterations cần thiết để đạt convergence</li></ol><p><strong>Vị trí trong kiến trúc:</strong> BN thường được đặt sau lớp convolution hoặc fully connected. Có hai cách tiếp cận phổ biến: đặt BN trước hàm kích hoạt (pre-activation, được sử dụng trong ResNet v2) hoặc sau hàm kích hoạt (post-activation, sử dụng trong kiến trúc gốc).</p><h2 id="_2-7-dropout" tabindex="-1">2.7. Dropout <a class="header-anchor" href="#_2-7-dropout" aria-label="Permalink to &quot;2.7. Dropout&quot;">​</a></h2><h3 id="_2-7-1-co-che-hoat-đong" tabindex="-1">2.7.1. Cơ chế Hoạt động <a class="header-anchor" href="#_2-7-1-co-che-hoat-đong" aria-label="Permalink to &quot;2.7.1. Cơ chế Hoạt động&quot;">​</a></h3><p>Dropout là kỹ thuật regularization được đề xuất bởi Srivastava et al. [5] nhằm giảm overfitting trong mạng nơ-ron sâu. Trong mỗi iteration huấn luyện, dropout ngẫu nhiên &quot;tắt&quot; một tỷ lệ p các nơ-ron bằng cách đặt output của chúng về 0.</p><div class="mermaid"></div><p>Cơ chế này buộc mạng phải học các biểu diễn robust, không phụ thuộc vào bất kỳ nơ-ron cụ thể nào. Từ góc độ lý thuyết, dropout có thể được hiểu như một hình thức model averaging: mỗi lần training với một tập con nơ-ron khác nhau tương đương với việc training một mạng con khác nhau, và kết quả inference là trung bình của tất cả các mạng con này.</p><h3 id="_2-7-2-chien-luoc-su-dung-dropout" tabindex="-1">2.7.2. Chiến lược sử dụng Dropout <a class="header-anchor" href="#_2-7-2-chien-luoc-su-dung-dropout" aria-label="Permalink to &quot;2.7.2. Chiến lược sử dụng Dropout&quot;">​</a></h3><p>Tỷ lệ dropout được lựa chọn phụ thuộc vào loại lớp và kiến trúc mạng:</p><ul><li><strong>Lớp fully connected:</strong> Thường sử dụng p = 0.5 (tắt 50% nơ-ron) vì số lượng tham số lớn, dễ overfitting</li><li><strong>Lớp convolution:</strong> Thường sử dụng p nhỏ hơn (0.1 - 0.3) hoặc không sử dụng do tính chất chia sẻ trọng số đã có tác dụng regularization</li><li><strong>Kiến trúc hiện đại:</strong> Nhiều kiến trúc như ResNet và EfficientNet thay thế dropout bằng Batch Normalization kết hợp với weight decay, cho kết quả tương đương hoặc tốt hơn</li></ul><h2 id="_2-8-kien-truc-tong-the-cua-cnn" tabindex="-1">2.8. Kiến trúc Tổng thể của CNN <a class="header-anchor" href="#_2-8-kien-truc-tong-the-cua-cnn" aria-label="Permalink to &quot;2.8. Kiến trúc Tổng thể của CNN&quot;">​</a></h2><h3 id="_2-8-1-mau-kien-truc-co-đien" tabindex="-1">2.8.1. Mẫu Kiến trúc Cổ điển <a class="header-anchor" href="#_2-8-1-mau-kien-truc-co-đien" aria-label="Permalink to &quot;2.8.1. Mẫu Kiến trúc Cổ điển&quot;">​</a></h3><p>Các kiến trúc CNN cổ điển như LeNet [2] và VGGNet [3] tuân theo một mẫu thiết kế nhất quán: xen kẽ các lớp convolution với pooling, theo sau bởi các lớp fully connected để thực hiện phân loại.</p><div class="mermaid"></div><p><strong>Quy luật thiết kế chung:</strong></p><ul><li><strong>Kích thước không gian giảm dần:</strong> 224 → 112 → 56 → 28 → 14 → 7 (thường giảm một nửa sau mỗi lần pooling)</li><li><strong>Số kênh tăng dần:</strong> 3 → 64 → 128 → 256 → 512 (thường tăng gấp đôi khi giảm kích thước không gian)</li><li><strong>Biểu diễn chuyển từ chi tiết không gian sang ngữ nghĩa trừu tượng:</strong> Các lớp đầu biểu diễn đặc trưng cấp thấp (cạnh, góc), các lớp sâu biểu diễn khái niệm ngữ nghĩa cao (đối tượng, bộ phận)</li></ul><h3 id="_2-8-2-kien-truc-hien-đai" tabindex="-1">2.8.2. Kiến trúc Hiện đại <a class="header-anchor" href="#_2-8-2-kien-truc-hien-đai" aria-label="Permalink to &quot;2.8.2. Kiến trúc Hiện đại&quot;">​</a></h3><p>Các kiến trúc CNN hiện đại như ResNet [9], Inception [10], và EfficientNet [8] đã đưa ra nhiều cải tiến quan trọng so với mẫu cổ điển:</p><ul><li><strong>Skip connection (Residual connection):</strong> Cho phép gradient chảy trực tiếp qua nhiều lớp, giải quyết vấn đề vanishing gradient và cho phép huấn luyện mạng rất sâu (hàng trăm đến hàng nghìn lớp)</li><li><strong>Bottleneck block:</strong> Sử dụng Conv 1×1 để giảm số kênh trước khi thực hiện Conv 3×3 tốn kém, sau đó tăng lại số kênh, giảm đáng kể chi phí tính toán</li><li><strong>Global Average Pooling:</strong> Thay thế các lớp fully connected lớn ở cuối mạng, giảm số tham số và tránh overfitting</li><li><strong>Compound scaling:</strong> Cân bằng đồng thời ba chiều (độ sâu, độ rộng, và độ phân giải) để đạt hiệu quả tối ưu với một lượng tài nguyên tính toán cho trước</li></ul><p>Chi tiết các kiến trúc backbone này được trình bày trong Mục 2.2.</p><h2 id="_2-9-qua-trinh-huan-luyen-cnn" tabindex="-1">2.9. Quá trình Huấn luyện CNN <a class="header-anchor" href="#_2-9-qua-trinh-huan-luyen-cnn" aria-label="Permalink to &quot;2.9. Quá trình Huấn luyện CNN&quot;">​</a></h2><h3 id="_2-9-1-forward-va-backward-propagation" tabindex="-1">2.9.1. Forward và Backward Propagation <a class="header-anchor" href="#_2-9-1-forward-va-backward-propagation" aria-label="Permalink to &quot;2.9.1. Forward và Backward Propagation&quot;">​</a></h3><p>Quá trình huấn luyện CNN bao gồm hai giai đoạn chính được thực hiện lặp đi lặp lại: forward propagation và backward propagation.</p><div class="mermaid"></div><p><strong>Forward propagation</strong> là quá trình tính toán output của mạng từ input đầu vào. Dữ liệu được truyền qua từng lớp theo thứ tự, với output của lớp trước trở thành input của lớp sau. Tại mỗi lớp, các phép biến đổi tương ứng (convolution, activation, pooling, v.v.) được thực hiện cho đến khi thu được output cuối cùng.</p><p><strong>Backward propagation</strong> (hay backpropagation) là quá trình tính toán gradient của loss function theo từng tham số trong mạng bằng cách áp dụng chain rule. Gradient được tính toán từ lớp cuối cùng và truyền ngược về lớp đầu tiên, cho phép xác định hướng cập nhật tối ưu cho mỗi tham số.</p><h3 id="_2-9-2-ham-loss-loss-function" tabindex="-1">2.9.2. Hàm Loss (Loss Function) <a class="header-anchor" href="#_2-9-2-ham-loss-loss-function" aria-label="Permalink to &quot;2.9.2. Hàm Loss (Loss Function)&quot;">​</a></h3><p>Hàm loss đo lường sự khác biệt giữa output dự đoán của mạng và nhãn thực tế (ground truth), cung cấp tín hiệu để điều chỉnh các tham số trong quá trình học.</p><p><strong>Cross-Entropy Loss</strong> là hàm loss được sử dụng phổ biến nhất cho bài toán phân loại đa lớp:</p><p>L = -Σᵢ yᵢ × log(pᵢ)</p><p>Trong đó:</p><ul><li><strong>yᵢ:</strong> One-hot encoding của nhãn thực tế (1 cho lớp đúng, 0 cho các lớp khác)</li><li><strong>pᵢ:</strong> Xác suất dự đoán cho lớp i (output của softmax)</li></ul><p>Cross-Entropy Loss có tính chất phạt nặng các dự đoán sai với độ tin cậy cao, khuyến khích mô hình đưa ra các dự đoán chính xác và đáng tin cậy.</p><p>Đối với các bài toán khác trong viễn thám như phát hiện đối tượng và phân đoạn ngữ nghĩa, các hàm loss phức tạp hơn được sử dụng, bao gồm:</p><ul><li><strong>Focal Loss:</strong> Giải quyết vấn đề mất cân bằng lớp trong object detection</li><li><strong>Dice Loss và IoU Loss:</strong> Tối ưu trực tiếp các metric đánh giá cho segmentation</li><li><strong>Smooth L1 Loss:</strong> Sử dụng cho bounding box regression trong object detection</li></ul><h3 id="_2-9-3-thuat-toan-optimization" tabindex="-1">2.9.3. Thuật toán Optimization <a class="header-anchor" href="#_2-9-3-thuat-toan-optimization" aria-label="Permalink to &quot;2.9.3. Thuật toán Optimization&quot;">​</a></h3><p>Sau khi tính được gradient, các thuật toán optimization sử dụng thông tin này để cập nhật tham số theo hướng giảm loss.</p><p><strong>Stochastic Gradient Descent (SGD) với Momentum</strong> là thuật toán cổ điển nhưng vẫn hiệu quả. Momentum giúp tích lũy &quot;đà&quot; từ các bước trước, giúp vượt qua các local minima nhỏ và tăng tốc convergence:</p><p>v_t = β × v_{t-1} + η × ∇L θ_t = θ_{t-1} - v_t</p><p>Trong đó β là hệ số momentum (thường 0.9) và η là learning rate.</p><p><strong>Adam (Adaptive Moment Estimation)</strong> kết hợp ưu điểm của momentum với adaptive learning rate cho từng tham số. Adam duy trì ước lượng của cả moment bậc một (mean) và bậc hai (variance) của gradient, cho phép điều chỉnh learning rate phù hợp với từng tham số. Thuật toán này đặc biệt hiệu quả cho các bài toán với gradient thưa hoặc noisy.</p><p><strong>Learning Rate Scheduling</strong> là kỹ thuật quan trọng để đạt convergence tốt. Các chiến lược phổ biến bao gồm:</p><ul><li><strong>Step decay:</strong> Giảm learning rate theo các bước cố định (ví dụ: giảm 10 lần sau mỗi 30 epochs)</li><li><strong>Cosine annealing:</strong> Giảm learning rate theo hàm cosine, cho phép &quot;warm restart&quot; để thoát khỏi local minima</li><li><strong>Warmup:</strong> Bắt đầu với learning rate nhỏ và tăng dần trong một số iterations đầu, giúp ổn định quá trình training ban đầu</li></ul><p><strong>Weight Decay (L2 Regularization)</strong> thêm penalty cho các trọng số có giá trị lớn, giúp tránh overfitting:</p><p>L_total = L_data + λ × ||W||²</p><p>Trong đó λ là hệ số regularization, kiểm soát độ mạnh của penalty. Weight decay được sử dụng rộng rãi trong hầu hết các kiến trúc CNN hiện đại.</p><hr><h2 id="tai-lieu-tham-khao" tabindex="-1">Tài liệu Tham khảo <a class="header-anchor" href="#tai-lieu-tham-khao" aria-label="Permalink to &quot;Tài liệu Tham khảo&quot;">​</a></h2><p>[1] Zhang, A., Lipton, Z. C., Li, M., &amp; Smola, A. J. (2023). Dive into Deep Learning. Cambridge University Press. <a href="https://d2l.ai/" target="_blank" rel="noreferrer">https://d2l.ai/</a></p><p>[2] LeCun, Y., Bottou, L., Bengio, Y., &amp; Haffner, P. (1998). Gradient-based learning applied to document recognition. <em>Proceedings of the IEEE</em>, 86(11), 2278-2324.</p><p>[3] Simonyan, K., &amp; Zisserman, A. (2015). Very Deep Convolutional Networks for Large-Scale Image Recognition. In <em>Proceedings of ICLR 2015</em>.</p><p>[4] Ioffe, S., &amp; Szegedy, C. (2015). Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. In <em>Proceedings of ICML 2015</em>.</p><p>[5] Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R. (2014). Dropout: A Simple Way to Prevent Neural Networks from Overfitting. <em>Journal of Machine Learning Research</em>, 15, 1929-1958.</p><p>[6] Lin, M., Chen, Q., &amp; Yan, S. (2014). Network In Network. In <em>Proceedings of ICLR 2014</em>.</p><p>[7] Hendrycks, D., &amp; Gimpel, K. (2016). Gaussian Error Linear Units (GELUs). <em>arXiv preprint arXiv:1606.08415</em>.</p><p>[8] Tan, M., &amp; Le, Q. V. (2019). EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. In <em>Proceedings of ICML 2019</em>.</p><p>[9] He, K., Zhang, X., Ren, S., &amp; Sun, J. (2016). Deep Residual Learning for Image Recognition. In <em>Proceedings of CVPR 2016</em>.</p><p>[10] Szegedy, C., et al. (2015). Going Deeper with Convolutions. In <em>Proceedings of CVPR 2015</em>.</p></div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-e257564d><!--[--><!--]--><div class="edit-info" data-v-e257564d><!----><div class="last-updated" data-v-e257564d><p class="VPLastUpdated" data-v-e257564d data-v-e98dd255>Cập nhật lần cuối: <time datetime="2025-12-21T07:29:49.000Z" data-v-e98dd255></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><a class="VPLink link pager-link prev" href="/sen_doc/chuong-01-gioi-thieu/muc-01-tong-quan/01-gioi-thieu-cnn-deep-learning.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Trang trước</span><span class="title" data-v-e257564d>1.1. Tổng quan CNN & Deep Learning</span><!--]--></a></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/sen_doc/chuong-02-co-so-ly-thuyet/muc-01-kien-truc-cnn/02-backbone-networks.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Trang sau</span><span class="title" data-v-e257564d>2.1.2. Backbone Networks</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5d98c3a5 data-v-e315a0ad><div class="container" data-v-e315a0ad><p class="message" data-v-e315a0ad>Nghiên cứu Ứng dụng Deep Learning trong Viễn thám</p><p class="copyright" data-v-e315a0ad>2024</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"assets_images_chuong-03-torchgeo_papers_index.md\":\"C5NkNcCF\",\"assets_images_chuong-04-xview1_image-sources.md\":\"BLJAGiKa\",\"assets_images_chuong-04-xview1_readme.md\":\"Bp5sqMPl\",\"assets_images_chuong-04-xview2_download-guide.md\":\"D5vnYAHG\",\"assets_images_chuong-04-xview2_image-reference-catalog.md\":\"BNiM_78j\",\"assets_images_chuong-04-xview2_image-sources.md\":\"DidqAo0G\",\"assets_images_chuong-04-xview2_readme.md\":\"Bxbqyjab\",\"assets_images_chuong-04-xview3_image-sources.md\":\"CoBvHO5R\",\"chuong-01-gioi-thieu_muc-01-tong-quan_01-gioi-thieu-cnn-deep-learning.md\":\"CLw4O4_d\",\"chuong-02-co-so-ly-thuyet_muc-01-kien-truc-cnn_01-kien-truc-co-ban.md\":\"D11mryt7\",\"chuong-02-co-so-ly-thuyet_muc-01-kien-truc-cnn_02-backbone-networks.md\":\"BdTjRE6v\",\"chuong-02-co-so-ly-thuyet_muc-02-phuong-phap-xu-ly-anh_01-phan-loai-anh.md\":\"Cnr5f5la\",\"chuong-02-co-so-ly-thuyet_muc-02-phuong-phap-xu-ly-anh_02-phat-hien-doi-tuong.md\":\"B07STELM\",\"chuong-02-co-so-ly-thuyet_muc-02-phuong-phap-xu-ly-anh_03-phan-doan-ngu-nghia.md\":\"BRqWC815\",\"chuong-02-co-so-ly-thuyet_muc-02-phuong-phap-xu-ly-anh_04-instance-segmentation.md\":\"DlkkGgB8\",\"chuong-03-kien-truc-model_muc-01-tong-quan_01-tong-quan.md\":\"CGWrV-eE\",\"chuong-03-kien-truc-model_muc-02-classification_01-classification-models.md\":\"BRxJkltS\",\"chuong-03-kien-truc-model_muc-03-segmentation_01-segmentation-models.md\":\"BKdvFMDk\",\"chuong-03-kien-truc-model_muc-04-change-detection_01-change-detection-models.md\":\"BaQ320br\",\"chuong-03-kien-truc-model_muc-05-pretrained-weights_01-pretrained-weights.md\":\"aUx15L_k\",\"chuong-04-xview-challenges_00-gioi-thieu-xview.md\":\"yIlTkIdA\",\"chuong-04-xview-challenges_muc-01-xview1-object-detection_01-dataset.md\":\"D2VavW7P\",\"chuong-04-xview-challenges_muc-01-xview1-object-detection_02-giai-nhat.md\":\"CKWmA9X1\",\"chuong-04-xview-challenges_muc-01-xview1-object-detection_03-giai-nhi.md\":\"C5xYVN0D\",\"chuong-04-xview-challenges_muc-01-xview1-object-detection_04-giai-ba.md\":\"Dn0UIXRj\",\"chuong-04-xview-challenges_muc-01-xview1-object-detection_05-giai-tu.md\":\"BhDRSgTT\",\"chuong-04-xview-challenges_muc-01-xview1-object-detection_06-giai-nam.md\":\"BoYY3Nro\",\"chuong-04-xview-challenges_muc-02-xview2-building-damage_01-dataset.md\":\"hEfNqg34\",\"chuong-04-xview-challenges_muc-02-xview2-building-damage_02-giai-nhat.md\":\"BWsThMHd\",\"chuong-04-xview-challenges_muc-02-xview2-building-damage_03-giai-nhi.md\":\"ChnKyP5U\",\"chuong-04-xview-challenges_muc-02-xview2-building-damage_04-giai-ba.md\":\"BNRQ6GgR\",\"chuong-04-xview-challenges_muc-02-xview2-building-damage_05-giai-tu.md\":\"vZFkAFDr\",\"chuong-04-xview-challenges_muc-02-xview2-building-damage_06-giai-nam.md\":\"D11BpdGm\",\"chuong-04-xview-challenges_muc-03-xview3-maritime_01-dataset.md\":\"_SwWS1Jl\",\"chuong-04-xview-challenges_muc-03-xview3-maritime_02-giai-nhat.md\":\"Bw4burmb\",\"chuong-04-xview-challenges_muc-03-xview3-maritime_03-giai-nhi.md\":\"CSZj-bK6\",\"chuong-04-xview-challenges_muc-03-xview3-maritime_04-giai-ba.md\":\"DsBvaXu6\",\"chuong-04-xview-challenges_muc-03-xview3-maritime_05-giai-tu.md\":\"DJgdp1Ke\",\"chuong-04-xview-challenges_muc-03-xview3-maritime_06-giai-nam.md\":\"B6Iyymdj\",\"chuong-05-ung-dung-tau-bien_muc-01-dac-diem-bai-toan_01-dac-diem.md\":\"CdcqOXEr\",\"chuong-05-ung-dung-tau-bien_muc-02-mo-hinh_01-cac-mo-hinh.md\":\"BSO5o0xw\",\"chuong-05-ung-dung-tau-bien_muc-03-quy-trinh_01-pipeline.md\":\"DEKNrU5n\",\"chuong-05-ung-dung-tau-bien_muc-04-bo-du-lieu_01-datasets.md\":\"1haPh7S9\",\"chuong-06-ung-dung-dau-loang_muc-01-dac-diem-bai-toan_01-dac-diem.md\":\"Dj-LDXfZ\",\"chuong-06-ung-dung-dau-loang_muc-02-mo-hinh_01-cac-mo-hinh.md\":\"UKAgWZhx\",\"chuong-06-ung-dung-dau-loang_muc-03-quy-trinh_01-pipeline.md\":\"C8BFksW6\",\"chuong-06-ung-dung-dau-loang_muc-04-bo-du-lieu_01-datasets.md\":\"DxvkYV1K\",\"chuong-07-ket-luan_muc-01-tong-ket_01-ket-luan.md\":\"2uYEwnmI\",\"index.md\":\"1CQCQxqJ\",\"plans_reports_fullstack-dev-2025-12-21-phase-04-xview-reorganization.md\":\"D9a2ewrS\",\"plans_reports_fullstack-dev-2025-12-21-phase-05-ship-detection-application.md\":\"WBfEIpe1\",\"plans_reports_phase-07-conclusion-synthesis.md\":\"Bq8cxMya\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"vi-VN\",\"dir\":\"ltr\",\"title\":\"Deep Learning trong Viễn thám\",\"description\":\"Nghiên cứu ứng dụng CNN và Deep Learning trong phân tích ảnh viễn thám\",\"base\":\"/sen_doc/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"Trang chủ\",\"link\":\"/\"},{\"text\":\"Giới thiệu\",\"link\":\"/chuong-01-gioi-thieu/muc-01-tong-quan/01-gioi-thieu-cnn-deep-learning\"},{\"text\":\"Kiến trúc Model\",\"link\":\"/chuong-03-kien-truc-model/muc-01-tong-quan/01-tong-quan\"},{\"text\":\"xView\",\"link\":\"/chuong-04-xview-challenges/00-gioi-thieu-xview\"},{\"text\":\"Ứng dụng\",\"link\":\"/chuong-05-ung-dung-tau-bien/muc-01-dac-diem-bai-toan/01-dac-diem\"}],\"sidebar\":[{\"text\":\"Chương 1: Giới thiệu\",\"collapsed\":false,\"items\":[{\"text\":\"1.1. Tổng quan CNN & Deep Learning\",\"link\":\"/chuong-01-gioi-thieu/muc-01-tong-quan/01-gioi-thieu-cnn-deep-learning\"}]},{\"text\":\"Chương 2: Cơ sở lý thuyết\",\"collapsed\":false,\"items\":[{\"text\":\"2.1.1. Kiến trúc CNN cơ bản\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-01-kien-truc-cnn/01-kien-truc-co-ban\"},{\"text\":\"2.1.2. Backbone Networks\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-01-kien-truc-cnn/02-backbone-networks\"},{\"text\":\"2.2.1. Phân loại ảnh\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/01-phan-loai-anh\"},{\"text\":\"2.2.2. Phát hiện đối tượng\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/02-phat-hien-doi-tuong\"},{\"text\":\"2.2.3. Phân đoạn ngữ nghĩa\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/03-phan-doan-ngu-nghia\"},{\"text\":\"2.2.4. Instance Segmentation\",\"link\":\"/chuong-02-co-so-ly-thuyet/muc-02-phuong-phap-xu-ly-anh/04-instance-segmentation\"}]},{\"text\":\"Chương 3: Kiến trúc Mô hình\",\"collapsed\":true,\"items\":[{\"text\":\"3.1. Tổng quan TorchGeo\",\"link\":\"/chuong-03-kien-truc-model/muc-01-tong-quan/01-tong-quan\"},{\"text\":\"3.2. Classification Models\",\"link\":\"/chuong-03-kien-truc-model/muc-02-classification/01-classification-models\"},{\"text\":\"3.3. Segmentation Models\",\"link\":\"/chuong-03-kien-truc-model/muc-03-segmentation/01-segmentation-models\"},{\"text\":\"3.4. Change Detection\",\"link\":\"/chuong-03-kien-truc-model/muc-04-change-detection/01-change-detection-models\"},{\"text\":\"3.5. Pre-trained Weights\",\"link\":\"/chuong-03-kien-truc-model/muc-05-pretrained-weights/01-pretrained-weights\"}]},{\"text\":\"Chương 4: xView Challenges\",\"collapsed\":false,\"items\":[{\"text\":\"Giới thiệu xView\",\"link\":\"/chuong-04-xview-challenges/00-gioi-thieu-xview\"},{\"text\":\"4.1. xView1 - Object Detection\",\"collapsed\":true,\"items\":[{\"text\":\"Dataset\",\"link\":\"/chuong-04-xview-challenges/muc-01-xview1-object-detection/01-dataset\"},{\"text\":\"Giải nhất\",\"link\":\"/chuong-04-xview-challenges/muc-01-xview1-object-detection/02-giai-nhat\"},{\"text\":\"Giải nhì\",\"link\":\"/chuong-04-xview-challenges/muc-01-xview1-object-detection/03-giai-nhi\"},{\"text\":\"Giải ba\",\"link\":\"/chuong-04-xview-challenges/muc-01-xview1-object-detection/04-giai-ba\"},{\"text\":\"Giải tư\",\"link\":\"/chuong-04-xview-challenges/muc-01-xview1-object-detection/05-giai-tu\"},{\"text\":\"Giải năm\",\"link\":\"/chuong-04-xview-challenges/muc-01-xview1-object-detection/06-giai-nam\"}]},{\"text\":\"4.2. xView2 - Building Damage\",\"collapsed\":true,\"items\":[{\"text\":\"Dataset (xBD)\",\"link\":\"/chuong-04-xview-challenges/muc-02-xview2-building-damage/01-dataset\"},{\"text\":\"Giải nhất\",\"link\":\"/chuong-04-xview-challenges/muc-02-xview2-building-damage/02-giai-nhat\"},{\"text\":\"Giải nhì\",\"link\":\"/chuong-04-xview-challenges/muc-02-xview2-building-damage/03-giai-nhi\"},{\"text\":\"Giải ba\",\"link\":\"/chuong-04-xview-challenges/muc-02-xview2-building-damage/04-giai-ba\"},{\"text\":\"Giải tư\",\"link\":\"/chuong-04-xview-challenges/muc-02-xview2-building-damage/05-giai-tu\"},{\"text\":\"Giải năm\",\"link\":\"/chuong-04-xview-challenges/muc-02-xview2-building-damage/06-giai-nam\"}]},{\"text\":\"4.3. xView3 - Maritime (SAR)\",\"collapsed\":true,\"items\":[{\"text\":\"Dataset\",\"link\":\"/chuong-04-xview-challenges/muc-03-xview3-maritime/01-dataset\"},{\"text\":\"Giải nhất\",\"link\":\"/chuong-04-xview-challenges/muc-03-xview3-maritime/02-giai-nhat\"},{\"text\":\"Giải nhì\",\"link\":\"/chuong-04-xview-challenges/muc-03-xview3-maritime/03-giai-nhi\"},{\"text\":\"Giải ba\",\"link\":\"/chuong-04-xview-challenges/muc-03-xview3-maritime/04-giai-ba\"},{\"text\":\"Giải tư\",\"link\":\"/chuong-04-xview-challenges/muc-03-xview3-maritime/05-giai-tu\"},{\"text\":\"Giải năm\",\"link\":\"/chuong-04-xview-challenges/muc-03-xview3-maritime/06-giai-nam\"}]}]},{\"text\":\"Chương 5: Phát hiện Tàu biển\",\"collapsed\":true,\"items\":[{\"text\":\"5.1. Đặc điểm bài toán\",\"link\":\"/chuong-05-ung-dung-tau-bien/muc-01-dac-diem-bai-toan/01-dac-diem\"},{\"text\":\"5.2. Các mô hình\",\"link\":\"/chuong-05-ung-dung-tau-bien/muc-02-mo-hinh/01-cac-mo-hinh\"},{\"text\":\"5.3. Quy trình xử lý\",\"link\":\"/chuong-05-ung-dung-tau-bien/muc-03-quy-trinh/01-pipeline\"},{\"text\":\"5.4. Bộ dữ liệu\",\"link\":\"/chuong-05-ung-dung-tau-bien/muc-04-bo-du-lieu/01-datasets\"}]},{\"text\":\"Chương 6: Phát hiện Dầu loang\",\"collapsed\":true,\"items\":[{\"text\":\"6.1. Đặc điểm bài toán\",\"link\":\"/chuong-06-ung-dung-dau-loang/muc-01-dac-diem-bai-toan/01-dac-diem\"},{\"text\":\"6.2. Các mô hình\",\"link\":\"/chuong-06-ung-dung-dau-loang/muc-02-mo-hinh/01-cac-mo-hinh\"},{\"text\":\"6.3. Quy trình xử lý\",\"link\":\"/chuong-06-ung-dung-dau-loang/muc-03-quy-trinh/01-pipeline\"},{\"text\":\"6.4. Bộ dữ liệu\",\"link\":\"/chuong-06-ung-dung-dau-loang/muc-04-bo-du-lieu/01-datasets\"}]},{\"text\":\"Chương 7: Kết luận\",\"collapsed\":false,\"items\":[{\"text\":\"7.1. Tổng kết\",\"link\":\"/chuong-07-ket-luan/muc-01-tong-ket/01-ket-luan\"}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/tchatb/sen_doc\"}],\"search\":{\"provider\":\"local\"},\"outline\":{\"level\":[2,3],\"label\":\"Mục lục trang\"},\"footer\":{\"message\":\"Nghiên cứu Ứng dụng Deep Learning trong Viễn thám\",\"copyright\":\"2024\"},\"docFooter\":{\"prev\":\"Trang trước\",\"next\":\"Trang sau\"},\"lastUpdated\":{\"text\":\"Cập nhật lần cuối\"},\"returnToTopLabel\":\"Về đầu trang\",\"sidebarMenuLabel\":\"Menu\",\"darkModeSwitchLabel\":\"Giao diện\"},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>